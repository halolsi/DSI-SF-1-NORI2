{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with stumbleupon data\n",
    "\n",
    "Project 4 has been changed since scraping was untenable. The project now focuses on the stumbleupon kaggle dataset. For more information on this dataset, [check out the website here](https://www.kaggle.com/c/stumbleupon).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the dataset\n",
    "\n",
    "This is the only part completed for you.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "su = pd.read_csv('../dataset/evergreen.tsv', delimiter='\\t', na_values='?')\n",
    "su_sub = su #get ready for subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean up/examine your data\n",
    "\n",
    "Some of the columns may have values that need changing or that are of the wrong type. There could also be columns that aren't very useful.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>...</th>\n",
       "      <th>is_news</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.popsci.com/technology/article/2012-...</td>\n",
       "      <td>8471</td>\n",
       "      <td>{\"title\":\"The Fully Electronic Futuristic Star...</td>\n",
       "      <td>recreation</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>3.677966</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4973</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  urlid  \\\n",
       "0  http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "1  http://www.popsci.com/technology/article/2012-...   8471   \n",
       "\n",
       "                                         boilerplate alchemy_category  \\\n",
       "0  {\"title\":\"IBM Sees Holographic Calls Air Breat...         business   \n",
       "1  {\"title\":\"The Fully Electronic Futuristic Star...       recreation   \n",
       "\n",
       "   alchemy_category_score  avglinksize  commonlinkratio_1  commonlinkratio_2  \\\n",
       "0                0.789131     2.055556           0.676471           0.205882   \n",
       "1                0.574147     3.677966           0.508021           0.288770   \n",
       "\n",
       "   commonlinkratio_3  commonlinkratio_4  ...    is_news  lengthyLinkDomain  \\\n",
       "0           0.047059           0.023529  ...        1.0                  1   \n",
       "1           0.213904           0.144385  ...        1.0                  1   \n",
       "\n",
       "   linkwordscore  news_front_page  non_markup_alphanum_characters  \\\n",
       "0             24              0.0                            5424   \n",
       "1             40              0.0                            4973   \n",
       "\n",
       "   numberOfLinks  numwords_in_url  parametrizedLinkRatio  \\\n",
       "0            170                8               0.152941   \n",
       "1            187                9               0.181818   \n",
       "\n",
       "   spelling_errors_ratio  label  \n",
       "0               0.079130      0  \n",
       "1               0.125448      1  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "su.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['url', 'urlid', 'boilerplate', 'alchemy_category', 'alchemy_category_score', 'avglinksize', 'commonlinkratio_1', 'commonlinkratio_2', 'commonlinkratio_3', 'commonlinkratio_4', 'compression_ratio', 'embed_ratio', 'framebased', 'frameTagRatio', 'hasDomainLink', 'html_ratio', 'image_ratio', 'is_news', 'lengthyLinkDomain', 'linkwordscore', 'news_front_page', 'non_markup_alphanum_characters', 'numberOfLinks', 'numwords_in_url', 'parametrizedLinkRatio', 'spelling_errors_ratio', 'label']\n"
     ]
    }
   ],
   "source": [
    "# List of Column Names\n",
    "col = list(su.columns.values) \n",
    "print col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_s    7395\n",
       "Name: url, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def def_count_unique(df):\n",
    "    cols = pd.Series(df.columns.values) #Series of column headers\n",
    "    \n",
    "    y = []\n",
    "    for x in df:\n",
    "        z = len(np.unique(df[x]))\n",
    "        y.append(z)\n",
    "                    \n",
    "    q = pd.DataFrame(y, index = df.columns.values, columns=[\"unique_s\"])\n",
    "    r = q.sort_values(\"unique_s\", ascending=False)\n",
    "    return r.T\n",
    "\n",
    "b = def_count_unique(su)\n",
    "b['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sutypes = su.apply(lambda x: pd.lib.infer_dtype(x.values))\n",
    "\n",
    "sutypes['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_count</th>\n",
       "      <th>example</th>\n",
       "      <th>types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urlid</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>4042</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boilerplate</th>\n",
       "      <td>7394.0</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>html_ratio</th>\n",
       "      <td>7376.0</td>\n",
       "      <td>0.245831</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <td>7147.0</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compression_ratio</th>\n",
       "      <td>6453.0</td>\n",
       "      <td>0.443783</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frameTagRatio</th>\n",
       "      <td>5911.0</td>\n",
       "      <td>0.0907738</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avglinksize</th>\n",
       "      <td>5710.0</td>\n",
       "      <td>2.05556</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_ratio</th>\n",
       "      <td>5418.0</td>\n",
       "      <td>0.00388349</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <td>5301.0</td>\n",
       "      <td>5424</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <td>4476.0</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <td>4219.0</td>\n",
       "      <td>0.0791296</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <td>4038.0</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <td>3922.0</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <td>3266.0</td>\n",
       "      <td>0.0470588</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_news</th>\n",
       "      <td>2844.0</td>\n",
       "      <td>1</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <td>2695.0</td>\n",
       "      <td>0.0235294</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news_front_page</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numberOfLinks</th>\n",
       "      <td>702.0</td>\n",
       "      <td>170</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_ratio</th>\n",
       "      <td>366.0</td>\n",
       "      <td>0</td>\n",
       "      <td>floating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linkwordscore</th>\n",
       "      <td>101.0</td>\n",
       "      <td>24</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numwords_in_url</th>\n",
       "      <td>23.0</td>\n",
       "      <td>8</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alchemy_category</th>\n",
       "      <td>14.0</td>\n",
       "      <td>business</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasDomainLink</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>framebased</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_count  \\\n",
       "url                                   7395.0   \n",
       "urlid                                 7395.0   \n",
       "boilerplate                           7394.0   \n",
       "html_ratio                            7376.0   \n",
       "alchemy_category_score                7147.0   \n",
       "compression_ratio                     6453.0   \n",
       "frameTagRatio                         5911.0   \n",
       "avglinksize                           5710.0   \n",
       "image_ratio                           5418.0   \n",
       "non_markup_alphanum_characters        5301.0   \n",
       "commonlinkratio_1                     4476.0   \n",
       "spelling_errors_ratio                 4219.0   \n",
       "commonlinkratio_2                     4038.0   \n",
       "parametrizedLinkRatio                 3922.0   \n",
       "commonlinkratio_3                     3266.0   \n",
       "is_news                               2844.0   \n",
       "commonlinkratio_4                     2695.0   \n",
       "news_front_page                       1250.0   \n",
       "numberOfLinks                          702.0   \n",
       "embed_ratio                            366.0   \n",
       "linkwordscore                          101.0   \n",
       "numwords_in_url                         23.0   \n",
       "alchemy_category                        14.0   \n",
       "hasDomainLink                            2.0   \n",
       "lengthyLinkDomain                        2.0   \n",
       "label                                    2.0   \n",
       "framebased                               1.0   \n",
       "\n",
       "                                                                          example  \\\n",
       "url                             http://www.bloomberg.com/news/2010-12-23/ibm-p...   \n",
       "urlid                                                                        4042   \n",
       "boilerplate                     {\"title\":\"IBM Sees Holographic Calls Air Breat...   \n",
       "html_ratio                                                               0.245831   \n",
       "alchemy_category_score                                                   0.789131   \n",
       "compression_ratio                                                        0.443783   \n",
       "frameTagRatio                                                           0.0907738   \n",
       "avglinksize                                                               2.05556   \n",
       "image_ratio                                                            0.00388349   \n",
       "non_markup_alphanum_characters                                               5424   \n",
       "commonlinkratio_1                                                        0.676471   \n",
       "spelling_errors_ratio                                                   0.0791296   \n",
       "commonlinkratio_2                                                        0.205882   \n",
       "parametrizedLinkRatio                                                    0.152941   \n",
       "commonlinkratio_3                                                       0.0470588   \n",
       "is_news                                                                         1   \n",
       "commonlinkratio_4                                                       0.0235294   \n",
       "news_front_page                                                                 0   \n",
       "numberOfLinks                                                                 170   \n",
       "embed_ratio                                                                     0   \n",
       "linkwordscore                                                                  24   \n",
       "numwords_in_url                                                                 8   \n",
       "alchemy_category                                                         business   \n",
       "hasDomainLink                                                                   0   \n",
       "lengthyLinkDomain                                                               1   \n",
       "label                                                                           0   \n",
       "framebased                                                                      0   \n",
       "\n",
       "                                   types  \n",
       "url                               string  \n",
       "urlid                            integer  \n",
       "boilerplate                       string  \n",
       "html_ratio                      floating  \n",
       "alchemy_category_score          floating  \n",
       "compression_ratio               floating  \n",
       "frameTagRatio                   floating  \n",
       "avglinksize                     floating  \n",
       "image_ratio                     floating  \n",
       "non_markup_alphanum_characters   integer  \n",
       "commonlinkratio_1               floating  \n",
       "spelling_errors_ratio           floating  \n",
       "commonlinkratio_2               floating  \n",
       "parametrizedLinkRatio           floating  \n",
       "commonlinkratio_3               floating  \n",
       "is_news                         floating  \n",
       "commonlinkratio_4               floating  \n",
       "news_front_page                 floating  \n",
       "numberOfLinks                    integer  \n",
       "embed_ratio                     floating  \n",
       "linkwordscore                    integer  \n",
       "numwords_in_url                  integer  \n",
       "alchemy_category                   mixed  \n",
       "hasDomainLink                    integer  \n",
       "lengthyLinkDomain                integer  \n",
       "label                            integer  \n",
       "framebased                       integer  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_a = \"unique_count\"\n",
    "col_b = \"example\"\n",
    "col_c = \"types\"\n",
    "\n",
    "dataDict = pd.DataFrame()\n",
    "\n",
    "for i,x in enumerate(b): #unique counts dataframe\n",
    "    dataDict.ix[x, col_a] = b.ix[0,x] #counts\n",
    "    dataDict.ix[x, col_b] = su.ix[0,x] #original\n",
    "    dataDict.ix[x, col_c] = sutypes.ix[x,0]\n",
    "    #print x\n",
    "dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    4552\n",
      "Name: is_news, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print su_sub['is_news'].value_counts() #Value counts with low values can drop this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    5853\n",
      "1.0     294\n",
      "Name: news_front_page, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print su_sub['news_front_page'].value_counts() #Value counts with low values can drop this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    4883\n",
      "0    2512\n",
      "Name: lengthyLinkDomain, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print su_sub['lengthyLinkDomain'].value_counts() #Value counts with low values can drop this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>embed_ratio</th>\n",
       "      <th>frameTagRatio</th>\n",
       "      <th>...</th>\n",
       "      <th>image_ratio</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.443783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>3.677966</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>0.468649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088652</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4973</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>health</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>2.382883</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>0.525448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120536</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2240</td>\n",
       "      <td>258</td>\n",
       "      <td>11</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.057613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health</td>\n",
       "      <td>0.801248</td>\n",
       "      <td>1.543103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035343</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2737</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.719157</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.446143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050473</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12032</td>\n",
       "      <td>162</td>\n",
       "      <td>10</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.434639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038636</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4368</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.087356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.221110</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.215054</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.579596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1287</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>0.719697</td>\n",
       "      <td>0.265152</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.499348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27656</td>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.148551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>0.190722</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021705</td>\n",
       "      <td>...</td>\n",
       "      <td>1.136646</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2471</td>\n",
       "      <td>194</td>\n",
       "      <td>7</td>\n",
       "      <td>0.644330</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.410112</td>\n",
       "      <td>0.469325</td>\n",
       "      <td>0.101227</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.465859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206262</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11459</td>\n",
       "      <td>326</td>\n",
       "      <td>4</td>\n",
       "      <td>0.236196</td>\n",
       "      <td>0.094412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>business</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>2.506527</td>\n",
       "      <td>0.637755</td>\n",
       "      <td>0.293367</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.048469</td>\n",
       "      <td>0.592322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4401</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.073684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.891560</td>\n",
       "      <td>4.986111</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.521064</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.162690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2701</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>health</td>\n",
       "      <td>0.872323</td>\n",
       "      <td>3.056911</td>\n",
       "      <td>0.595588</td>\n",
       "      <td>0.227941</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.573109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084112</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>136</td>\n",
       "      <td>9</td>\n",
       "      <td>0.169118</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4091</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.559991</td>\n",
       "      <td>2.299492</td>\n",
       "      <td>0.547414</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.473965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3610</td>\n",
       "      <td>232</td>\n",
       "      <td>11</td>\n",
       "      <td>0.215517</td>\n",
       "      <td>0.080205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.548963</td>\n",
       "      <td>0.990431</td>\n",
       "      <td>0.522523</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>883</td>\n",
       "      <td>222</td>\n",
       "      <td>4</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.598149</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.772920</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>852</td>\n",
       "      <td>95</td>\n",
       "      <td>8</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.139738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.287884</td>\n",
       "      <td>3.164384</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.149425</td>\n",
       "      <td>0.520415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3509</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.090580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>health</td>\n",
       "      <td>0.585389</td>\n",
       "      <td>2.826772</td>\n",
       "      <td>0.669065</td>\n",
       "      <td>0.237410</td>\n",
       "      <td>0.064748</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.562795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1511</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>0.165468</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alchemy_category  alchemy_category_score  avglinksize  \\\n",
       "0             business                0.789131     2.055556   \n",
       "1           recreation                0.574147     3.677966   \n",
       "2               health                0.996526     2.382883   \n",
       "3               health                0.801248     1.543103   \n",
       "4               sports                0.719157     2.676471   \n",
       "5                  NaN                     NaN   119.000000   \n",
       "6   arts_entertainment                0.221110     0.773810   \n",
       "7                  NaN                     NaN     1.883333   \n",
       "8                  NaN                     NaN     0.471503   \n",
       "9                  NaN                     NaN     2.410112   \n",
       "10            business                0.816604     2.506527   \n",
       "11              sports                0.891560     4.986111   \n",
       "12              health                0.872323     3.056911   \n",
       "13                 NaN                     NaN     0.000000   \n",
       "14          recreation                0.559991     2.299492   \n",
       "15          recreation                0.548963     0.990431   \n",
       "16          recreation                0.598149     0.929825   \n",
       "17  arts_entertainment                0.772920     2.083333   \n",
       "18          recreation                0.287884     3.164384   \n",
       "19              health                0.585389     2.826772   \n",
       "\n",
       "    commonlinkratio_1  commonlinkratio_2  commonlinkratio_3  \\\n",
       "0            0.676471           0.205882           0.047059   \n",
       "1            0.508021           0.288770           0.213904   \n",
       "2            0.562016           0.321705           0.120155   \n",
       "3            0.400000           0.100000           0.016667   \n",
       "4            0.500000           0.222222           0.123457   \n",
       "5            0.745455           0.581818           0.290909   \n",
       "6            0.215054           0.053763           0.043011   \n",
       "7            0.719697           0.265152           0.113636   \n",
       "8            0.190722           0.036082           0.000000   \n",
       "9            0.469325           0.101227           0.018405   \n",
       "10           0.637755           0.293367           0.091837   \n",
       "11           0.640000           0.426667           0.320000   \n",
       "12           0.595588           0.227941           0.044118   \n",
       "13           0.000000           0.000000           0.000000   \n",
       "14           0.547414           0.206897           0.056034   \n",
       "15           0.522523           0.108108           0.009009   \n",
       "16           0.068966           0.000000           0.000000   \n",
       "17           0.421053           0.178947           0.042105   \n",
       "18           0.586207           0.275862           0.172414   \n",
       "19           0.669065           0.237410           0.064748   \n",
       "\n",
       "    commonlinkratio_4  compression_ratio  embed_ratio  frameTagRatio  ...    \\\n",
       "0            0.023529           0.443783     0.000000       0.090774  ...     \n",
       "1            0.144385           0.468649     0.000000       0.098707  ...     \n",
       "2            0.042636           0.525448     0.000000       0.072448  ...     \n",
       "3            0.000000           0.480725     0.000000       0.095861  ...     \n",
       "4            0.043210           0.446143     0.000000       0.024908  ...     \n",
       "5            0.018182           0.434639     0.000000       0.019841  ...     \n",
       "6            0.043011           0.579596     0.000000       0.039568  ...     \n",
       "7            0.015152           0.499348     0.000000       0.026616  ...     \n",
       "8            0.000000           0.383199     0.000000       0.021705  ...     \n",
       "9            0.003067           0.465859     0.000000       0.012000  ...     \n",
       "10           0.048469           0.592322     0.000000       0.056497  ...     \n",
       "11           0.293333           0.521064     0.004065       0.162690  ...     \n",
       "12           0.014706           0.573109     0.000000       0.074576  ...     \n",
       "13           0.000000          21.000000    -1.000000       0.057692  ...     \n",
       "14           0.017241           0.473965     0.000000       0.078431  ...     \n",
       "15           0.000000           0.414155     0.000000       0.054993  ...     \n",
       "16           0.000000           0.478355     0.000000       0.157576  ...     \n",
       "17           0.000000           0.462995     0.000000       0.099778  ...     \n",
       "18           0.149425           0.520415     0.000000       0.035865  ...     \n",
       "19           0.021583           0.562795     0.000000       0.073456  ...     \n",
       "\n",
       "    image_ratio  lengthyLinkDomain  linkwordscore  news_front_page  \\\n",
       "0      0.003883                  1             24              0.0   \n",
       "1      0.088652                  1             40              0.0   \n",
       "2      0.120536                  1             55              0.0   \n",
       "3      0.035343                  0             24              0.0   \n",
       "4      0.050473                  1             14              0.0   \n",
       "5      0.038636                  0             12              NaN   \n",
       "6      0.311377                  0             21              0.0   \n",
       "7      0.025830                  0              5              NaN   \n",
       "8      1.136646                  0             17              0.0   \n",
       "9      0.206262                  1             14              NaN   \n",
       "10     0.511364                  1             53              0.0   \n",
       "11     0.060976                  1             40              0.0   \n",
       "12     0.084112                  1             64              0.0   \n",
       "13    -1.000000                  0              0              0.0   \n",
       "14     0.036424                  1             37              0.0   \n",
       "15     0.075630                  0             54              0.0   \n",
       "16     0.276316                  0             50              0.0   \n",
       "17     0.275862                  0             49              0.0   \n",
       "18     0.091549                  1             23              0.0   \n",
       "19     0.053254                  1             55              0.0   \n",
       "\n",
       "    non_markup_alphanum_characters  numberOfLinks  numwords_in_url  \\\n",
       "0                             5424            170                8   \n",
       "1                             4973            187                9   \n",
       "2                             2240            258               11   \n",
       "3                             2737            120                5   \n",
       "4                            12032            162               10   \n",
       "5                             4368             55                3   \n",
       "6                             1287             93                3   \n",
       "7                            27656            132                4   \n",
       "8                             2471            194                7   \n",
       "9                            11459            326                4   \n",
       "10                            4401            392                0   \n",
       "11                            2701             75                8   \n",
       "12                            1062            136                9   \n",
       "13                            4091              5               11   \n",
       "14                            3610            232               11   \n",
       "15                             883            222                4   \n",
       "16                             268             58                2   \n",
       "17                             852             95                8   \n",
       "18                            3509             87                2   \n",
       "19                            1511            139                9   \n",
       "\n",
       "    parametrizedLinkRatio  spelling_errors_ratio  label  \n",
       "0                0.152941               0.079130      0  \n",
       "1                0.181818               0.125448      1  \n",
       "2                0.166667               0.057613      1  \n",
       "3                0.041667               0.100858      1  \n",
       "4                0.098765               0.082569      0  \n",
       "5                0.054545               0.087356      0  \n",
       "6                0.548387               0.064327      1  \n",
       "7                0.068182               0.148551      0  \n",
       "8                0.644330               0.125000      1  \n",
       "9                0.236196               0.094412      1  \n",
       "10               0.160714               0.073684      0  \n",
       "11               0.186667               0.115385      0  \n",
       "12               0.169118               0.180328      1  \n",
       "13               0.000000               0.083333      1  \n",
       "14               0.215517               0.080205      0  \n",
       "15               0.013514               0.059603      0  \n",
       "16               0.137931               0.107143      0  \n",
       "17               0.305263               0.139738      0  \n",
       "18               0.402299               0.090580      1  \n",
       "19               0.165468               0.065217      1  \n",
       "\n",
       "[20 rows x 22 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "su_sub = su_sub.drop(['url','boilerplate','framebased','is_news'], axis=1) #drop columns for url and boilerplate\n",
    "su_sub = su_sub.drop(['urlid'], axis=1) #will drop urlid as well, for Categorization\n",
    "su_sub.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alchemy_category                  2342\n",
      "alchemy_category_score            2342\n",
      "avglinksize                          0\n",
      "commonlinkratio_1                    0\n",
      "commonlinkratio_2                    0\n",
      "commonlinkratio_3                    0\n",
      "commonlinkratio_4                    0\n",
      "compression_ratio                    0\n",
      "embed_ratio                          0\n",
      "frameTagRatio                        0\n",
      "hasDomainLink                        0\n",
      "html_ratio                           0\n",
      "image_ratio                          0\n",
      "lengthyLinkDomain                    0\n",
      "linkwordscore                        0\n",
      "news_front_page                   1248\n",
      "non_markup_alphanum_characters       0\n",
      "numberOfLinks                        0\n",
      "numwords_in_url                      0\n",
      "parametrizedLinkRatio                0\n",
      "spelling_errors_ratio                0\n",
      "label                                0\n",
      "dtype: int64\n",
      "(7395, 22)\n",
      "(7395, 19)\n",
      "alchemy_category                  0\n",
      "alchemy_category_score            0\n",
      "avglinksize                       0\n",
      "commonlinkratio_1                 0\n",
      "commonlinkratio_2                 0\n",
      "commonlinkratio_3                 0\n",
      "commonlinkratio_4                 0\n",
      "compression_ratio                 0\n",
      "embed_ratio                       0\n",
      "frameTagRatio                     0\n",
      "hasDomainLink                     0\n",
      "html_ratio                        0\n",
      "image_ratio                       0\n",
      "lengthyLinkDomain                 0\n",
      "linkwordscore                     0\n",
      "news_front_page                   0\n",
      "non_markup_alphanum_characters    0\n",
      "numberOfLinks                     0\n",
      "numwords_in_url                   0\n",
      "parametrizedLinkRatio             0\n",
      "spelling_errors_ratio             0\n",
      "label                             0\n",
      "dtype: int64\n",
      "(4824, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>embed_ratio</th>\n",
       "      <th>frameTagRatio</th>\n",
       "      <th>...</th>\n",
       "      <th>image_ratio</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.443783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>3.677966</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>0.468649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088652</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4973</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>health</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>2.382883</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>0.525448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120536</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2240</td>\n",
       "      <td>258</td>\n",
       "      <td>11</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.057613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health</td>\n",
       "      <td>0.801248</td>\n",
       "      <td>1.543103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035343</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2737</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.719157</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.446143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050473</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12032</td>\n",
       "      <td>162</td>\n",
       "      <td>10</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.221110</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.215054</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.579596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1287</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>business</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>2.506527</td>\n",
       "      <td>0.637755</td>\n",
       "      <td>0.293367</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.048469</td>\n",
       "      <td>0.592322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4401</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.073684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.891560</td>\n",
       "      <td>4.986111</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.521064</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.162690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2701</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>health</td>\n",
       "      <td>0.872323</td>\n",
       "      <td>3.056911</td>\n",
       "      <td>0.595588</td>\n",
       "      <td>0.227941</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.573109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084112</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>136</td>\n",
       "      <td>9</td>\n",
       "      <td>0.169118</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.559991</td>\n",
       "      <td>2.299492</td>\n",
       "      <td>0.547414</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.473965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3610</td>\n",
       "      <td>232</td>\n",
       "      <td>11</td>\n",
       "      <td>0.215517</td>\n",
       "      <td>0.080205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.548963</td>\n",
       "      <td>0.990431</td>\n",
       "      <td>0.522523</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>883</td>\n",
       "      <td>222</td>\n",
       "      <td>4</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.598149</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.772920</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>852</td>\n",
       "      <td>95</td>\n",
       "      <td>8</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.139738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.287884</td>\n",
       "      <td>3.164384</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.149425</td>\n",
       "      <td>0.520415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3509</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.090580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>health</td>\n",
       "      <td>0.585389</td>\n",
       "      <td>2.826772</td>\n",
       "      <td>0.669065</td>\n",
       "      <td>0.237410</td>\n",
       "      <td>0.064748</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.562795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1511</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>0.165468</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.941129</td>\n",
       "      <td>4.103627</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>0.297778</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.412429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693182</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3243</td>\n",
       "      <td>225</td>\n",
       "      <td>6</td>\n",
       "      <td>0.208889</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.437599</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.172043</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1927</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>health</td>\n",
       "      <td>0.644872</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.468310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062963</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1766</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.084175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.898192</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.173210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1802</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.348995</td>\n",
       "      <td>3.355263</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.573826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>business</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>3.321429</td>\n",
       "      <td>0.505747</td>\n",
       "      <td>0.298851</td>\n",
       "      <td>0.183908</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.421386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67406</td>\n",
       "      <td>87</td>\n",
       "      <td>7</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.097297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.289158</td>\n",
       "      <td>1.985816</td>\n",
       "      <td>0.356643</td>\n",
       "      <td>0.139860</td>\n",
       "      <td>0.055944</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.571006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9935</td>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.198413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.670358</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.451327</td>\n",
       "      <td>0.168142</td>\n",
       "      <td>0.106195</td>\n",
       "      <td>0.053097</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087824</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5500</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>0.159292</td>\n",
       "      <td>0.086066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>business</td>\n",
       "      <td>0.899731</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.207182</td>\n",
       "      <td>0.074586</td>\n",
       "      <td>0.030387</td>\n",
       "      <td>0.828025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027661</td>\n",
       "      <td>...</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4809</td>\n",
       "      <td>362</td>\n",
       "      <td>6</td>\n",
       "      <td>0.472376</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.783732</td>\n",
       "      <td>2.544041</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.324074</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.514042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270073</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3225</td>\n",
       "      <td>216</td>\n",
       "      <td>16</td>\n",
       "      <td>0.189815</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>1.549451</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.114428</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.569044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183206</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2382</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>science_technology</td>\n",
       "      <td>0.849952</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.439757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7456</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.089825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.487492</td>\n",
       "      <td>2.086957</td>\n",
       "      <td>0.498195</td>\n",
       "      <td>0.202166</td>\n",
       "      <td>0.028881</td>\n",
       "      <td>0.021661</td>\n",
       "      <td>0.510095</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100410</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8366</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523466</td>\n",
       "      <td>0.124726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>health</td>\n",
       "      <td>0.802314</td>\n",
       "      <td>1.783333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9309</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.504924</td>\n",
       "      <td>2.443983</td>\n",
       "      <td>0.365517</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.072414</td>\n",
       "      <td>0.055172</td>\n",
       "      <td>0.464775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1078</td>\n",
       "      <td>290</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117241</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>science_technology</td>\n",
       "      <td>0.260166</td>\n",
       "      <td>1.345794</td>\n",
       "      <td>0.360308</td>\n",
       "      <td>0.225434</td>\n",
       "      <td>0.181118</td>\n",
       "      <td>0.169557</td>\n",
       "      <td>0.480171</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.026647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330370</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16092</td>\n",
       "      <td>519</td>\n",
       "      <td>2</td>\n",
       "      <td>0.487476</td>\n",
       "      <td>0.096063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>science_technology</td>\n",
       "      <td>0.701326</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1589</td>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7352</th>\n",
       "      <td>science_technology</td>\n",
       "      <td>0.224411</td>\n",
       "      <td>2.198630</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.227891</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.451460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140371</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11923</td>\n",
       "      <td>294</td>\n",
       "      <td>4</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.094268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.479485</td>\n",
       "      <td>3.627907</td>\n",
       "      <td>0.987597</td>\n",
       "      <td>0.973643</td>\n",
       "      <td>0.903876</td>\n",
       "      <td>0.494574</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>972</td>\n",
       "      <td>645</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012403</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7354</th>\n",
       "      <td>religion</td>\n",
       "      <td>0.777470</td>\n",
       "      <td>1.965174</td>\n",
       "      <td>0.556604</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.033019</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.541991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284519</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1745</td>\n",
       "      <td>212</td>\n",
       "      <td>4</td>\n",
       "      <td>0.457547</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7355</th>\n",
       "      <td>business</td>\n",
       "      <td>0.852631</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7358</th>\n",
       "      <td>health</td>\n",
       "      <td>0.542932</td>\n",
       "      <td>4.993827</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.368132</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.391150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29708</td>\n",
       "      <td>182</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.091247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7359</th>\n",
       "      <td>health</td>\n",
       "      <td>0.613426</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.459227</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.090592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015106</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2775</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.065672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7360</th>\n",
       "      <td>religion</td>\n",
       "      <td>0.846979</td>\n",
       "      <td>2.097561</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>0.133858</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013223</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5801</td>\n",
       "      <td>127</td>\n",
       "      <td>8</td>\n",
       "      <td>0.070866</td>\n",
       "      <td>0.125637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7362</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.521839</td>\n",
       "      <td>1.765432</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.132530</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.498446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1618</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.127946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7364</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.556059</td>\n",
       "      <td>1.476190</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3668</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.079223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7370</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.749882</td>\n",
       "      <td>1.677966</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>826</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>computer_internet</td>\n",
       "      <td>0.393665</td>\n",
       "      <td>1.168367</td>\n",
       "      <td>0.627551</td>\n",
       "      <td>0.301020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172535</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1953</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.080537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7373</th>\n",
       "      <td>science_technology</td>\n",
       "      <td>0.700190</td>\n",
       "      <td>2.085774</td>\n",
       "      <td>0.747390</td>\n",
       "      <td>0.488518</td>\n",
       "      <td>0.146138</td>\n",
       "      <td>0.050104</td>\n",
       "      <td>0.382163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14627</td>\n",
       "      <td>479</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.882445</td>\n",
       "      <td>2.093333</td>\n",
       "      <td>0.349057</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>964</td>\n",
       "      <td>106</td>\n",
       "      <td>8</td>\n",
       "      <td>0.349057</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7375</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.483953</td>\n",
       "      <td>1.978495</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.308511</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.463504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043829</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4744</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.098644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.332504</td>\n",
       "      <td>7.392157</td>\n",
       "      <td>0.743421</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>0.269737</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.465021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026966</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3331</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.076577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7377</th>\n",
       "      <td>computer_internet</td>\n",
       "      <td>0.949532</td>\n",
       "      <td>1.861789</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.447591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112288</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2896</td>\n",
       "      <td>144</td>\n",
       "      <td>13</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.077869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.648793</td>\n",
       "      <td>2.488753</td>\n",
       "      <td>0.791583</td>\n",
       "      <td>0.509018</td>\n",
       "      <td>0.178357</td>\n",
       "      <td>0.044088</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2234</td>\n",
       "      <td>499</td>\n",
       "      <td>6</td>\n",
       "      <td>0.150301</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7379</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.657172</td>\n",
       "      <td>2.373134</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.236111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.474796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3178</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.104046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7381</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.223110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.607059</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7382</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.395289</td>\n",
       "      <td>5.611570</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.528037</td>\n",
       "      <td>0.490654</td>\n",
       "      <td>0.469481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15829</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7383</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.307736</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386</th>\n",
       "      <td>culture_politics</td>\n",
       "      <td>0.832741</td>\n",
       "      <td>3.156863</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.313043</td>\n",
       "      <td>0.113043</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>0.259315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12714</td>\n",
       "      <td>115</td>\n",
       "      <td>9</td>\n",
       "      <td>0.113043</td>\n",
       "      <td>0.022329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.316930</td>\n",
       "      <td>1.753731</td>\n",
       "      <td>0.510791</td>\n",
       "      <td>0.251799</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>964</td>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>0.158273</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.679419</td>\n",
       "      <td>1.995098</td>\n",
       "      <td>0.539535</td>\n",
       "      <td>0.213953</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>0.548148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1819</td>\n",
       "      <td>215</td>\n",
       "      <td>5</td>\n",
       "      <td>0.455814</td>\n",
       "      <td>0.070632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>computer_internet</td>\n",
       "      <td>0.651067</td>\n",
       "      <td>3.010526</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.474273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2219</td>\n",
       "      <td>99</td>\n",
       "      <td>11</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>culture_politics</td>\n",
       "      <td>0.141920</td>\n",
       "      <td>2.208054</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.558184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225962</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5672</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7392</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.196273</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.692529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>848</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.617876</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>386</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4824 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        alchemy_category  alchemy_category_score  avglinksize  \\\n",
       "0               business                0.789131     2.055556   \n",
       "1             recreation                0.574147     3.677966   \n",
       "2                 health                0.996526     2.382883   \n",
       "3                 health                0.801248     1.543103   \n",
       "4                 sports                0.719157     2.676471   \n",
       "6     arts_entertainment                0.221110     0.773810   \n",
       "10              business                0.816604     2.506527   \n",
       "11                sports                0.891560     4.986111   \n",
       "12                health                0.872323     3.056911   \n",
       "14            recreation                0.559991     2.299492   \n",
       "15            recreation                0.548963     0.990431   \n",
       "16            recreation                0.598149     0.929825   \n",
       "17    arts_entertainment                0.772920     2.083333   \n",
       "18            recreation                0.287884     3.164384   \n",
       "19                health                0.585389     2.826772   \n",
       "20                sports                0.941129     4.103627   \n",
       "21            recreation                0.437599     2.033333   \n",
       "22                health                0.644872     1.333333   \n",
       "25                sports                0.898192     4.800000   \n",
       "26                sports                0.348995     3.355263   \n",
       "27              business                0.850000     3.321429   \n",
       "30            recreation                0.289158     1.985816   \n",
       "31            recreation                0.670358     1.571429   \n",
       "33              business                0.899731     2.166667   \n",
       "34            recreation                0.783732     2.544041   \n",
       "37    arts_entertainment                0.519337     1.549451   \n",
       "40    science_technology                0.849952     9.800000   \n",
       "41            recreation                0.487492     2.086957   \n",
       "43                health                0.802314     1.783333   \n",
       "45                sports                0.504924     2.443983   \n",
       "...                  ...                     ...          ...   \n",
       "7349  science_technology                0.260166     1.345794   \n",
       "7351  science_technology                0.701326     1.200000   \n",
       "7352  science_technology                0.224411     2.198630   \n",
       "7353          recreation                0.479485     3.627907   \n",
       "7354            religion                0.777470     1.965174   \n",
       "7355            business                0.852631     1.840000   \n",
       "7358              health                0.542932     4.993827   \n",
       "7359              health                0.613426     2.260000   \n",
       "7360            religion                0.846979     2.097561   \n",
       "7362  arts_entertainment                0.521839     1.765432   \n",
       "7364          recreation                0.556059     1.476190   \n",
       "7370          recreation                0.749882     1.677966   \n",
       "7372   computer_internet                0.393665     1.168367   \n",
       "7373  science_technology                0.700190     2.085774   \n",
       "7374  arts_entertainment                0.882445     2.093333   \n",
       "7375          recreation                0.483953     1.978495   \n",
       "7376          recreation                0.332504     7.392157   \n",
       "7377   computer_internet                0.949532     1.861789   \n",
       "7378          recreation                0.648793     2.488753   \n",
       "7379  arts_entertainment                0.657172     2.373134   \n",
       "7381          recreation                0.223110     1.000000   \n",
       "7382          recreation                0.395289     5.611570   \n",
       "7383          recreation                0.307736     1.687500   \n",
       "7386    culture_politics                0.832741     3.156863   \n",
       "7387  arts_entertainment                0.316930     1.753731   \n",
       "7388          recreation                0.679419     1.995098   \n",
       "7390   computer_internet                0.651067     3.010526   \n",
       "7391    culture_politics                0.141920     2.208054   \n",
       "7392          recreation                0.196273     2.000000   \n",
       "7393  arts_entertainment                0.617876     1.026316   \n",
       "\n",
       "      commonlinkratio_1  commonlinkratio_2  commonlinkratio_3  \\\n",
       "0              0.676471           0.205882           0.047059   \n",
       "1              0.508021           0.288770           0.213904   \n",
       "2              0.562016           0.321705           0.120155   \n",
       "3              0.400000           0.100000           0.016667   \n",
       "4              0.500000           0.222222           0.123457   \n",
       "6              0.215054           0.053763           0.043011   \n",
       "10             0.637755           0.293367           0.091837   \n",
       "11             0.640000           0.426667           0.320000   \n",
       "12             0.595588           0.227941           0.044118   \n",
       "14             0.547414           0.206897           0.056034   \n",
       "15             0.522523           0.108108           0.009009   \n",
       "16             0.068966           0.000000           0.000000   \n",
       "17             0.421053           0.178947           0.042105   \n",
       "18             0.586207           0.275862           0.172414   \n",
       "19             0.669065           0.237410           0.064748   \n",
       "20             0.515556           0.297778           0.186667   \n",
       "21             0.516129           0.172043           0.043011   \n",
       "22             0.000000           0.000000           0.000000   \n",
       "25             0.603448           0.379310           0.241379   \n",
       "26             0.488372           0.290698           0.081395   \n",
       "27             0.505747           0.298851           0.183908   \n",
       "30             0.356643           0.139860           0.055944   \n",
       "31             0.451327           0.168142           0.106195   \n",
       "33             0.447514           0.207182           0.074586   \n",
       "34             0.583333           0.324074           0.129630   \n",
       "37             0.417910           0.114428           0.004975   \n",
       "40             0.292308           0.092308           0.015385   \n",
       "41             0.498195           0.202166           0.028881   \n",
       "43             0.214286           0.071429           0.014286   \n",
       "45             0.365517           0.200000           0.072414   \n",
       "...                 ...                ...                ...   \n",
       "7349           0.360308           0.225434           0.181118   \n",
       "7351           0.091667           0.008333           0.000000   \n",
       "7352           0.693878           0.340136           0.227891   \n",
       "7353           0.987597           0.973643           0.903876   \n",
       "7354           0.556604           0.226415           0.033019   \n",
       "7355           0.484848           0.060606           0.000000   \n",
       "7358           0.802198           0.670330           0.368132   \n",
       "7359           0.448276           0.068966           0.068966   \n",
       "7360           0.370079           0.133858           0.039370   \n",
       "7362           0.602410           0.132530           0.012048   \n",
       "7364           0.366197           0.098592           0.014085   \n",
       "7370           0.256757           0.135135           0.000000   \n",
       "7372           0.627551           0.301020           0.000000   \n",
       "7373           0.747390           0.488518           0.146138   \n",
       "7374           0.349057           0.150943           0.037736   \n",
       "7375           0.510638           0.308511           0.148936   \n",
       "7376           0.743421           0.460526           0.269737   \n",
       "7377           0.347222           0.104167           0.055556   \n",
       "7378           0.791583           0.509018           0.178357   \n",
       "7379           0.375000           0.277778           0.236111   \n",
       "7381           0.000000           0.000000           0.000000   \n",
       "7382           0.738318           0.579439           0.528037   \n",
       "7383           0.531250           0.062500           0.062500   \n",
       "7386           0.669565           0.313043           0.113043   \n",
       "7387           0.510791           0.251799           0.043165   \n",
       "7388           0.539535           0.213953           0.018605   \n",
       "7390           0.474747           0.222222           0.191919   \n",
       "7391           0.483333           0.246667           0.036667   \n",
       "7392           0.315789           0.171053           0.105263   \n",
       "7393           0.210526           0.052632           0.000000   \n",
       "\n",
       "      commonlinkratio_4  compression_ratio  embed_ratio  frameTagRatio  ...    \\\n",
       "0              0.023529           0.443783     0.000000       0.090774  ...     \n",
       "1              0.144385           0.468649     0.000000       0.098707  ...     \n",
       "2              0.042636           0.525448     0.000000       0.072448  ...     \n",
       "3              0.000000           0.480725     0.000000       0.095861  ...     \n",
       "4              0.043210           0.446143     0.000000       0.024908  ...     \n",
       "6              0.043011           0.579596     0.000000       0.039568  ...     \n",
       "10             0.048469           0.592322     0.000000       0.056497  ...     \n",
       "11             0.293333           0.521064     0.004065       0.162690  ...     \n",
       "12             0.014706           0.573109     0.000000       0.074576  ...     \n",
       "14             0.017241           0.473965     0.000000       0.078431  ...     \n",
       "15             0.000000           0.414155     0.000000       0.054993  ...     \n",
       "16             0.000000           0.478355     0.000000       0.157576  ...     \n",
       "17             0.000000           0.462995     0.000000       0.099778  ...     \n",
       "18             0.149425           0.520415     0.000000       0.035865  ...     \n",
       "19             0.021583           0.562795     0.000000       0.073456  ...     \n",
       "20             0.106667           0.412429     0.000000       0.064489  ...     \n",
       "21             0.000000           0.909836     0.000000       0.105578  ...     \n",
       "22             0.000000           0.468310     0.000000       0.041262  ...     \n",
       "25             0.155172           0.480519     0.010638       0.173210  ...     \n",
       "26             0.023256           0.573826     0.000000       0.007968  ...     \n",
       "27             0.137931           0.421386     0.000000       0.004970  ...     \n",
       "30             0.027972           0.571006     0.000000       0.027027  ...     \n",
       "31             0.053097           0.437500     0.000000       0.055215  ...     \n",
       "33             0.030387           0.828025     0.000000       0.027661  ...     \n",
       "34             0.037037           0.514042     0.000000       0.082569  ...     \n",
       "37             0.004975           0.569044     0.000000       0.040764  ...     \n",
       "40             0.000000           0.439757     0.000000       0.058228  ...     \n",
       "41             0.021661           0.510095     0.002049       0.008850  ...     \n",
       "43             0.000000           0.445471     0.000000       0.070117  ...     \n",
       "45             0.055172           0.464775     0.000000       0.022196  ...     \n",
       "...                 ...                ...          ...            ...  ...     \n",
       "7349           0.169557           0.480171     0.001481       0.026647  ...     \n",
       "7351           0.000000           0.427184     0.000000       0.084437  ...     \n",
       "7352           0.204082           0.451460     0.000000       0.027009  ...     \n",
       "7353           0.494574           0.705882     0.000000       0.003574  ...     \n",
       "7354           0.028302           0.541991     0.000000       0.041045  ...     \n",
       "7355           0.000000           0.485164     0.000000       0.121429  ...     \n",
       "7358           0.274725           0.391150     0.000000       0.009009  ...     \n",
       "7359           0.034483           0.459227     0.003021       0.090592  ...     \n",
       "7360           0.000000           0.493393     0.000000       0.062635  ...     \n",
       "7362           0.000000           0.498446     0.000000       0.061224  ...     \n",
       "7364           0.000000           0.414183     0.000000       0.056604  ...     \n",
       "7370           0.000000           0.737201     0.000000       0.031320  ...     \n",
       "7372           0.000000           0.524778     0.000000       0.106931  ...     \n",
       "7373           0.050104           0.382163     0.000000       0.039698  ...     \n",
       "7374           0.000000           0.518707     0.000000       0.091463  ...     \n",
       "7375           0.042553           0.463504     0.000000       0.040984  ...     \n",
       "7376           0.013158           0.465021     0.000000       0.023499  ...     \n",
       "7377           0.027778           0.447591     0.000000       0.045706  ...     \n",
       "7378           0.044088           0.609756     0.000000       0.022850  ...     \n",
       "7379           0.222222           0.474796     0.000000       0.046563  ...     \n",
       "7381           0.000000           0.607059     0.019231       0.054795  ...     \n",
       "7382           0.490654           0.469481     0.000000       0.020336  ...     \n",
       "7383           0.062500          21.000000    -1.000000       0.103896  ...     \n",
       "7386           0.034783           0.259315     0.000000       0.044103  ...     \n",
       "7387           0.000000           0.639198     0.000000       0.048733  ...     \n",
       "7388           0.018605           0.548148     0.000000       0.040293  ...     \n",
       "7390           0.191919           0.474273     0.000000       0.177043  ...     \n",
       "7391           0.026667           0.558184     0.000000       0.057377  ...     \n",
       "7392           0.052632           0.692529     0.000000       0.124122  ...     \n",
       "7393           0.000000          21.000000    -1.000000       0.097778  ...     \n",
       "\n",
       "      image_ratio  lengthyLinkDomain  linkwordscore  news_front_page  \\\n",
       "0        0.003883                  1             24              0.0   \n",
       "1        0.088652                  1             40              0.0   \n",
       "2        0.120536                  1             55              0.0   \n",
       "3        0.035343                  0             24              0.0   \n",
       "4        0.050473                  1             14              0.0   \n",
       "6        0.311377                  0             21              0.0   \n",
       "10       0.511364                  1             53              0.0   \n",
       "11       0.060976                  1             40              0.0   \n",
       "12       0.084112                  1             64              0.0   \n",
       "14       0.036424                  1             37              0.0   \n",
       "15       0.075630                  0             54              0.0   \n",
       "16       0.276316                  0             50              0.0   \n",
       "17       0.275862                  0             49              0.0   \n",
       "18       0.091549                  1             23              0.0   \n",
       "19       0.053254                  1             55              0.0   \n",
       "20       0.693182                  1             53              0.0   \n",
       "21       0.863636                  1             31              0.0   \n",
       "22       0.062963                  0              3              0.0   \n",
       "25       0.085106                  1             45              0.0   \n",
       "26       0.004608                  1             98              1.0   \n",
       "27       0.004007                  1              2              0.0   \n",
       "30       0.230769                  1             11              0.0   \n",
       "31       0.087824                  1             12              0.0   \n",
       "33       3.625000                  1             35              0.0   \n",
       "34       0.270073                  1             44              0.0   \n",
       "37       0.183206                  0             37              0.0   \n",
       "40       0.012346                  0              6              0.0   \n",
       "41       0.100410                  1             22              1.0   \n",
       "43       0.314815                  1              5              0.0   \n",
       "45       0.918919                  1             76              0.0   \n",
       "...           ...                ...            ...              ...   \n",
       "7349     0.330370                  1             13              0.0   \n",
       "7351     0.317073                  1             29              0.0   \n",
       "7352     0.140371                  1             19              0.0   \n",
       "7353     0.588235                  1             93              0.0   \n",
       "7354     0.284519                  1             53              0.0   \n",
       "7355     0.035714                  0             14              0.0   \n",
       "7358     0.002358                  1             10              0.0   \n",
       "7359     0.015106                  1             16              0.0   \n",
       "7360     0.013223                  1             17              0.0   \n",
       "7362     0.026316                  0             28              0.0   \n",
       "7364     0.044118                  0             11              0.0   \n",
       "7370     0.313725                  0             36              0.0   \n",
       "7372     0.172535                  0             37              0.0   \n",
       "7373     0.006561                  1             25              1.0   \n",
       "7374     0.363636                  0             48              0.0   \n",
       "7375     0.043829                  1             15              1.0   \n",
       "7376     0.026966                  0             35              0.0   \n",
       "7377     0.112288                  1             29              0.0   \n",
       "7378     0.278689                  1             74              0.0   \n",
       "7379     0.067227                  1             21              0.0   \n",
       "7381     0.461538                  0             10              0.0   \n",
       "7382     0.023490                  1             16              0.0   \n",
       "7383    -1.000000                  0             73              0.0   \n",
       "7386     0.003122                  1             15              0.0   \n",
       "7387     0.137500                  0             53              0.0   \n",
       "7388     0.274194                  1             54              0.0   \n",
       "7390     0.048780                  1             38              0.0   \n",
       "7391     0.225962                  1             34              0.0   \n",
       "7392     0.464286                  1             43              0.0   \n",
       "7393    -1.000000                  0             37              1.0   \n",
       "\n",
       "      non_markup_alphanum_characters  numberOfLinks  numwords_in_url  \\\n",
       "0                               5424            170                8   \n",
       "1                               4973            187                9   \n",
       "2                               2240            258               11   \n",
       "3                               2737            120                5   \n",
       "4                              12032            162               10   \n",
       "6                               1287             93                3   \n",
       "10                              4401            392                0   \n",
       "11                              2701             75                8   \n",
       "12                              1062            136                9   \n",
       "14                              3610            232               11   \n",
       "15                               883            222                4   \n",
       "16                               268             58                2   \n",
       "17                               852             95                8   \n",
       "18                              3509             87                2   \n",
       "19                              1511            139                9   \n",
       "20                              3243            225                6   \n",
       "21                              1927             93                5   \n",
       "22                              1766             11                2   \n",
       "25                              1802             58                9   \n",
       "26                                21             86                0   \n",
       "27                             67406             87                7   \n",
       "30                              9935            143                2   \n",
       "31                              5500            113                4   \n",
       "33                              4809            362                6   \n",
       "34                              3225            216               16   \n",
       "37                              2382            201                1   \n",
       "40                              7456             65                1   \n",
       "41                              8366            277                0   \n",
       "43                              9309             70                8   \n",
       "45                              1078            290                2   \n",
       "...                              ...            ...              ...   \n",
       "7349                           16092            519                2   \n",
       "7351                            1589            120                9   \n",
       "7352                           11923            294                4   \n",
       "7353                             972            645                3   \n",
       "7354                            1745            212                4   \n",
       "7355                            1440             33                4   \n",
       "7358                           29708            182                3   \n",
       "7359                            2775             58               14   \n",
       "7360                            5801            127                8   \n",
       "7362                            1618             83                6   \n",
       "7364                            3668             71                3   \n",
       "7370                             826             74                4   \n",
       "7372                            1953            196               10   \n",
       "7373                           14627            479                0   \n",
       "7374                             964            106                8   \n",
       "7375                            4744             94                0   \n",
       "7376                            3331            152                0   \n",
       "7377                            2896            144               13   \n",
       "7378                            2234            499                6   \n",
       "7379                            3178             72                6   \n",
       "7381                             137             16                0   \n",
       "7382                           15829            214                3   \n",
       "7383                              90             32                1   \n",
       "7386                           12714            115                9   \n",
       "7387                             964            139                2   \n",
       "7388                            1819            215                5   \n",
       "7390                            2219             99               11   \n",
       "7391                            5672            300                4   \n",
       "7392                             848             76                5   \n",
       "7393                             386             38                0   \n",
       "\n",
       "      parametrizedLinkRatio  spelling_errors_ratio  label  \n",
       "0                  0.152941               0.079130      0  \n",
       "1                  0.181818               0.125448      1  \n",
       "2                  0.166667               0.057613      1  \n",
       "3                  0.041667               0.100858      1  \n",
       "4                  0.098765               0.082569      0  \n",
       "6                  0.548387               0.064327      1  \n",
       "10                 0.160714               0.073684      0  \n",
       "11                 0.186667               0.115385      0  \n",
       "12                 0.169118               0.180328      1  \n",
       "14                 0.215517               0.080205      0  \n",
       "15                 0.013514               0.059603      0  \n",
       "16                 0.137931               0.107143      0  \n",
       "17                 0.305263               0.139738      0  \n",
       "18                 0.402299               0.090580      1  \n",
       "19                 0.165468               0.065217      1  \n",
       "20                 0.208889               0.043860      0  \n",
       "21                 0.043011               0.078947      1  \n",
       "22                 0.090909               0.084175      0  \n",
       "25                 0.155172               0.055000      0  \n",
       "26                 0.000000               0.128440      0  \n",
       "27                 0.091954               0.097297      0  \n",
       "30                 0.027972               0.198413      1  \n",
       "31                 0.159292               0.086066      1  \n",
       "33                 0.472376               0.085106      1  \n",
       "34                 0.189815               0.039773      0  \n",
       "37                 0.014925               0.092308      0  \n",
       "40                 0.046154               0.089825      0  \n",
       "41                 0.523466               0.124726      1  \n",
       "43                 0.114286               0.061856      1  \n",
       "45                 0.117241               0.081081      0  \n",
       "...                     ...                    ...    ...  \n",
       "7349               0.487476               0.096063      1  \n",
       "7351               0.058333               0.095890      0  \n",
       "7352               0.469388               0.094268      0  \n",
       "7353               0.012403               0.040000      1  \n",
       "7354               0.457547               0.084615      1  \n",
       "7355               0.181818               0.079208      1  \n",
       "7358               0.021978               0.091247      1  \n",
       "7359               0.103448               0.065672      0  \n",
       "7360               0.070866               0.125637      1  \n",
       "7362               0.096386               0.127946      0  \n",
       "7364               0.014085               0.079223      0  \n",
       "7370               0.067568               0.049180      0  \n",
       "7372               0.045918               0.080537      0  \n",
       "7373               0.008351               0.085393      0  \n",
       "7374               0.349057               0.077586      0  \n",
       "7375               0.010638               0.098644      0  \n",
       "7376               0.013158               0.076577      1  \n",
       "7377               0.194444               0.077869      0  \n",
       "7378               0.150301               0.083333      1  \n",
       "7379               0.180556               0.104046      1  \n",
       "7381               0.000000               0.072727      0  \n",
       "7382               0.056075               0.092715      1  \n",
       "7383               0.031250               0.166667      1  \n",
       "7386               0.113043               0.022329      1  \n",
       "7387               0.158273               0.036585      1  \n",
       "7388               0.455814               0.070632      0  \n",
       "7390               0.040404               0.071429      0  \n",
       "7391               0.020000               0.109453      0  \n",
       "7392               0.434211               0.117647      1  \n",
       "7393               0.026316               0.333333      1  \n",
       "\n",
       "[4824 rows x 22 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NULLS ??? \n",
    "print su_sub.isnull().sum() #YES THERE ARE...\n",
    "print su_sub.shape\n",
    "\n",
    "#Let's group them together, before we drop nulls, so we don't drop info for other columns\n",
    "\n",
    "#GROUP A: has none of the null columns\n",
    "\n",
    "su_suba = su_sub.drop(['alchemy_category', 'alchemy_category_score','news_front_page'], axis=1)\n",
    "su_suba\n",
    "\n",
    "print su_suba.shape\n",
    "\n",
    "su_subb = su_sub.dropna()\n",
    "\n",
    "print su_subb.isnull().sum() #NO THERE AREN'T...\n",
    "print su_subb.shape\n",
    "su_subb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>embed_ratio</th>\n",
       "      <th>frameTagRatio</th>\n",
       "      <th>...</th>\n",
       "      <th>image_ratio</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.443783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>3.677966</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>0.468649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088652</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4973</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>health</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>2.382883</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>0.525448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120536</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2240</td>\n",
       "      <td>258</td>\n",
       "      <td>11</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.057613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health</td>\n",
       "      <td>0.801248</td>\n",
       "      <td>1.543103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035343</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2737</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.719157</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.446143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050473</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12032</td>\n",
       "      <td>162</td>\n",
       "      <td>10</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.221110</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.215054</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.579596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1287</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>business</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>2.506527</td>\n",
       "      <td>0.637755</td>\n",
       "      <td>0.293367</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.048469</td>\n",
       "      <td>0.592322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4401</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.073684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.891560</td>\n",
       "      <td>4.986111</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.521064</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.162690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2701</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>health</td>\n",
       "      <td>0.872323</td>\n",
       "      <td>3.056911</td>\n",
       "      <td>0.595588</td>\n",
       "      <td>0.227941</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.573109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084112</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>136</td>\n",
       "      <td>9</td>\n",
       "      <td>0.169118</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.559991</td>\n",
       "      <td>2.299492</td>\n",
       "      <td>0.547414</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.473965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3610</td>\n",
       "      <td>232</td>\n",
       "      <td>11</td>\n",
       "      <td>0.215517</td>\n",
       "      <td>0.080205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.548963</td>\n",
       "      <td>0.990431</td>\n",
       "      <td>0.522523</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>883</td>\n",
       "      <td>222</td>\n",
       "      <td>4</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.598149</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.772920</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>852</td>\n",
       "      <td>95</td>\n",
       "      <td>8</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.139738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.287884</td>\n",
       "      <td>3.164384</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.149425</td>\n",
       "      <td>0.520415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3509</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.090580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>health</td>\n",
       "      <td>0.585389</td>\n",
       "      <td>2.826772</td>\n",
       "      <td>0.669065</td>\n",
       "      <td>0.237410</td>\n",
       "      <td>0.064748</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.562795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1511</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>0.165468</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.941129</td>\n",
       "      <td>4.103627</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>0.297778</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.412429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693182</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3243</td>\n",
       "      <td>225</td>\n",
       "      <td>6</td>\n",
       "      <td>0.208889</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.437599</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.172043</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1927</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>health</td>\n",
       "      <td>0.644872</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.468310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062963</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1766</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.084175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.898192</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.173210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1802</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.348995</td>\n",
       "      <td>3.355263</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.573826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>business</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>3.321429</td>\n",
       "      <td>0.505747</td>\n",
       "      <td>0.298851</td>\n",
       "      <td>0.183908</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.421386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67406</td>\n",
       "      <td>87</td>\n",
       "      <td>7</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.097297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.289158</td>\n",
       "      <td>1.985816</td>\n",
       "      <td>0.356643</td>\n",
       "      <td>0.139860</td>\n",
       "      <td>0.055944</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.571006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9935</td>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.198413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.670358</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.451327</td>\n",
       "      <td>0.168142</td>\n",
       "      <td>0.106195</td>\n",
       "      <td>0.053097</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087824</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5500</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>0.159292</td>\n",
       "      <td>0.086066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>business</td>\n",
       "      <td>0.899731</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.207182</td>\n",
       "      <td>0.074586</td>\n",
       "      <td>0.030387</td>\n",
       "      <td>0.828025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027661</td>\n",
       "      <td>...</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4809</td>\n",
       "      <td>362</td>\n",
       "      <td>6</td>\n",
       "      <td>0.472376</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.783732</td>\n",
       "      <td>2.544041</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.324074</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.514042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270073</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3225</td>\n",
       "      <td>216</td>\n",
       "      <td>16</td>\n",
       "      <td>0.189815</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>1.549451</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.114428</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.569044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183206</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2382</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>science_technology</td>\n",
       "      <td>0.849952</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.439757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7456</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.089825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.487492</td>\n",
       "      <td>2.086957</td>\n",
       "      <td>0.498195</td>\n",
       "      <td>0.202166</td>\n",
       "      <td>0.028881</td>\n",
       "      <td>0.021661</td>\n",
       "      <td>0.510095</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100410</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8366</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523466</td>\n",
       "      <td>0.124726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>health</td>\n",
       "      <td>0.802314</td>\n",
       "      <td>1.783333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9309</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.504924</td>\n",
       "      <td>2.443983</td>\n",
       "      <td>0.365517</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.072414</td>\n",
       "      <td>0.055172</td>\n",
       "      <td>0.464775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1078</td>\n",
       "      <td>290</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117241</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>science_technology</td>\n",
       "      <td>0.260166</td>\n",
       "      <td>1.345794</td>\n",
       "      <td>0.360308</td>\n",
       "      <td>0.225434</td>\n",
       "      <td>0.181118</td>\n",
       "      <td>0.169557</td>\n",
       "      <td>0.480171</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.026647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330370</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16092</td>\n",
       "      <td>519</td>\n",
       "      <td>2</td>\n",
       "      <td>0.487476</td>\n",
       "      <td>0.096063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>science_technology</td>\n",
       "      <td>0.701326</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1589</td>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7352</th>\n",
       "      <td>science_technology</td>\n",
       "      <td>0.224411</td>\n",
       "      <td>2.198630</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.227891</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.451460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140371</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11923</td>\n",
       "      <td>294</td>\n",
       "      <td>4</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.094268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.479485</td>\n",
       "      <td>3.627907</td>\n",
       "      <td>0.987597</td>\n",
       "      <td>0.973643</td>\n",
       "      <td>0.903876</td>\n",
       "      <td>0.494574</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>972</td>\n",
       "      <td>645</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012403</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7354</th>\n",
       "      <td>religion</td>\n",
       "      <td>0.777470</td>\n",
       "      <td>1.965174</td>\n",
       "      <td>0.556604</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.033019</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.541991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284519</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1745</td>\n",
       "      <td>212</td>\n",
       "      <td>4</td>\n",
       "      <td>0.457547</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7355</th>\n",
       "      <td>business</td>\n",
       "      <td>0.852631</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7358</th>\n",
       "      <td>health</td>\n",
       "      <td>0.542932</td>\n",
       "      <td>4.993827</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.368132</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.391150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29708</td>\n",
       "      <td>182</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.091247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7359</th>\n",
       "      <td>health</td>\n",
       "      <td>0.613426</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.459227</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.090592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015106</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2775</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.065672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7360</th>\n",
       "      <td>religion</td>\n",
       "      <td>0.846979</td>\n",
       "      <td>2.097561</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>0.133858</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013223</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5801</td>\n",
       "      <td>127</td>\n",
       "      <td>8</td>\n",
       "      <td>0.070866</td>\n",
       "      <td>0.125637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7362</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.521839</td>\n",
       "      <td>1.765432</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.132530</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.498446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1618</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.127946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7364</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.556059</td>\n",
       "      <td>1.476190</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3668</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.079223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7370</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.749882</td>\n",
       "      <td>1.677966</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>826</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>computer_internet</td>\n",
       "      <td>0.393665</td>\n",
       "      <td>1.168367</td>\n",
       "      <td>0.627551</td>\n",
       "      <td>0.301020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172535</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1953</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.080537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7373</th>\n",
       "      <td>science_technology</td>\n",
       "      <td>0.700190</td>\n",
       "      <td>2.085774</td>\n",
       "      <td>0.747390</td>\n",
       "      <td>0.488518</td>\n",
       "      <td>0.146138</td>\n",
       "      <td>0.050104</td>\n",
       "      <td>0.382163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14627</td>\n",
       "      <td>479</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.882445</td>\n",
       "      <td>2.093333</td>\n",
       "      <td>0.349057</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>964</td>\n",
       "      <td>106</td>\n",
       "      <td>8</td>\n",
       "      <td>0.349057</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7375</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.483953</td>\n",
       "      <td>1.978495</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.308511</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.463504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043829</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4744</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.098644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.332504</td>\n",
       "      <td>7.392157</td>\n",
       "      <td>0.743421</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>0.269737</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.465021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026966</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3331</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.076577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7377</th>\n",
       "      <td>computer_internet</td>\n",
       "      <td>0.949532</td>\n",
       "      <td>1.861789</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.447591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112288</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2896</td>\n",
       "      <td>144</td>\n",
       "      <td>13</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.077869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.648793</td>\n",
       "      <td>2.488753</td>\n",
       "      <td>0.791583</td>\n",
       "      <td>0.509018</td>\n",
       "      <td>0.178357</td>\n",
       "      <td>0.044088</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2234</td>\n",
       "      <td>499</td>\n",
       "      <td>6</td>\n",
       "      <td>0.150301</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7379</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.657172</td>\n",
       "      <td>2.373134</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.236111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.474796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3178</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.104046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7381</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.223110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.607059</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7382</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.395289</td>\n",
       "      <td>5.611570</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.528037</td>\n",
       "      <td>0.490654</td>\n",
       "      <td>0.469481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15829</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7383</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.307736</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386</th>\n",
       "      <td>culture_politics</td>\n",
       "      <td>0.832741</td>\n",
       "      <td>3.156863</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.313043</td>\n",
       "      <td>0.113043</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>0.259315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12714</td>\n",
       "      <td>115</td>\n",
       "      <td>9</td>\n",
       "      <td>0.113043</td>\n",
       "      <td>0.022329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.316930</td>\n",
       "      <td>1.753731</td>\n",
       "      <td>0.510791</td>\n",
       "      <td>0.251799</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>964</td>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>0.158273</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.679419</td>\n",
       "      <td>1.995098</td>\n",
       "      <td>0.539535</td>\n",
       "      <td>0.213953</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>0.548148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1819</td>\n",
       "      <td>215</td>\n",
       "      <td>5</td>\n",
       "      <td>0.455814</td>\n",
       "      <td>0.070632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>computer_internet</td>\n",
       "      <td>0.651067</td>\n",
       "      <td>3.010526</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.474273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2219</td>\n",
       "      <td>99</td>\n",
       "      <td>11</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>culture_politics</td>\n",
       "      <td>0.141920</td>\n",
       "      <td>2.208054</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.558184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225962</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5672</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7392</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.196273</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.692529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>848</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.617876</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>386</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4824 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        alchemy_category  alchemy_category_score  avglinksize  \\\n",
       "0               business                0.789131     2.055556   \n",
       "1             recreation                0.574147     3.677966   \n",
       "2                 health                0.996526     2.382883   \n",
       "3                 health                0.801248     1.543103   \n",
       "4                 sports                0.719157     2.676471   \n",
       "6     arts_entertainment                0.221110     0.773810   \n",
       "10              business                0.816604     2.506527   \n",
       "11                sports                0.891560     4.986111   \n",
       "12                health                0.872323     3.056911   \n",
       "14            recreation                0.559991     2.299492   \n",
       "15            recreation                0.548963     0.990431   \n",
       "16            recreation                0.598149     0.929825   \n",
       "17    arts_entertainment                0.772920     2.083333   \n",
       "18            recreation                0.287884     3.164384   \n",
       "19                health                0.585389     2.826772   \n",
       "20                sports                0.941129     4.103627   \n",
       "21            recreation                0.437599     2.033333   \n",
       "22                health                0.644872     1.333333   \n",
       "25                sports                0.898192     4.800000   \n",
       "26                sports                0.348995     3.355263   \n",
       "27              business                0.850000     3.321429   \n",
       "30            recreation                0.289158     1.985816   \n",
       "31            recreation                0.670358     1.571429   \n",
       "33              business                0.899731     2.166667   \n",
       "34            recreation                0.783732     2.544041   \n",
       "37    arts_entertainment                0.519337     1.549451   \n",
       "40    science_technology                0.849952     9.800000   \n",
       "41            recreation                0.487492     2.086957   \n",
       "43                health                0.802314     1.783333   \n",
       "45                sports                0.504924     2.443983   \n",
       "...                  ...                     ...          ...   \n",
       "7349  science_technology                0.260166     1.345794   \n",
       "7351  science_technology                0.701326     1.200000   \n",
       "7352  science_technology                0.224411     2.198630   \n",
       "7353          recreation                0.479485     3.627907   \n",
       "7354            religion                0.777470     1.965174   \n",
       "7355            business                0.852631     1.840000   \n",
       "7358              health                0.542932     4.993827   \n",
       "7359              health                0.613426     2.260000   \n",
       "7360            religion                0.846979     2.097561   \n",
       "7362  arts_entertainment                0.521839     1.765432   \n",
       "7364          recreation                0.556059     1.476190   \n",
       "7370          recreation                0.749882     1.677966   \n",
       "7372   computer_internet                0.393665     1.168367   \n",
       "7373  science_technology                0.700190     2.085774   \n",
       "7374  arts_entertainment                0.882445     2.093333   \n",
       "7375          recreation                0.483953     1.978495   \n",
       "7376          recreation                0.332504     7.392157   \n",
       "7377   computer_internet                0.949532     1.861789   \n",
       "7378          recreation                0.648793     2.488753   \n",
       "7379  arts_entertainment                0.657172     2.373134   \n",
       "7381          recreation                0.223110     1.000000   \n",
       "7382          recreation                0.395289     5.611570   \n",
       "7383          recreation                0.307736     1.687500   \n",
       "7386    culture_politics                0.832741     3.156863   \n",
       "7387  arts_entertainment                0.316930     1.753731   \n",
       "7388          recreation                0.679419     1.995098   \n",
       "7390   computer_internet                0.651067     3.010526   \n",
       "7391    culture_politics                0.141920     2.208054   \n",
       "7392          recreation                0.196273     2.000000   \n",
       "7393  arts_entertainment                0.617876     1.026316   \n",
       "\n",
       "      commonlinkratio_1  commonlinkratio_2  commonlinkratio_3  \\\n",
       "0              0.676471           0.205882           0.047059   \n",
       "1              0.508021           0.288770           0.213904   \n",
       "2              0.562016           0.321705           0.120155   \n",
       "3              0.400000           0.100000           0.016667   \n",
       "4              0.500000           0.222222           0.123457   \n",
       "6              0.215054           0.053763           0.043011   \n",
       "10             0.637755           0.293367           0.091837   \n",
       "11             0.640000           0.426667           0.320000   \n",
       "12             0.595588           0.227941           0.044118   \n",
       "14             0.547414           0.206897           0.056034   \n",
       "15             0.522523           0.108108           0.009009   \n",
       "16             0.068966           0.000000           0.000000   \n",
       "17             0.421053           0.178947           0.042105   \n",
       "18             0.586207           0.275862           0.172414   \n",
       "19             0.669065           0.237410           0.064748   \n",
       "20             0.515556           0.297778           0.186667   \n",
       "21             0.516129           0.172043           0.043011   \n",
       "22             0.000000           0.000000           0.000000   \n",
       "25             0.603448           0.379310           0.241379   \n",
       "26             0.488372           0.290698           0.081395   \n",
       "27             0.505747           0.298851           0.183908   \n",
       "30             0.356643           0.139860           0.055944   \n",
       "31             0.451327           0.168142           0.106195   \n",
       "33             0.447514           0.207182           0.074586   \n",
       "34             0.583333           0.324074           0.129630   \n",
       "37             0.417910           0.114428           0.004975   \n",
       "40             0.292308           0.092308           0.015385   \n",
       "41             0.498195           0.202166           0.028881   \n",
       "43             0.214286           0.071429           0.014286   \n",
       "45             0.365517           0.200000           0.072414   \n",
       "...                 ...                ...                ...   \n",
       "7349           0.360308           0.225434           0.181118   \n",
       "7351           0.091667           0.008333           0.000000   \n",
       "7352           0.693878           0.340136           0.227891   \n",
       "7353           0.987597           0.973643           0.903876   \n",
       "7354           0.556604           0.226415           0.033019   \n",
       "7355           0.484848           0.060606           0.000000   \n",
       "7358           0.802198           0.670330           0.368132   \n",
       "7359           0.448276           0.068966           0.068966   \n",
       "7360           0.370079           0.133858           0.039370   \n",
       "7362           0.602410           0.132530           0.012048   \n",
       "7364           0.366197           0.098592           0.014085   \n",
       "7370           0.256757           0.135135           0.000000   \n",
       "7372           0.627551           0.301020           0.000000   \n",
       "7373           0.747390           0.488518           0.146138   \n",
       "7374           0.349057           0.150943           0.037736   \n",
       "7375           0.510638           0.308511           0.148936   \n",
       "7376           0.743421           0.460526           0.269737   \n",
       "7377           0.347222           0.104167           0.055556   \n",
       "7378           0.791583           0.509018           0.178357   \n",
       "7379           0.375000           0.277778           0.236111   \n",
       "7381           0.000000           0.000000           0.000000   \n",
       "7382           0.738318           0.579439           0.528037   \n",
       "7383           0.531250           0.062500           0.062500   \n",
       "7386           0.669565           0.313043           0.113043   \n",
       "7387           0.510791           0.251799           0.043165   \n",
       "7388           0.539535           0.213953           0.018605   \n",
       "7390           0.474747           0.222222           0.191919   \n",
       "7391           0.483333           0.246667           0.036667   \n",
       "7392           0.315789           0.171053           0.105263   \n",
       "7393           0.210526           0.052632           0.000000   \n",
       "\n",
       "      commonlinkratio_4  compression_ratio  embed_ratio  frameTagRatio  ...    \\\n",
       "0              0.023529           0.443783     0.000000       0.090774  ...     \n",
       "1              0.144385           0.468649     0.000000       0.098707  ...     \n",
       "2              0.042636           0.525448     0.000000       0.072448  ...     \n",
       "3              0.000000           0.480725     0.000000       0.095861  ...     \n",
       "4              0.043210           0.446143     0.000000       0.024908  ...     \n",
       "6              0.043011           0.579596     0.000000       0.039568  ...     \n",
       "10             0.048469           0.592322     0.000000       0.056497  ...     \n",
       "11             0.293333           0.521064     0.004065       0.162690  ...     \n",
       "12             0.014706           0.573109     0.000000       0.074576  ...     \n",
       "14             0.017241           0.473965     0.000000       0.078431  ...     \n",
       "15             0.000000           0.414155     0.000000       0.054993  ...     \n",
       "16             0.000000           0.478355     0.000000       0.157576  ...     \n",
       "17             0.000000           0.462995     0.000000       0.099778  ...     \n",
       "18             0.149425           0.520415     0.000000       0.035865  ...     \n",
       "19             0.021583           0.562795     0.000000       0.073456  ...     \n",
       "20             0.106667           0.412429     0.000000       0.064489  ...     \n",
       "21             0.000000           0.909836     0.000000       0.105578  ...     \n",
       "22             0.000000           0.468310     0.000000       0.041262  ...     \n",
       "25             0.155172           0.480519     0.010638       0.173210  ...     \n",
       "26             0.023256           0.573826     0.000000       0.007968  ...     \n",
       "27             0.137931           0.421386     0.000000       0.004970  ...     \n",
       "30             0.027972           0.571006     0.000000       0.027027  ...     \n",
       "31             0.053097           0.437500     0.000000       0.055215  ...     \n",
       "33             0.030387           0.828025     0.000000       0.027661  ...     \n",
       "34             0.037037           0.514042     0.000000       0.082569  ...     \n",
       "37             0.004975           0.569044     0.000000       0.040764  ...     \n",
       "40             0.000000           0.439757     0.000000       0.058228  ...     \n",
       "41             0.021661           0.510095     0.002049       0.008850  ...     \n",
       "43             0.000000           0.445471     0.000000       0.070117  ...     \n",
       "45             0.055172           0.464775     0.000000       0.022196  ...     \n",
       "...                 ...                ...          ...            ...  ...     \n",
       "7349           0.169557           0.480171     0.001481       0.026647  ...     \n",
       "7351           0.000000           0.427184     0.000000       0.084437  ...     \n",
       "7352           0.204082           0.451460     0.000000       0.027009  ...     \n",
       "7353           0.494574           0.705882     0.000000       0.003574  ...     \n",
       "7354           0.028302           0.541991     0.000000       0.041045  ...     \n",
       "7355           0.000000           0.485164     0.000000       0.121429  ...     \n",
       "7358           0.274725           0.391150     0.000000       0.009009  ...     \n",
       "7359           0.034483           0.459227     0.003021       0.090592  ...     \n",
       "7360           0.000000           0.493393     0.000000       0.062635  ...     \n",
       "7362           0.000000           0.498446     0.000000       0.061224  ...     \n",
       "7364           0.000000           0.414183     0.000000       0.056604  ...     \n",
       "7370           0.000000           0.737201     0.000000       0.031320  ...     \n",
       "7372           0.000000           0.524778     0.000000       0.106931  ...     \n",
       "7373           0.050104           0.382163     0.000000       0.039698  ...     \n",
       "7374           0.000000           0.518707     0.000000       0.091463  ...     \n",
       "7375           0.042553           0.463504     0.000000       0.040984  ...     \n",
       "7376           0.013158           0.465021     0.000000       0.023499  ...     \n",
       "7377           0.027778           0.447591     0.000000       0.045706  ...     \n",
       "7378           0.044088           0.609756     0.000000       0.022850  ...     \n",
       "7379           0.222222           0.474796     0.000000       0.046563  ...     \n",
       "7381           0.000000           0.607059     0.019231       0.054795  ...     \n",
       "7382           0.490654           0.469481     0.000000       0.020336  ...     \n",
       "7383           0.062500          21.000000    -1.000000       0.103896  ...     \n",
       "7386           0.034783           0.259315     0.000000       0.044103  ...     \n",
       "7387           0.000000           0.639198     0.000000       0.048733  ...     \n",
       "7388           0.018605           0.548148     0.000000       0.040293  ...     \n",
       "7390           0.191919           0.474273     0.000000       0.177043  ...     \n",
       "7391           0.026667           0.558184     0.000000       0.057377  ...     \n",
       "7392           0.052632           0.692529     0.000000       0.124122  ...     \n",
       "7393           0.000000          21.000000    -1.000000       0.097778  ...     \n",
       "\n",
       "      image_ratio  lengthyLinkDomain  linkwordscore  news_front_page  \\\n",
       "0        0.003883                  1             24              0.0   \n",
       "1        0.088652                  1             40              0.0   \n",
       "2        0.120536                  1             55              0.0   \n",
       "3        0.035343                  0             24              0.0   \n",
       "4        0.050473                  1             14              0.0   \n",
       "6        0.311377                  0             21              0.0   \n",
       "10       0.511364                  1             53              0.0   \n",
       "11       0.060976                  1             40              0.0   \n",
       "12       0.084112                  1             64              0.0   \n",
       "14       0.036424                  1             37              0.0   \n",
       "15       0.075630                  0             54              0.0   \n",
       "16       0.276316                  0             50              0.0   \n",
       "17       0.275862                  0             49              0.0   \n",
       "18       0.091549                  1             23              0.0   \n",
       "19       0.053254                  1             55              0.0   \n",
       "20       0.693182                  1             53              0.0   \n",
       "21       0.863636                  1             31              0.0   \n",
       "22       0.062963                  0              3              0.0   \n",
       "25       0.085106                  1             45              0.0   \n",
       "26       0.004608                  1             98              1.0   \n",
       "27       0.004007                  1              2              0.0   \n",
       "30       0.230769                  1             11              0.0   \n",
       "31       0.087824                  1             12              0.0   \n",
       "33       3.625000                  1             35              0.0   \n",
       "34       0.270073                  1             44              0.0   \n",
       "37       0.183206                  0             37              0.0   \n",
       "40       0.012346                  0              6              0.0   \n",
       "41       0.100410                  1             22              1.0   \n",
       "43       0.314815                  1              5              0.0   \n",
       "45       0.918919                  1             76              0.0   \n",
       "...           ...                ...            ...              ...   \n",
       "7349     0.330370                  1             13              0.0   \n",
       "7351     0.317073                  1             29              0.0   \n",
       "7352     0.140371                  1             19              0.0   \n",
       "7353     0.588235                  1             93              0.0   \n",
       "7354     0.284519                  1             53              0.0   \n",
       "7355     0.035714                  0             14              0.0   \n",
       "7358     0.002358                  1             10              0.0   \n",
       "7359     0.015106                  1             16              0.0   \n",
       "7360     0.013223                  1             17              0.0   \n",
       "7362     0.026316                  0             28              0.0   \n",
       "7364     0.044118                  0             11              0.0   \n",
       "7370     0.313725                  0             36              0.0   \n",
       "7372     0.172535                  0             37              0.0   \n",
       "7373     0.006561                  1             25              1.0   \n",
       "7374     0.363636                  0             48              0.0   \n",
       "7375     0.043829                  1             15              1.0   \n",
       "7376     0.026966                  0             35              0.0   \n",
       "7377     0.112288                  1             29              0.0   \n",
       "7378     0.278689                  1             74              0.0   \n",
       "7379     0.067227                  1             21              0.0   \n",
       "7381     0.461538                  0             10              0.0   \n",
       "7382     0.023490                  1             16              0.0   \n",
       "7383    -1.000000                  0             73              0.0   \n",
       "7386     0.003122                  1             15              0.0   \n",
       "7387     0.137500                  0             53              0.0   \n",
       "7388     0.274194                  1             54              0.0   \n",
       "7390     0.048780                  1             38              0.0   \n",
       "7391     0.225962                  1             34              0.0   \n",
       "7392     0.464286                  1             43              0.0   \n",
       "7393    -1.000000                  0             37              1.0   \n",
       "\n",
       "      non_markup_alphanum_characters  numberOfLinks  numwords_in_url  \\\n",
       "0                               5424            170                8   \n",
       "1                               4973            187                9   \n",
       "2                               2240            258               11   \n",
       "3                               2737            120                5   \n",
       "4                              12032            162               10   \n",
       "6                               1287             93                3   \n",
       "10                              4401            392                0   \n",
       "11                              2701             75                8   \n",
       "12                              1062            136                9   \n",
       "14                              3610            232               11   \n",
       "15                               883            222                4   \n",
       "16                               268             58                2   \n",
       "17                               852             95                8   \n",
       "18                              3509             87                2   \n",
       "19                              1511            139                9   \n",
       "20                              3243            225                6   \n",
       "21                              1927             93                5   \n",
       "22                              1766             11                2   \n",
       "25                              1802             58                9   \n",
       "26                                21             86                0   \n",
       "27                             67406             87                7   \n",
       "30                              9935            143                2   \n",
       "31                              5500            113                4   \n",
       "33                              4809            362                6   \n",
       "34                              3225            216               16   \n",
       "37                              2382            201                1   \n",
       "40                              7456             65                1   \n",
       "41                              8366            277                0   \n",
       "43                              9309             70                8   \n",
       "45                              1078            290                2   \n",
       "...                              ...            ...              ...   \n",
       "7349                           16092            519                2   \n",
       "7351                            1589            120                9   \n",
       "7352                           11923            294                4   \n",
       "7353                             972            645                3   \n",
       "7354                            1745            212                4   \n",
       "7355                            1440             33                4   \n",
       "7358                           29708            182                3   \n",
       "7359                            2775             58               14   \n",
       "7360                            5801            127                8   \n",
       "7362                            1618             83                6   \n",
       "7364                            3668             71                3   \n",
       "7370                             826             74                4   \n",
       "7372                            1953            196               10   \n",
       "7373                           14627            479                0   \n",
       "7374                             964            106                8   \n",
       "7375                            4744             94                0   \n",
       "7376                            3331            152                0   \n",
       "7377                            2896            144               13   \n",
       "7378                            2234            499                6   \n",
       "7379                            3178             72                6   \n",
       "7381                             137             16                0   \n",
       "7382                           15829            214                3   \n",
       "7383                              90             32                1   \n",
       "7386                           12714            115                9   \n",
       "7387                             964            139                2   \n",
       "7388                            1819            215                5   \n",
       "7390                            2219             99               11   \n",
       "7391                            5672            300                4   \n",
       "7392                             848             76                5   \n",
       "7393                             386             38                0   \n",
       "\n",
       "      parametrizedLinkRatio  spelling_errors_ratio  label  \n",
       "0                  0.152941               0.079130      0  \n",
       "1                  0.181818               0.125448      1  \n",
       "2                  0.166667               0.057613      1  \n",
       "3                  0.041667               0.100858      1  \n",
       "4                  0.098765               0.082569      0  \n",
       "6                  0.548387               0.064327      1  \n",
       "10                 0.160714               0.073684      0  \n",
       "11                 0.186667               0.115385      0  \n",
       "12                 0.169118               0.180328      1  \n",
       "14                 0.215517               0.080205      0  \n",
       "15                 0.013514               0.059603      0  \n",
       "16                 0.137931               0.107143      0  \n",
       "17                 0.305263               0.139738      0  \n",
       "18                 0.402299               0.090580      1  \n",
       "19                 0.165468               0.065217      1  \n",
       "20                 0.208889               0.043860      0  \n",
       "21                 0.043011               0.078947      1  \n",
       "22                 0.090909               0.084175      0  \n",
       "25                 0.155172               0.055000      0  \n",
       "26                 0.000000               0.128440      0  \n",
       "27                 0.091954               0.097297      0  \n",
       "30                 0.027972               0.198413      1  \n",
       "31                 0.159292               0.086066      1  \n",
       "33                 0.472376               0.085106      1  \n",
       "34                 0.189815               0.039773      0  \n",
       "37                 0.014925               0.092308      0  \n",
       "40                 0.046154               0.089825      0  \n",
       "41                 0.523466               0.124726      1  \n",
       "43                 0.114286               0.061856      1  \n",
       "45                 0.117241               0.081081      0  \n",
       "...                     ...                    ...    ...  \n",
       "7349               0.487476               0.096063      1  \n",
       "7351               0.058333               0.095890      0  \n",
       "7352               0.469388               0.094268      0  \n",
       "7353               0.012403               0.040000      1  \n",
       "7354               0.457547               0.084615      1  \n",
       "7355               0.181818               0.079208      1  \n",
       "7358               0.021978               0.091247      1  \n",
       "7359               0.103448               0.065672      0  \n",
       "7360               0.070866               0.125637      1  \n",
       "7362               0.096386               0.127946      0  \n",
       "7364               0.014085               0.079223      0  \n",
       "7370               0.067568               0.049180      0  \n",
       "7372               0.045918               0.080537      0  \n",
       "7373               0.008351               0.085393      0  \n",
       "7374               0.349057               0.077586      0  \n",
       "7375               0.010638               0.098644      0  \n",
       "7376               0.013158               0.076577      1  \n",
       "7377               0.194444               0.077869      0  \n",
       "7378               0.150301               0.083333      1  \n",
       "7379               0.180556               0.104046      1  \n",
       "7381               0.000000               0.072727      0  \n",
       "7382               0.056075               0.092715      1  \n",
       "7383               0.031250               0.166667      1  \n",
       "7386               0.113043               0.022329      1  \n",
       "7387               0.158273               0.036585      1  \n",
       "7388               0.455814               0.070632      0  \n",
       "7390               0.040404               0.071429      0  \n",
       "7391               0.020000               0.109453      0  \n",
       "7392               0.434211               0.117647      1  \n",
       "7393               0.026316               0.333333      1  \n",
       "\n",
       "[4824 rows x 22 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to String Floats to Floats - can only do this for one type, need to take out '?' in floats ahead of time\n",
    "\n",
    "su_subb['news_front_page'] = su_subb['news_front_page'].map(lambda x: float(x))\n",
    "su_subb['alchemy_category_score'] = su_subb['alchemy_category_score'].map(lambda x: float(x))\n",
    "\n",
    "su_subb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alchemy_category                     mixed\n",
       "alchemy_category_score            floating\n",
       "avglinksize                       floating\n",
       "commonlinkratio_1                 floating\n",
       "commonlinkratio_2                 floating\n",
       "commonlinkratio_3                 floating\n",
       "commonlinkratio_4                 floating\n",
       "compression_ratio                 floating\n",
       "embed_ratio                       floating\n",
       "frameTagRatio                     floating\n",
       "hasDomainLink                      integer\n",
       "html_ratio                        floating\n",
       "image_ratio                       floating\n",
       "lengthyLinkDomain                  integer\n",
       "linkwordscore                      integer\n",
       "news_front_page                   floating\n",
       "non_markup_alphanum_characters     integer\n",
       "numberOfLinks                      integer\n",
       "numwords_in_url                    integer\n",
       "parametrizedLinkRatio             floating\n",
       "spelling_errors_ratio             floating\n",
       "label                              integer\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sutypes2 = su_sub.apply(lambda x: pd.lib.infer_dtype(x.values))\n",
    "sutypes2 #GOOD ALL IS NUMBERS except for alchemy_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use statsmodels' logistic regression function to look at variable significance\n",
    "\n",
    "The **`import statsmodels.formula.api as smf`** code below gives us access to a statsmodels api that can run logistic regressions using patsy-style formulas.\n",
    "\n",
    "Ex:\n",
    "\n",
    "```python\n",
    "formula = 'target ~ var1 + var2 + C(var3) -1'\n",
    "logreg = smf.logit(formula, data=data)\n",
    "logreg_results = logreg.fit()\n",
    "print logreg_results.summary()\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label ~ avglinksize + commonlinkratio_1 + commonlinkratio_2 + commonlinkratio_3 + commonlinkratio_4 + compression_ratio + embed_ratio + frameTagRatio + hasDomainLink + html_ratio + image_ratio + lengthyLinkDomain + linkwordscore + non_markup_alphanum_characters + numberOfLinks + numwords_in_url + parametrizedLinkRatio + spelling_errors_ratio - 1\n"
     ]
    }
   ],
   "source": [
    "#alchemy_category is Categorical\n",
    "\n",
    "# Get the non-target cols with a simple list comprehension, \"label\" is TARGET\n",
    "non_target_cols_a = [c for c in su_suba.columns if c not in [\"label\"]]\n",
    "\n",
    "# Use some string adding and joining to make the simple model formula:\n",
    "formula_za = 'label' + ' ~ ' + ' + '.join(non_target_cols_a) + ' - 1'\n",
    "formula_za = str(formula_za)\n",
    "\n",
    "print formula_za\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Run a logistic regression predicting evergreen from the numeric columns\n",
    "\n",
    "And print out the results as shown in the example above.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653858\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "logreg_a = smf.logit(formula_za, data = su_suba)\n",
    "logreg_results_a = logreg_a.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   No. Observations:                 7395\n",
      "Model:                          Logit   Df Residuals:                     7377\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Tue, 17 May 2016   Pseudo R-squ.:                 0.05620\n",
      "Time:                        06:11:23   Log-Likelihood:                -4835.3\n",
      "converged:                       True   LL-Null:                       -5123.2\n",
      "                                        LLR p-value:                1.850e-111\n",
      "==================================================================================================\n",
      "                                     coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "avglinksize                        0.0014      0.003      0.478      0.633        -0.004     0.007\n",
      "commonlinkratio_1                  0.9679      0.210      4.606      0.000         0.556     1.380\n",
      "commonlinkratio_2                 -0.4070      0.373     -1.090      0.276        -1.139     0.325\n",
      "commonlinkratio_3                  3.2943      0.717      4.596      0.000         1.889     4.699\n",
      "commonlinkratio_4                 -2.0011      0.732     -2.733      0.006        -3.436    -0.566\n",
      "compression_ratio                 -0.0136      0.010     -1.411      0.158        -0.033     0.005\n",
      "embed_ratio                       -0.2601      0.176     -1.479      0.139        -0.605     0.084\n",
      "frameTagRatio                     -6.1001      0.776     -7.860      0.000        -7.621    -4.579\n",
      "hasDomainLink                      0.0045      0.167      0.027      0.978        -0.322     0.332\n",
      "html_ratio                         2.4216      0.337      7.178      0.000         1.760     3.083\n",
      "image_ratio                       -0.0141      0.015     -0.962      0.336        -0.043     0.015\n",
      "lengthyLinkDomain                 -0.0574      0.061     -0.946      0.344        -0.176     0.061\n",
      "linkwordscore                     -0.0230      0.002    -13.893      0.000        -0.026    -0.020\n",
      "non_markup_alphanum_characters  -2.12e-05   3.85e-06     -5.508      0.000     -2.87e-05 -1.37e-05\n",
      "numberOfLinks                      0.0015      0.000      6.877      0.000         0.001     0.002\n",
      "numwords_in_url                   -0.0158      0.008     -2.038      0.042        -0.031    -0.001\n",
      "parametrizedLinkRatio              0.1376      0.134      1.026      0.305        -0.125     0.401\n",
      "spelling_errors_ratio             -1.1743      0.340     -3.457      0.001        -1.840    -0.509\n",
      "==================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print logreg_results_a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "ya = su_suba['label']\n",
    "Xa = su_suba.drop(['label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>embed_ratio</th>\n",
       "      <th>frameTagRatio</th>\n",
       "      <th>hasDomainLink</th>\n",
       "      <th>html_ratio</th>\n",
       "      <th>image_ratio</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avglinksize</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120467</td>\n",
       "      <td>0.161769</td>\n",
       "      <td>0.174554</td>\n",
       "      <td>0.134527</td>\n",
       "      <td>-0.003578</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>-0.049270</td>\n",
       "      <td>-0.002046</td>\n",
       "      <td>0.018974</td>\n",
       "      <td>-0.003002</td>\n",
       "      <td>0.020852</td>\n",
       "      <td>0.122550</td>\n",
       "      <td>-0.010982</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>-0.033890</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>0.035393</td>\n",
       "      <td>0.006172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <td>0.120467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808047</td>\n",
       "      <td>0.560584</td>\n",
       "      <td>0.388801</td>\n",
       "      <td>-0.017878</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>-0.294860</td>\n",
       "      <td>0.006790</td>\n",
       "      <td>-0.201501</td>\n",
       "      <td>-0.064435</td>\n",
       "      <td>0.421284</td>\n",
       "      <td>0.257200</td>\n",
       "      <td>0.193914</td>\n",
       "      <td>0.317293</td>\n",
       "      <td>0.144354</td>\n",
       "      <td>-0.078026</td>\n",
       "      <td>-0.035019</td>\n",
       "      <td>0.083364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <td>0.161769</td>\n",
       "      <td>0.808047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758330</td>\n",
       "      <td>0.555148</td>\n",
       "      <td>-0.032460</td>\n",
       "      <td>0.019387</td>\n",
       "      <td>-0.259222</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>-0.159702</td>\n",
       "      <td>-0.044663</td>\n",
       "      <td>0.398817</td>\n",
       "      <td>0.257594</td>\n",
       "      <td>0.177785</td>\n",
       "      <td>0.311492</td>\n",
       "      <td>0.096940</td>\n",
       "      <td>-0.079485</td>\n",
       "      <td>-0.027888</td>\n",
       "      <td>0.083488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <td>0.174554</td>\n",
       "      <td>0.560584</td>\n",
       "      <td>0.758330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850604</td>\n",
       "      <td>-0.016188</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>-0.218559</td>\n",
       "      <td>-0.031097</td>\n",
       "      <td>-0.133370</td>\n",
       "      <td>-0.050357</td>\n",
       "      <td>0.363159</td>\n",
       "      <td>0.109654</td>\n",
       "      <td>0.264022</td>\n",
       "      <td>0.283924</td>\n",
       "      <td>0.049203</td>\n",
       "      <td>-0.008652</td>\n",
       "      <td>-0.008599</td>\n",
       "      <td>0.105964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <td>0.134527</td>\n",
       "      <td>0.388801</td>\n",
       "      <td>0.555148</td>\n",
       "      <td>0.850604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020415</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>-0.178064</td>\n",
       "      <td>-0.052519</td>\n",
       "      <td>-0.136561</td>\n",
       "      <td>-0.038071</td>\n",
       "      <td>0.287159</td>\n",
       "      <td>0.059223</td>\n",
       "      <td>0.162883</td>\n",
       "      <td>0.233898</td>\n",
       "      <td>0.026384</td>\n",
       "      <td>0.036387</td>\n",
       "      <td>-0.013507</td>\n",
       "      <td>0.080464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compression_ratio</th>\n",
       "      <td>-0.003578</td>\n",
       "      <td>-0.017878</td>\n",
       "      <td>-0.032460</td>\n",
       "      <td>-0.016188</td>\n",
       "      <td>-0.020415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.889345</td>\n",
       "      <td>0.159335</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>0.106335</td>\n",
       "      <td>-0.188976</td>\n",
       "      <td>-0.090325</td>\n",
       "      <td>0.146470</td>\n",
       "      <td>-0.064163</td>\n",
       "      <td>-0.055388</td>\n",
       "      <td>-0.042614</td>\n",
       "      <td>-0.033772</td>\n",
       "      <td>0.364122</td>\n",
       "      <td>-0.059737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_ratio</th>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.019387</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>-0.889345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.130753</td>\n",
       "      <td>-0.026473</td>\n",
       "      <td>-0.090938</td>\n",
       "      <td>0.183808</td>\n",
       "      <td>0.075322</td>\n",
       "      <td>-0.108476</td>\n",
       "      <td>0.046484</td>\n",
       "      <td>0.042942</td>\n",
       "      <td>0.043343</td>\n",
       "      <td>0.037361</td>\n",
       "      <td>-0.342206</td>\n",
       "      <td>0.039536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frameTagRatio</th>\n",
       "      <td>-0.049270</td>\n",
       "      <td>-0.294860</td>\n",
       "      <td>-0.259222</td>\n",
       "      <td>-0.218559</td>\n",
       "      <td>-0.178064</td>\n",
       "      <td>0.159335</td>\n",
       "      <td>-0.130753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010193</td>\n",
       "      <td>0.384937</td>\n",
       "      <td>-0.088847</td>\n",
       "      <td>-0.196673</td>\n",
       "      <td>0.158874</td>\n",
       "      <td>-0.303682</td>\n",
       "      <td>-0.362491</td>\n",
       "      <td>0.049330</td>\n",
       "      <td>-0.094557</td>\n",
       "      <td>0.033663</td>\n",
       "      <td>-0.187762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasDomainLink</th>\n",
       "      <td>-0.002046</td>\n",
       "      <td>0.006790</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>-0.031097</td>\n",
       "      <td>-0.052519</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>-0.026473</td>\n",
       "      <td>0.010193</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009665</td>\n",
       "      <td>-0.003890</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>0.022583</td>\n",
       "      <td>-0.017361</td>\n",
       "      <td>0.013678</td>\n",
       "      <td>0.058085</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>0.008718</td>\n",
       "      <td>-0.004863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>html_ratio</th>\n",
       "      <td>0.018974</td>\n",
       "      <td>-0.201501</td>\n",
       "      <td>-0.159702</td>\n",
       "      <td>-0.133370</td>\n",
       "      <td>-0.136561</td>\n",
       "      <td>0.106335</td>\n",
       "      <td>-0.090938</td>\n",
       "      <td>0.384937</td>\n",
       "      <td>0.009665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.172924</td>\n",
       "      <td>-0.215809</td>\n",
       "      <td>-0.141363</td>\n",
       "      <td>-0.136550</td>\n",
       "      <td>-0.455636</td>\n",
       "      <td>-0.042001</td>\n",
       "      <td>-0.183350</td>\n",
       "      <td>0.013860</td>\n",
       "      <td>-0.051149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_ratio</th>\n",
       "      <td>-0.003002</td>\n",
       "      <td>-0.064435</td>\n",
       "      <td>-0.044663</td>\n",
       "      <td>-0.050357</td>\n",
       "      <td>-0.038071</td>\n",
       "      <td>-0.188976</td>\n",
       "      <td>0.183808</td>\n",
       "      <td>-0.088847</td>\n",
       "      <td>-0.003890</td>\n",
       "      <td>-0.172924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047652</td>\n",
       "      <td>0.051436</td>\n",
       "      <td>-0.026655</td>\n",
       "      <td>0.091977</td>\n",
       "      <td>-0.037265</td>\n",
       "      <td>0.118549</td>\n",
       "      <td>-0.010975</td>\n",
       "      <td>-0.017266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <td>0.020852</td>\n",
       "      <td>0.421284</td>\n",
       "      <td>0.398817</td>\n",
       "      <td>0.363159</td>\n",
       "      <td>0.287159</td>\n",
       "      <td>-0.090325</td>\n",
       "      <td>0.075322</td>\n",
       "      <td>-0.196673</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>-0.215809</td>\n",
       "      <td>-0.047652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130844</td>\n",
       "      <td>0.203278</td>\n",
       "      <td>0.307005</td>\n",
       "      <td>0.229114</td>\n",
       "      <td>-0.034653</td>\n",
       "      <td>-0.031943</td>\n",
       "      <td>0.032824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linkwordscore</th>\n",
       "      <td>0.122550</td>\n",
       "      <td>0.257200</td>\n",
       "      <td>0.257594</td>\n",
       "      <td>0.109654</td>\n",
       "      <td>0.059223</td>\n",
       "      <td>0.146470</td>\n",
       "      <td>-0.108476</td>\n",
       "      <td>0.158874</td>\n",
       "      <td>0.022583</td>\n",
       "      <td>-0.141363</td>\n",
       "      <td>0.051436</td>\n",
       "      <td>0.130844</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.379487</td>\n",
       "      <td>0.171880</td>\n",
       "      <td>-0.011236</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.025707</td>\n",
       "      <td>-0.173800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <td>-0.010982</td>\n",
       "      <td>0.193914</td>\n",
       "      <td>0.177785</td>\n",
       "      <td>0.264022</td>\n",
       "      <td>0.162883</td>\n",
       "      <td>-0.064163</td>\n",
       "      <td>0.046484</td>\n",
       "      <td>-0.303682</td>\n",
       "      <td>-0.017361</td>\n",
       "      <td>-0.136550</td>\n",
       "      <td>-0.026655</td>\n",
       "      <td>0.203278</td>\n",
       "      <td>-0.379487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375584</td>\n",
       "      <td>0.076632</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>-0.010207</td>\n",
       "      <td>0.097580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numberOfLinks</th>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.317293</td>\n",
       "      <td>0.311492</td>\n",
       "      <td>0.283924</td>\n",
       "      <td>0.233898</td>\n",
       "      <td>-0.055388</td>\n",
       "      <td>0.042942</td>\n",
       "      <td>-0.362491</td>\n",
       "      <td>0.013678</td>\n",
       "      <td>-0.455636</td>\n",
       "      <td>0.091977</td>\n",
       "      <td>0.307005</td>\n",
       "      <td>0.171880</td>\n",
       "      <td>0.375584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068791</td>\n",
       "      <td>0.136482</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.080187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numwords_in_url</th>\n",
       "      <td>-0.033890</td>\n",
       "      <td>0.144354</td>\n",
       "      <td>0.096940</td>\n",
       "      <td>0.049203</td>\n",
       "      <td>0.026384</td>\n",
       "      <td>-0.042614</td>\n",
       "      <td>0.043343</td>\n",
       "      <td>0.049330</td>\n",
       "      <td>0.058085</td>\n",
       "      <td>-0.042001</td>\n",
       "      <td>-0.037265</td>\n",
       "      <td>0.229114</td>\n",
       "      <td>-0.011236</td>\n",
       "      <td>0.076632</td>\n",
       "      <td>0.068791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.095363</td>\n",
       "      <td>-0.107631</td>\n",
       "      <td>-0.024823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <td>0.006089</td>\n",
       "      <td>-0.078026</td>\n",
       "      <td>-0.079485</td>\n",
       "      <td>-0.008652</td>\n",
       "      <td>0.036387</td>\n",
       "      <td>-0.033772</td>\n",
       "      <td>0.037361</td>\n",
       "      <td>-0.094557</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>-0.183350</td>\n",
       "      <td>0.118549</td>\n",
       "      <td>-0.034653</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>0.136482</td>\n",
       "      <td>-0.095363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007397</td>\n",
       "      <td>0.010668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <td>0.035393</td>\n",
       "      <td>-0.035019</td>\n",
       "      <td>-0.027888</td>\n",
       "      <td>-0.008599</td>\n",
       "      <td>-0.013507</td>\n",
       "      <td>0.364122</td>\n",
       "      <td>-0.342206</td>\n",
       "      <td>0.033663</td>\n",
       "      <td>0.008718</td>\n",
       "      <td>0.013860</td>\n",
       "      <td>-0.010975</td>\n",
       "      <td>-0.031943</td>\n",
       "      <td>0.025707</td>\n",
       "      <td>-0.010207</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>-0.107631</td>\n",
       "      <td>-0.007397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0.006172</td>\n",
       "      <td>0.083364</td>\n",
       "      <td>0.083488</td>\n",
       "      <td>0.105964</td>\n",
       "      <td>0.080464</td>\n",
       "      <td>-0.059737</td>\n",
       "      <td>0.039536</td>\n",
       "      <td>-0.187762</td>\n",
       "      <td>-0.004863</td>\n",
       "      <td>-0.051149</td>\n",
       "      <td>-0.017266</td>\n",
       "      <td>0.032824</td>\n",
       "      <td>-0.173800</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.080187</td>\n",
       "      <td>-0.024823</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>-0.058578</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                avglinksize  commonlinkratio_1  \\\n",
       "avglinksize                        1.000000           0.120467   \n",
       "commonlinkratio_1                  0.120467           1.000000   \n",
       "commonlinkratio_2                  0.161769           0.808047   \n",
       "commonlinkratio_3                  0.174554           0.560584   \n",
       "commonlinkratio_4                  0.134527           0.388801   \n",
       "compression_ratio                 -0.003578          -0.017878   \n",
       "embed_ratio                        0.005254           0.005280   \n",
       "frameTagRatio                     -0.049270          -0.294860   \n",
       "hasDomainLink                     -0.002046           0.006790   \n",
       "html_ratio                         0.018974          -0.201501   \n",
       "image_ratio                       -0.003002          -0.064435   \n",
       "lengthyLinkDomain                  0.020852           0.421284   \n",
       "linkwordscore                      0.122550           0.257200   \n",
       "non_markup_alphanum_characters    -0.010982           0.193914   \n",
       "numberOfLinks                      0.000360           0.317293   \n",
       "numwords_in_url                   -0.033890           0.144354   \n",
       "parametrizedLinkRatio              0.006089          -0.078026   \n",
       "spelling_errors_ratio              0.035393          -0.035019   \n",
       "label                              0.006172           0.083364   \n",
       "\n",
       "                                commonlinkratio_2  commonlinkratio_3  \\\n",
       "avglinksize                              0.161769           0.174554   \n",
       "commonlinkratio_1                        0.808047           0.560584   \n",
       "commonlinkratio_2                        1.000000           0.758330   \n",
       "commonlinkratio_3                        0.758330           1.000000   \n",
       "commonlinkratio_4                        0.555148           0.850604   \n",
       "compression_ratio                       -0.032460          -0.016188   \n",
       "embed_ratio                              0.019387           0.007578   \n",
       "frameTagRatio                           -0.259222          -0.218559   \n",
       "hasDomainLink                            0.000263          -0.031097   \n",
       "html_ratio                              -0.159702          -0.133370   \n",
       "image_ratio                             -0.044663          -0.050357   \n",
       "lengthyLinkDomain                        0.398817           0.363159   \n",
       "linkwordscore                            0.257594           0.109654   \n",
       "non_markup_alphanum_characters           0.177785           0.264022   \n",
       "numberOfLinks                            0.311492           0.283924   \n",
       "numwords_in_url                          0.096940           0.049203   \n",
       "parametrizedLinkRatio                   -0.079485          -0.008652   \n",
       "spelling_errors_ratio                   -0.027888          -0.008599   \n",
       "label                                    0.083488           0.105964   \n",
       "\n",
       "                                commonlinkratio_4  compression_ratio  \\\n",
       "avglinksize                              0.134527          -0.003578   \n",
       "commonlinkratio_1                        0.388801          -0.017878   \n",
       "commonlinkratio_2                        0.555148          -0.032460   \n",
       "commonlinkratio_3                        0.850604          -0.016188   \n",
       "commonlinkratio_4                        1.000000          -0.020415   \n",
       "compression_ratio                       -0.020415           1.000000   \n",
       "embed_ratio                              0.005473          -0.889345   \n",
       "frameTagRatio                           -0.178064           0.159335   \n",
       "hasDomainLink                           -0.052519           0.027657   \n",
       "html_ratio                              -0.136561           0.106335   \n",
       "image_ratio                             -0.038071          -0.188976   \n",
       "lengthyLinkDomain                        0.287159          -0.090325   \n",
       "linkwordscore                            0.059223           0.146470   \n",
       "non_markup_alphanum_characters           0.162883          -0.064163   \n",
       "numberOfLinks                            0.233898          -0.055388   \n",
       "numwords_in_url                          0.026384          -0.042614   \n",
       "parametrizedLinkRatio                    0.036387          -0.033772   \n",
       "spelling_errors_ratio                   -0.013507           0.364122   \n",
       "label                                    0.080464          -0.059737   \n",
       "\n",
       "                                embed_ratio  frameTagRatio  hasDomainLink  \\\n",
       "avglinksize                        0.005254      -0.049270      -0.002046   \n",
       "commonlinkratio_1                  0.005280      -0.294860       0.006790   \n",
       "commonlinkratio_2                  0.019387      -0.259222       0.000263   \n",
       "commonlinkratio_3                  0.007578      -0.218559      -0.031097   \n",
       "commonlinkratio_4                  0.005473      -0.178064      -0.052519   \n",
       "compression_ratio                 -0.889345       0.159335       0.027657   \n",
       "embed_ratio                        1.000000      -0.130753      -0.026473   \n",
       "frameTagRatio                     -0.130753       1.000000       0.010193   \n",
       "hasDomainLink                     -0.026473       0.010193       1.000000   \n",
       "html_ratio                        -0.090938       0.384937       0.009665   \n",
       "image_ratio                        0.183808      -0.088847      -0.003890   \n",
       "lengthyLinkDomain                  0.075322      -0.196673       0.008579   \n",
       "linkwordscore                     -0.108476       0.158874       0.022583   \n",
       "non_markup_alphanum_characters     0.046484      -0.303682      -0.017361   \n",
       "numberOfLinks                      0.042942      -0.362491       0.013678   \n",
       "numwords_in_url                    0.043343       0.049330       0.058085   \n",
       "parametrizedLinkRatio              0.037361      -0.094557       0.051330   \n",
       "spelling_errors_ratio             -0.342206       0.033663       0.008718   \n",
       "label                              0.039536      -0.187762      -0.004863   \n",
       "\n",
       "                                html_ratio  image_ratio  lengthyLinkDomain  \\\n",
       "avglinksize                       0.018974    -0.003002           0.020852   \n",
       "commonlinkratio_1                -0.201501    -0.064435           0.421284   \n",
       "commonlinkratio_2                -0.159702    -0.044663           0.398817   \n",
       "commonlinkratio_3                -0.133370    -0.050357           0.363159   \n",
       "commonlinkratio_4                -0.136561    -0.038071           0.287159   \n",
       "compression_ratio                 0.106335    -0.188976          -0.090325   \n",
       "embed_ratio                      -0.090938     0.183808           0.075322   \n",
       "frameTagRatio                     0.384937    -0.088847          -0.196673   \n",
       "hasDomainLink                     0.009665    -0.003890           0.008579   \n",
       "html_ratio                        1.000000    -0.172924          -0.215809   \n",
       "image_ratio                      -0.172924     1.000000          -0.047652   \n",
       "lengthyLinkDomain                -0.215809    -0.047652           1.000000   \n",
       "linkwordscore                    -0.141363     0.051436           0.130844   \n",
       "non_markup_alphanum_characters   -0.136550    -0.026655           0.203278   \n",
       "numberOfLinks                    -0.455636     0.091977           0.307005   \n",
       "numwords_in_url                  -0.042001    -0.037265           0.229114   \n",
       "parametrizedLinkRatio            -0.183350     0.118549          -0.034653   \n",
       "spelling_errors_ratio             0.013860    -0.010975          -0.031943   \n",
       "label                            -0.051149    -0.017266           0.032824   \n",
       "\n",
       "                                linkwordscore  non_markup_alphanum_characters  \\\n",
       "avglinksize                          0.122550                       -0.010982   \n",
       "commonlinkratio_1                    0.257200                        0.193914   \n",
       "commonlinkratio_2                    0.257594                        0.177785   \n",
       "commonlinkratio_3                    0.109654                        0.264022   \n",
       "commonlinkratio_4                    0.059223                        0.162883   \n",
       "compression_ratio                    0.146470                       -0.064163   \n",
       "embed_ratio                         -0.108476                        0.046484   \n",
       "frameTagRatio                        0.158874                       -0.303682   \n",
       "hasDomainLink                        0.022583                       -0.017361   \n",
       "html_ratio                          -0.141363                       -0.136550   \n",
       "image_ratio                          0.051436                       -0.026655   \n",
       "lengthyLinkDomain                    0.130844                        0.203278   \n",
       "linkwordscore                        1.000000                       -0.379487   \n",
       "non_markup_alphanum_characters      -0.379487                        1.000000   \n",
       "numberOfLinks                        0.171880                        0.375584   \n",
       "numwords_in_url                     -0.011236                        0.076632   \n",
       "parametrizedLinkRatio               -0.000052                        0.012631   \n",
       "spelling_errors_ratio                0.025707                       -0.010207   \n",
       "label                               -0.173800                        0.097580   \n",
       "\n",
       "                                numberOfLinks  numwords_in_url  \\\n",
       "avglinksize                          0.000360        -0.033890   \n",
       "commonlinkratio_1                    0.317293         0.144354   \n",
       "commonlinkratio_2                    0.311492         0.096940   \n",
       "commonlinkratio_3                    0.283924         0.049203   \n",
       "commonlinkratio_4                    0.233898         0.026384   \n",
       "compression_ratio                   -0.055388        -0.042614   \n",
       "embed_ratio                          0.042942         0.043343   \n",
       "frameTagRatio                       -0.362491         0.049330   \n",
       "hasDomainLink                        0.013678         0.058085   \n",
       "html_ratio                          -0.455636        -0.042001   \n",
       "image_ratio                          0.091977        -0.037265   \n",
       "lengthyLinkDomain                    0.307005         0.229114   \n",
       "linkwordscore                        0.171880        -0.011236   \n",
       "non_markup_alphanum_characters       0.375584         0.076632   \n",
       "numberOfLinks                        1.000000         0.068791   \n",
       "numwords_in_url                      0.068791         1.000000   \n",
       "parametrizedLinkRatio                0.136482        -0.095363   \n",
       "spelling_errors_ratio                0.001343        -0.107631   \n",
       "label                                0.080187        -0.024823   \n",
       "\n",
       "                                parametrizedLinkRatio  spelling_errors_ratio  \\\n",
       "avglinksize                                  0.006089               0.035393   \n",
       "commonlinkratio_1                           -0.078026              -0.035019   \n",
       "commonlinkratio_2                           -0.079485              -0.027888   \n",
       "commonlinkratio_3                           -0.008652              -0.008599   \n",
       "commonlinkratio_4                            0.036387              -0.013507   \n",
       "compression_ratio                           -0.033772               0.364122   \n",
       "embed_ratio                                  0.037361              -0.342206   \n",
       "frameTagRatio                               -0.094557               0.033663   \n",
       "hasDomainLink                                0.051330               0.008718   \n",
       "html_ratio                                  -0.183350               0.013860   \n",
       "image_ratio                                  0.118549              -0.010975   \n",
       "lengthyLinkDomain                           -0.034653              -0.031943   \n",
       "linkwordscore                               -0.000052               0.025707   \n",
       "non_markup_alphanum_characters               0.012631              -0.010207   \n",
       "numberOfLinks                                0.136482               0.001343   \n",
       "numwords_in_url                             -0.095363              -0.107631   \n",
       "parametrizedLinkRatio                        1.000000              -0.007397   \n",
       "spelling_errors_ratio                       -0.007397               1.000000   \n",
       "label                                        0.010668              -0.058578   \n",
       "\n",
       "                                   label  \n",
       "avglinksize                     0.006172  \n",
       "commonlinkratio_1               0.083364  \n",
       "commonlinkratio_2               0.083488  \n",
       "commonlinkratio_3               0.105964  \n",
       "commonlinkratio_4               0.080464  \n",
       "compression_ratio              -0.059737  \n",
       "embed_ratio                     0.039536  \n",
       "frameTagRatio                  -0.187762  \n",
       "hasDomainLink                  -0.004863  \n",
       "html_ratio                     -0.051149  \n",
       "image_ratio                    -0.017266  \n",
       "lengthyLinkDomain               0.032824  \n",
       "linkwordscore                  -0.173800  \n",
       "non_markup_alphanum_characters  0.097580  \n",
       "numberOfLinks                   0.080187  \n",
       "numwords_in_url                -0.024823  \n",
       "parametrizedLinkRatio           0.010668  \n",
       "spelling_errors_ratio          -0.058578  \n",
       "label                           1.000000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "su_suba.corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Run a logistic regression predicting evergreen from the numeric columns and a categorical variable of alchemy_category\n",
    "\n",
    "And print out the results as shown in the example.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alchemy_category', 'alchemy_category_score', 'avglinksize',\n",
       "       'commonlinkratio_1', 'commonlinkratio_2', 'commonlinkratio_3',\n",
       "       'commonlinkratio_4', 'compression_ratio', 'embed_ratio',\n",
       "       'frameTagRatio', 'hasDomainLink', 'html_ratio', 'image_ratio',\n",
       "       'lengthyLinkDomain', 'linkwordscore', 'news_front_page',\n",
       "       'non_markup_alphanum_characters', 'numberOfLinks',\n",
       "       'numwords_in_url', 'parametrizedLinkRatio', 'spelling_errors_ratio',\n",
       "       'label'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "su_subb.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>embed_ratio</th>\n",
       "      <th>frameTagRatio</th>\n",
       "      <th>...</th>\n",
       "      <th>image_ratio</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.443783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  alchemy_category  alchemy_category_score  avglinksize  commonlinkratio_1  \\\n",
       "0         business                0.789131     2.055556           0.676471   \n",
       "\n",
       "   commonlinkratio_2  commonlinkratio_3  commonlinkratio_4  compression_ratio  \\\n",
       "0           0.205882           0.047059           0.023529           0.443783   \n",
       "\n",
       "   embed_ratio  frameTagRatio  ...    image_ratio  lengthyLinkDomain  \\\n",
       "0          0.0       0.090774  ...       0.003883                  1   \n",
       "\n",
       "   linkwordscore  news_front_page  non_markup_alphanum_characters  \\\n",
       "0             24              0.0                            5424   \n",
       "\n",
       "   numberOfLinks  numwords_in_url  parametrizedLinkRatio  \\\n",
       "0            170                8               0.152941   \n",
       "\n",
       "   spelling_errors_ratio  label  \n",
       "0                0.07913      0  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "su_subc = pd.DataFrame()\n",
    "su_subc = su_subb\n",
    "su_subc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.590719\n",
      "         Iterations: 35\n",
      "label ~ C(alchemy_category) + alchemy_category_score + avglinksize + commonlinkratio_1 + commonlinkratio_2 + commonlinkratio_3 + commonlinkratio_4 + compression_ratio + embed_ratio + frameTagRatio + hasDomainLink + html_ratio + image_ratio + lengthyLinkDomain + linkwordscore + news_front_page + non_markup_alphanum_characters + numberOfLinks + numwords_in_url + parametrizedLinkRatio + spelling_errors_ratio - 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#import statsmodels.formula.api as smf\n",
    "\n",
    "yc = su_subc['label']\n",
    "Xc = su_subc.drop(['label'], axis = 1)\n",
    "\n",
    "\n",
    "non_target_cols_c = [c for c in Xc.columns if c not in [\"label\", \"alchemy_category\"]]\n",
    "\n",
    "# Use some string adding and joining to make the simple model formula:\n",
    "formula_zc = 'label' + ' ~ C(alchemy_category) + ' + ' + '.join(non_target_cols_c) + ' - 1'\n",
    "formula_zc = str(formula_zc)\n",
    "\n",
    "logreg_c = smf.logit(formula_zc, data = su_subc)\n",
    "logreg_results_c = logreg_c.fit()\n",
    "\n",
    "print formula_zc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   No. Observations:                 4824\n",
      "Model:                          Logit   Df Residuals:                     4791\n",
      "Method:                           MLE   Df Model:                           32\n",
      "Date:                Tue, 17 May 2016   Pseudo R-squ.:                  0.1465\n",
      "Time:                        06:11:28   Log-Likelihood:                -2849.6\n",
      "converged:                      False   LL-Null:                       -3338.9\n",
      "                                        LLR p-value:                5.616e-185\n",
      "===========================================================================================================\n",
      "                                              coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "C(alchemy_category)[arts_entertainment]     1.0543      0.273      3.859      0.000         0.519     1.590\n",
      "C(alchemy_category)[business]               2.4150      0.275      8.774      0.000         1.875     2.954\n",
      "C(alchemy_category)[computer_internet]      0.6198      0.308      2.015      0.044         0.017     1.223\n",
      "C(alchemy_category)[culture_politics]       1.3427      0.286      4.694      0.000         0.782     1.903\n",
      "C(alchemy_category)[gaming]                 0.9201      0.360      2.556      0.011         0.214     1.626\n",
      "C(alchemy_category)[health]                 1.8845      0.295      6.382      0.000         1.306     2.463\n",
      "C(alchemy_category)[law_crime]              1.5701      0.493      3.187      0.001         0.605     2.536\n",
      "C(alchemy_category)[recreation]             2.3382      0.268      8.729      0.000         1.813     2.863\n",
      "C(alchemy_category)[religion]               1.3354      0.366      3.647      0.000         0.618     2.053\n",
      "C(alchemy_category)[science_technology]     1.2904      0.298      4.331      0.000         0.706     1.874\n",
      "C(alchemy_category)[sports]                 0.2784      0.299      0.931      0.352        -0.308     0.864\n",
      "C(alchemy_category)[unknown]                1.5692      0.976      1.608      0.108        -0.344     3.482\n",
      "C(alchemy_category)[weather]               -9.8005    186.560     -0.053      0.958      -375.452   355.851\n",
      "alchemy_category_score                     -0.5695      0.164     -3.464      0.001        -0.892    -0.247\n",
      "avglinksize                                 0.0044      0.004      1.242      0.214        -0.003     0.011\n",
      "commonlinkratio_1                           0.3031      0.299      1.013      0.311        -0.283     0.889\n",
      "commonlinkratio_2                           0.2506      0.509      0.493      0.622        -0.746     1.247\n",
      "commonlinkratio_3                           2.6657      0.961      2.774      0.006         0.782     4.549\n",
      "commonlinkratio_4                          -1.9475      0.978     -1.992      0.046        -3.864    -0.031\n",
      "compression_ratio                           0.0020      0.015      0.132      0.895        -0.028     0.032\n",
      "embed_ratio                                -0.3487      0.244     -1.430      0.153        -0.827     0.129\n",
      "frameTagRatio                              -7.4783      1.043     -7.172      0.000        -9.522    -5.435\n",
      "hasDomainLink                              -0.0835      0.226     -0.370      0.711        -0.526     0.359\n",
      "html_ratio                                 -0.1603      0.786     -0.204      0.838        -1.700     1.380\n",
      "image_ratio                                -0.0022      0.016     -0.139      0.889        -0.033     0.029\n",
      "lengthyLinkDomain                           0.1004      0.083      1.208      0.227        -0.062     0.263\n",
      "linkwordscore                              -0.0230      0.002     -9.656      0.000        -0.028    -0.018\n",
      "news_front_page                            -0.6413      0.163     -3.925      0.000        -0.961    -0.321\n",
      "non_markup_alphanum_characters          -1.382e-05   6.27e-06     -2.202      0.028     -2.61e-05 -1.52e-06\n",
      "numberOfLinks                               0.0007      0.000      2.266      0.023      9.33e-05     0.001\n",
      "numwords_in_url                            -0.0377      0.011     -3.419      0.001        -0.059    -0.016\n",
      "parametrizedLinkRatio                      -0.0491      0.190     -0.258      0.796        -0.421     0.323\n",
      "spelling_errors_ratio                      -3.3649      0.628     -5.355      0.000        -4.596    -2.133\n",
      "===========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print logreg_results_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.51332\n",
       "0    0.48668\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline => 51% vs 59% from model above\n",
    "baseline = ya.value_counts() / len(ya)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use sklearn to cross-validate the accuracy of the model above\n",
    "\n",
    "Normalize the numeric and categorical columns of the predictor matrix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Score: 0.661658031088\n",
      "0.661658031088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import patsy\n",
    "from patsy import dmatrices\n",
    "\n",
    "yb, Xb = dmatrices(formula_zc, data = su_subc, return_type='dataframe')\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Better estimate of training accuracy of out of sample performance\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    Xb, yb, test_size=0.4, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "#fit a model on the training data and test on the testing data\n",
    "model = logreg.fit(X_train, y_train)\n",
    "print model\n",
    "predictions = logreg.predict(X_test)\n",
    "\n",
    "print \"Score:\", model.score(X_test, y_test)     \n",
    "print accuracy_score(y_test, predictions)\n",
    "\n",
    "#66% is a better fit with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Score: 0.687046632124\n",
      "0.687046632124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#normalize predictor matrix- doesn't really change anything...\n",
    "\n",
    "nc = [x for x in Xb.columns]\n",
    "\n",
    "yb, Xb = dmatrices(formula_zc, data = su_subc, return_type='dataframe')\n",
    "\n",
    "#NORMALIZE\n",
    "Xb.ix[:, nc] = (Xb.ix[:, nc] - Xb.ix[:, nc].mean()) / Xb.ix[:, nc].std()\n",
    "\n",
    "# Better estimate of training accuracy of out of sample performance\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    Xb, yb, test_size=0.4, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "#fit a model on the training data and test on the testing data\n",
    "model = logreg.fit(X_train, y_train)\n",
    "print model\n",
    "predictions = logreg.predict(X_test)\n",
    "\n",
    "print \"Score:\", model.score(X_test, y_test)     \n",
    "print accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.610279520202\n",
      "0.00692960061803\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "model = logreg.fit(Xb, yb)\n",
    "\n",
    "ya = su_suba['label']\n",
    "Xa = su_suba.drop(['label'], axis = 1)\n",
    "\n",
    "scores = cross_val_score(logreg, Xa, ya, cv=5)\n",
    "print scores.mean()\n",
    "print scores.std()\n",
    "\n",
    "#lower score before cv, 0.69, may have had overffiting before cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653858\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from patsy import dmatrices\n",
    "\n",
    "y, X = dmatrices(formula_za, data = su_suba)\n",
    "Y = np.ravel(y)\n",
    "\n",
    "logreg_a = smf.logit(formula_za, data = su_suba)\n",
    "logreg_results_a = logreg_a.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gridsearch regularization parameters for logistic regression\n",
    "\n",
    "Find the best regularization type (Ridge, Lasso) across a set of regularization strengths.\n",
    "\n",
    "[NOTE: C is the inverse of the regularization strength. Lower C values are stronger regularization. Having a C higher than 1 will significantly slow down the search. I'm not particularly interested in values over 1, since this is the default regularization strength in LogisticRegression.]\n",
    "\n",
    "**After you find the best set of parameters, build a Logistic Regression with those parameters and crossvalidate the score.**\n",
    "\n",
    "[NOTE 2: to run Lasso regularization the solver should be `'liblinear'`]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grid Search with Ridge Regularization\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "ridgemodel = Ridge() #Ridge\n",
    "\n",
    "#Prepare a Range of Alpha Values to Test\n",
    "alphas = np.array([1000,100, 10, 1,0.1,0.01,0.001,0.0001,0])\n",
    "\n",
    "estim_ridge = GridSearchCV(estimator=ridgemodel, param_grid=dict(alpha=alphas)) #Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([  1.00000e+03,   1.00000e+02,   1.00000e+01,   1.00000e+00,\n",
       "         1.00000e-01,   1.00000e-02,   1.00000e-03,   1.00000e-04,\n",
       "         0.00000e+00])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estim_ridge.fit(Xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([  1.00000e+03,   1.00000e+02,   1.00000e+01,   1.00000e+00,\n",
      "         1.00000e-01,   1.00000e-02,   1.00000e-03,   1.00000e-04,\n",
      "         0.00000e+00])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "0.172935743591\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(estim_ridge)\n",
    "\n",
    "#Summarize the Results of the Grid Search\n",
    "print(estim_ridge.best_score_)\n",
    "print(estim_ridge.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 100.0}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = estim_ridge.fit(Xb,yb)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.16859, std: 0.01345, params: {'alpha': 1000.0},\n",
       " mean: 0.17294, std: 0.01702, params: {'alpha': 100.0},\n",
       " mean: 0.17233, std: 0.01739, params: {'alpha': 10.0},\n",
       " mean: 0.17224, std: 0.01742, params: {'alpha': 1.0},\n",
       " mean: 0.17223, std: 0.01742, params: {'alpha': 0.10000000000000001},\n",
       " mean: 0.17223, std: 0.01742, params: {'alpha': 0.01},\n",
       " mean: 0.17223, std: 0.01742, params: {'alpha': 0.001},\n",
       " mean: 0.17223, std: 0.01742, params: {'alpha': 0.0001},\n",
       " mean: 0.17137, std: 0.01743, params: {'alpha': 0.0}]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-7a347ced3528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mestim_lasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlassomodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Lasso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#estim_lasso = GridSearchCV(estimator=lassomodel, search_parameters) #Lasso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestim_lasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mya\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1581\u001b[0m                       \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m                       )\n\u001b[0;32m-> 1583\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m             for train, test in folds)\n\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[0;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, copy, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0mcoefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0mwarm_start_sag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'coef'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "nc = [x for x in Xb.columns]\n",
    "\n",
    "yb, Xb = dmatrices(formula_zc, data = su_subc, return_type='dataframe')\n",
    "\n",
    "Xb.ix[:, nc] = (Xb.ix[:, nc] - Xb.ix[:, nc].mean()) / Xb.ix[:, nc].std()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lassomodel = LogisticRegressionCV(solver='liblinear', refit=True, penalty='l2', cv=5, scoring='average_precision') # Lasso\n",
    "\n",
    "\n",
    "#Prepare a Range of Alpha Values to Test\n",
    "alphas = np.array([1000,100, 10, 1,0.1,0.01,0.001,0.0001,0])\n",
    "\n",
    "search_parameters = {\n",
    "    \"penalty\":             ['l1','l2'],   # Used to specify the norm used in the penalization.\n",
    "    \"Cs\":                   [0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5]  # Regularization paramter -- totally out of bounds but we will try it\n",
    "}\n",
    "\n",
    "yb= su_subc['label']\n",
    "\n",
    "estim_lasso = GridSearchCV(estimator=lassomodel, param_grid=dict(Cs=alphas)) #Lasso\n",
    "#estim_lasso = GridSearchCV(estimator=lassomodel, search_parameters) #Lasso\n",
    "grid = estim_lasso.fit(Xa,ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n",
      "/Users/noriogura/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression() #Normal logistic regression\n",
    "\n",
    "search_parameters = {\n",
    "    \"penalty\":             ['l1','l2'],   # Used to specify the norm used in the penalization.\n",
    "    \"C\":                   [0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5],  # Regularization paramter -- totally out of bounds but we will try it\n",
    "    #\"dual\":                [True, False], # Dual or primal formulation. Dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=False when n_samples > n_features\n",
    "    \"fit_intercept\":       [False, True], # Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.\n",
    "    \"class_weight\":        [None, \"balanced\", \"auto\"], # The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))\n",
    "    \"intercept_scaling\":   [2, 1],        # Useful only if solver is liblinear. when self.fit_intercept is True, instance vector x becomes [x, self.intercept_scaling], i.e. a “synthetic” feature with constant value equals to intercept_scaling is appended to the instance vector. \n",
    "    \"solver\":              ['liblinear'],\n",
    "    \"warm_start\":          [False, True]\n",
    "}\n",
    "\n",
    "estim_log = GridSearchCV(logistic, search_parameters) #Logistic\n",
    "grid = estim_log.fit(Xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.51427, std: 0.00138, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.51427, std: 0.00138, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.59162, std: 0.00580, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.59162, std: 0.00580, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.51427, std: 0.00138, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.51427, std: 0.00138, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.59162, std: 0.00580, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.59162, std: 0.00580, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.51427, std: 0.00138, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.51427, std: 0.00138, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.59459, std: 0.00471, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.59459, std: 0.00471, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.51427, std: 0.00138, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.51427, std: 0.00138, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.59324, std: 0.00491, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.59324, std: 0.00491, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.58404, std: 0.00630, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58350, std: 0.00583, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58607, std: 0.00538, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58607, std: 0.00538, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58404, std: 0.00625, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58418, std: 0.00637, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58607, std: 0.00538, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58607, std: 0.00538, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58418, std: 0.00580, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58323, std: 0.00564, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58851, std: 0.00593, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58851, std: 0.00593, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58323, std: 0.00564, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58350, std: 0.00584, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58661, std: 0.00514, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58661, std: 0.00514, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58350, std: 0.00612, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58391, std: 0.00644, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58661, std: 0.00507, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58661, std: 0.00507, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58350, std: 0.00612, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58296, std: 0.00661, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58661, std: 0.00507, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58661, std: 0.00507, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58350, std: 0.00612, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58337, std: 0.00663, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58945, std: 0.00610, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58945, std: 0.00610, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58418, std: 0.00517, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58337, std: 0.00617, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58634, std: 0.00479, params: {'warm_start': False, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58634, std: 0.00479, params: {'warm_start': True, 'C': 0.0001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58824, std: 0.00588, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.58810, std: 0.00570, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.59811, std: 0.00452, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.59811, std: 0.00452, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.58810, std: 0.00570, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.58824, std: 0.00588, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.59811, std: 0.00452, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.59811, std: 0.00452, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.58824, std: 0.00588, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.58810, std: 0.00570, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61028, std: 0.00198, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61028, std: 0.00198, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.58824, std: 0.00588, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.58810, std: 0.00570, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.60609, std: 0.00345, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.60609, std: 0.00345, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58932, std: 0.00358, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58932, std: 0.00358, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58932, std: 0.00358, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58932, std: 0.00358, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.60433, std: 0.00542, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.60433, std: 0.00542, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.59865, std: 0.00377, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.59865, std: 0.00377, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.59067, std: 0.00442, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.59067, std: 0.00442, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.59067, std: 0.00442, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.59067, std: 0.00442, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.60203, std: 0.00377, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.60203, std: 0.00377, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58377, std: 0.00707, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.59851, std: 0.00370, params: {'warm_start': False, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.59851, std: 0.00370, params: {'warm_start': True, 'C': 0.001, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58878, std: 0.00456, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.58878, std: 0.00456, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.60581, std: 0.00948, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.60581, std: 0.00948, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.58878, std: 0.00456, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.58878, std: 0.00456, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.60581, std: 0.00948, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.60581, std: 0.00948, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.60798, std: 0.00448, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.60784, std: 0.00455, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61163, std: 0.00437, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61163, std: 0.00437, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.58878, std: 0.00456, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.58891, std: 0.00468, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61285, std: 0.00095, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61285, std: 0.00095, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.58540, std: 0.00621, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58526, std: 0.00679, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.60798, std: 0.00432, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.60798, std: 0.00432, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58540, std: 0.00643, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58540, std: 0.00653, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.60798, std: 0.00432, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.60798, std: 0.00432, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.60162, std: 0.00607, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.60149, std: 0.00605, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.60987, std: 0.00261, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.60987, std: 0.00261, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58526, std: 0.00615, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.58553, std: 0.00639, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.60960, std: 0.00404, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.60960, std: 0.00404, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.58553, std: 0.00639, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58553, std: 0.00639, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.60379, std: 0.00695, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.60379, std: 0.00695, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58540, std: 0.00621, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58553, std: 0.00639, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.60379, std: 0.00695, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.60379, std: 0.00695, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.60122, std: 0.00541, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.60162, std: 0.00588, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61231, std: 0.00523, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61231, std: 0.00523, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.58513, std: 0.00661, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.58540, std: 0.00653, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.60865, std: 0.00670, params: {'warm_start': False, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.60865, std: 0.00670, params: {'warm_start': True, 'C': 0.01, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61988, std: 0.00305, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62028, std: 0.00276, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61028, std: 0.01183, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61028, std: 0.01183, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61988, std: 0.00219, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62028, std: 0.00220, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61028, std: 0.01183, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61028, std: 0.01183, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61717, std: 0.00110, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61677, std: 0.00130, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.60987, std: 0.00227, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.60987, std: 0.00227, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61853, std: 0.00085, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61880, std: 0.00066, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61812, std: 0.00232, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61812, std: 0.00232, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61515, std: 0.00111, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61542, std: 0.00127, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.60838, std: 0.00451, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.60838, std: 0.00451, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61582, std: 0.00213, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61582, std: 0.00134, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.60838, std: 0.00451, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.60838, std: 0.00451, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61744, std: 0.00146, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61690, std: 0.00106, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61122, std: 0.00404, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61122, std: 0.00404, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61650, std: 0.00071, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61623, std: 0.00047, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61596, std: 0.00774, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61596, std: 0.00774, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61515, std: 0.00111, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61542, std: 0.00148, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61014, std: 0.00390, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61014, std: 0.00390, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61542, std: 0.00134, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61515, std: 0.00126, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61014, std: 0.00390, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61014, std: 0.00390, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61663, std: 0.00115, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61704, std: 0.00124, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61122, std: 0.00397, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61122, std: 0.00397, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61596, std: 0.00121, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61650, std: 0.00085, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.60947, std: 0.00143, params: {'warm_start': False, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.60947, std: 0.00143, params: {'warm_start': True, 'C': 0.1, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61866, std: 0.01052, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61920, std: 0.01071, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61880, std: 0.00445, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61880, std: 0.00445, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61880, std: 0.01072, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61866, std: 0.01053, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61880, std: 0.00445, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61880, std: 0.00445, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62312, std: 0.00707, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62204, std: 0.00726, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61176, std: 0.00624, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61176, std: 0.00624, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62285, std: 0.00787, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62231, std: 0.00798, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61880, std: 0.00208, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61880, std: 0.00208, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62110, std: 0.00391, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62137, std: 0.00372, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61433, std: 0.00266, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61433, std: 0.00266, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62110, std: 0.00420, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62123, std: 0.00381, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61433, std: 0.00266, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61433, std: 0.00266, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62353, std: 0.00773, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62339, std: 0.00806, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61190, std: 0.00247, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61190, std: 0.00247, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62299, std: 0.00707, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62326, std: 0.00723, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61542, std: 0.00820, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61542, std: 0.00820, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62164, std: 0.00411, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62082, std: 0.00410, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61095, std: 0.00585, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61095, std: 0.00585, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62137, std: 0.00429, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62082, std: 0.00296, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61095, std: 0.00585, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61095, std: 0.00585, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62326, std: 0.00789, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62339, std: 0.00806, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61731, std: 0.00759, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61731, std: 0.00759, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62407, std: 0.00807, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62312, std: 0.00691, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61393, std: 0.00592, params: {'warm_start': False, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61393, std: 0.00592, params: {'warm_start': True, 'C': 0.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62028, std: 0.01080, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62042, std: 0.01071, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.60987, std: 0.00596, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.60987, std: 0.00596, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62042, std: 0.01071, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62028, std: 0.01053, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.60987, std: 0.00596, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.60987, std: 0.00596, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62299, std: 0.00659, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62245, std: 0.00555, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61028, std: 0.00309, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61028, std: 0.00309, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62218, std: 0.00661, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62272, std: 0.00623, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61758, std: 0.00650, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61758, std: 0.00650, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62231, std: 0.00622, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62258, std: 0.00632, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61501, std: 0.00303, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61501, std: 0.00303, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62218, std: 0.00632, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62258, std: 0.00632, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61501, std: 0.00303, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61501, std: 0.00303, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62272, std: 0.00710, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62353, std: 0.00706, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61339, std: 0.00489, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61339, std: 0.00489, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62366, std: 0.00723, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62461, std: 0.00844, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61447, std: 0.00391, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61447, std: 0.00391, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62245, std: 0.00613, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62245, std: 0.00641, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.60947, std: 0.00337, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.60947, std: 0.00337, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62231, std: 0.00649, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62231, std: 0.00649, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.60947, std: 0.00337, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.60947, std: 0.00337, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62272, std: 0.00710, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62339, std: 0.00766, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61109, std: 0.00421, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61109, std: 0.00421, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62312, std: 0.00763, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62421, std: 0.00773, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61420, std: 0.00493, params: {'warm_start': False, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61420, std: 0.00493, params: {'warm_start': True, 'C': 0.75, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62082, std: 0.01099, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62096, std: 0.01146, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.60974, std: 0.01083, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.60974, std: 0.01083, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62123, std: 0.01185, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62055, std: 0.01119, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.60974, std: 0.01083, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.60974, std: 0.01083, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62353, std: 0.00592, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62312, std: 0.00636, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61420, std: 0.00433, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61420, std: 0.00433, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62353, std: 0.00592, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62285, std: 0.00642, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61582, std: 0.00672, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61582, std: 0.00672, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62421, std: 0.00755, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62394, std: 0.00780, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.60960, std: 0.00551, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.60960, std: 0.00551, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62326, std: 0.00750, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62421, std: 0.00736, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.60960, std: 0.00551, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.60960, std: 0.00551, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62475, std: 0.00575, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62502, std: 0.00640, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61582, std: 0.00216, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61582, std: 0.00216, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62502, std: 0.00623, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62502, std: 0.00674, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61366, std: 0.00627, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61366, std: 0.00627, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62366, std: 0.00711, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62366, std: 0.00679, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61285, std: 0.00232, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61285, std: 0.00232, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62421, std: 0.00755, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62353, std: 0.00686, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61285, std: 0.00232, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61285, std: 0.00232, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62448, std: 0.00624, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62488, std: 0.00591, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61204, std: 0.00457, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61204, std: 0.00457, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62529, std: 0.00690, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62475, std: 0.00607, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61744, std: 0.00314, params: {'warm_start': False, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61744, std: 0.00314, params: {'warm_start': True, 'C': 1.0, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62191, std: 0.00944, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62191, std: 0.00883, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.60947, std: 0.01091, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.60947, std: 0.01091, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62218, std: 0.00987, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62218, std: 0.00956, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.60947, std: 0.01091, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.60947, std: 0.01091, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62407, std: 0.00612, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62299, std: 0.00544, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.60784, std: 0.00148, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.60784, std: 0.00148, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62421, std: 0.00602, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.62448, std: 0.00612, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None},\n",
       " mean: 0.61826, std: 0.00352, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.61826, std: 0.00352, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None},\n",
       " mean: 0.62366, std: 0.00841, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62339, std: 0.00832, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61095, std: 0.00332, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61095, std: 0.00332, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62339, std: 0.00802, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62353, std: 0.00822, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61095, std: 0.00332, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61095, std: 0.00332, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62461, std: 0.00495, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62596, std: 0.00516, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.60987, std: 0.00305, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.60987, std: 0.00305, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62596, std: 0.00516, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.62623, std: 0.00460, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'balanced'},\n",
       " mean: 0.61893, std: 0.00260, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.61893, std: 0.00260, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'balanced'},\n",
       " mean: 0.62353, std: 0.00822, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62353, std: 0.00822, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61190, std: 0.00519, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61190, std: 0.00519, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62312, std: 0.00823, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62353, std: 0.00822, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61190, std: 0.00519, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61190, std: 0.00519, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': False, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62610, std: 0.00520, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62637, std: 0.00476, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61149, std: 0.00323, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61149, std: 0.00323, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.62556, std: 0.00571, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.62542, std: 0.00451, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': 'auto'},\n",
       " mean: 0.61447, std: 0.00526, params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'},\n",
       " mean: 0.61447, std: 0.00526, params: {'warm_start': True, 'C': 2.5, 'intercept_scaling': 1, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': 'auto'}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.691749585406\n",
      "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=2, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "{'warm_start': False, 'C': 0.5, 'intercept_scaling': 2, 'fit_intercept': True, 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "print(estim_log.best_score_)\n",
    "print(estim_log.best_estimator_)\n",
    "print(estim_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gridsearch neighbors for kNN\n",
    "\n",
    "Find the best number of neighbors with your predictors to predict the `label` target variable.\n",
    "\n",
    "Start by bulding a kNN model with a set number of neighbors, then use gridsearch to run through a series of neighbors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "[ 0.67701863  0.69151139  0.67080745  0.68944099  0.65560166  0.68879668\n",
      "  0.68257261  0.67427386  0.67427386  0.67842324]\n",
      "0.678272037662\n",
      "0.779021558872\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with K=5 for KNN neighbors parameter\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors =5)\n",
    "scores = cross_val_score(knn, Xb, yb, cv=10, scoring='accuracy')\n",
    "#estimate of out of sample accuracy\n",
    "print knn\n",
    "print scores\n",
    "print scores.mean()\n",
    "\n",
    "knn.fit(Xb,yb)\n",
    "y_pred = knn.predict(Xb)\n",
    "print metrics.accuracy_score(yb, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Range of neighbors 1-30\n",
    "k_range = range(1,31)\n",
    "\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "param_grid\n",
    "\n",
    "#instantiate grid\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "#fit grid with data\n",
    "grid.fit(Xb,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1271a6ed0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAERCAYAAABowZDXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4FNfVwOHfqiMk0QSI3jl0jOjNYIwbLnHsxA5x7y12\nYifOZ1JdEyeO7cSJncTGvbe4G4yNTTFFpncdiuggBEKNor7fH7OSF6EyAi3alc77PDxodnZmzmph\nz965957r8Xq9GGOMMTUJq+8AjDHGhAZLGMYYY1yxhGGMMcYVSxjGGGNcsYRhjDHGFUsYxhhjXIkI\n5MlFxAM8AwwG8oEbVTXNt68t8BbgBTzAacD/Ac9VdYwxxpj6E+gWxsVAtKqOAaYBT5TtUNV9qnqG\nqk7y7VuGkyyqPMYYY0z9CXTCGAfMBFDVFGBYFc/7J3CrqnprcYwxxphTKNAJIwHI8dsuFpFjriki\nFwJrVXWz22OMMcacegHtwwBygXi/7TBVLa3wnCuBv9fymHIiEg0MB/YCJScXrjHGNBrhQDtgiaoW\nuDkg0AljAXAB8J6IjALWVPKcYaq6qJbH+BsOzK+LYI0xphEaD3zr5omBThgfAGeJyALf9nUiMhVo\nqqrTRSSRY28/VXpMDdfYC/D666+TlJRUV3EbY0yDlp6ezhVXXAG+z1A3ApowfJ3Yt1V4eKPf/gNA\nsotjqlMCkJSURMeOHU8wUmOMabRc38q3zmRjjDGuWMIwxhjjiiUMY4wxrljCMMYY44olDGOMMa5Y\nwjDGGOOKJQxjjDGuWMIwpoErKamyso4xtWIJw5gGLCs3n+sfnsVjry6l2BKHOUmWMIxpwGZ9t52D\nuQXMW7mbJ99YTkmpt75DMiEs0LWkjDH1pKTUy6zF24mJCqdruwTmrdxNZGQYd102hLAwT32HZ0KQ\ntTCMaaBWaAYZWUeZkNyR+28aTc9OzZm9ZCf/+WA1Xq+1NEztWcIwpoGauWgbAOeO6krTJpE8ePNo\nurVPYMbCbTz/8TpLGqbWLGEY0wBl5hxlyYZ99OzYjJ6dmgMQHxvFQ7eMoVPbOD6at4XXZqbWc5Qm\n1FjCMKYBmpWyg9JSL+eO7nrM483ionn41rG0S2zKO19t5O2vtH4CNCHJEoYxQaCwqIQ1Ww7UyW2i\nklIvs1K20yQ6gtOHHL9GTMuEGB6+dQxtWjThtRmpfDh380lf0zQOljCMqWclJaX86aXv+M0zC/hk\nftpJn29Z6j4OZB9lYnJHmkRXPhCyTYtYHrltLK2axfD8x+v4bMFW9/GWetm4I4u3v1K+TNl+0vGa\n0GHDao2pZ9M/Wsuy1AwA3vpSmTSsE3GxUSd8vvLO7gq3oypKatWUh28dw7RnFvCf/60mKiKMs0Z2\nqfS5mTlHWZ6awYqN+1m5MYO8I0Xl+3p2ak639s1OOF4TOqyFYUw9+mR+Gp8u2EqXpHguP6s3eUeK\nePurjTUfWIX9WUdZtmEfvTo1p3uHmj/EO7aJ5+FbxhAfG8U/313JnOW7ACgoKmG5ZvD8x2u547Gv\nufbBWTz1zkrmr9xNdGQ4Z43ozE/PFgBet87zRsNaGMbUkyXr05n+0Rqax0fzhxtG0Tw+mm+W7eLT\nb7dy/thuJLVqWutzzkrZTqm35taFvy7tEnjwltH87t8LePLN5XyZsp3UbQcpLHZKiURFhpPcpw3J\n0oYhvVvTqW08Ho8Hr9fLyk37SVmXjm4/iHRpWet4TWixFoYx9WDrnhwee20pEeFh/P76kbRpGUtU\nZDjXTOlLcUkpL3+2vtbnLCkp5cvvthMbE8Hpp3Wo1bE9OzbngZtHEx0ZzurNB2jfOo4fTuzJQ7eM\n5s2HzuOBm0bzg9N70DkpAY/HmSXu8Xi48ry+ADZEt5GwFoapU6WlXnIOF9AiPqa+QwlaB3PzeXD6\nYo4WlHDf1cPp3blF+b7xp3Xg43lpfLtqDz/YdpA+Xd1/a1+6YR+ZOflMGdOVmCo6u6sjXVryn/vO\nBJyRVG4M7JHIab1bs3LjftZsOcDAHom1vq4JHdbCMHXq1RkbuPr+L3jrS63TmcRFxaV8u2o369Iy\nQ7pcd35hMQ+9kMKBnHyuntKXsYPbH7Pf4/Fw/UX9AXj+47W1+h3OXOyMWKrN7aiKWibEuE4WZa48\ntw8Ar83YYLPHGzhrYZg6k19QzOcLneGZr89MZUd6Hj//yRCiI8NP6rwZB4/wl1eXsHFHNgCxMREM\n7tWaIb1bM0TanNC9/vpQWurliTeWs3lnNpOHd+ZHk3pV+rx+3VoxZlA7Fq7ey4LVexg3uObbSxkH\nj7AsdR/SpcUpH7EkXVoyol8S361PZ4XuJ7lPm1N6fXPqWMIwdWbuil0cyS/m/LHdSNudw/yVu9mb\neZjfXTeCVs2anNA5l6xP54k3lnPoaBGnn9aBuNhIVuh+Fq3Zy6I1ewFon9jU6ZCVNgzsmVjl3IP6\n9srn61m0Zi8DeyRy+48Gl/cFVOaa8/vx3bp0Xv5sPSP7JxEZUX3SnZWyHa/XqRtVH644tw/frU/n\n1ZkbGCKtq31tJnQF5/8sE3K8Xi+fL9hGWJiHH5/Zi4SmUTzz3mq+WrKDe/4+l99eN/KYe/U1KSkp\n5bWZqbz39SYiI8L42Y8Hc/bILuUfRHsPHGbFxgyWp2awevMBPl2wlU8XbCUi3EPfrq0YIq05e2QX\nmsVFB+ol18qslO28/81mOrRuyrRrhxMZUf3d4PaJcUwZ242P56Xx2YKtXDyhZ5XPLfZ1djeNiWDc\nae2rfF4gde/QjHGD2/Ptqj0sXpvO6IHt6iUOE1iWMEyd0O1ZpO3JYcygduWtibsuP40u7eJ58ZN1\nTHv6W+66fAgTko8vVVFRZs5RHnttGevSMmnXqin3XTP8uDkF7RKb0i6xG1PGdKO4pJTUbQdZsXE/\nyzWDtWkHWLPlAPNW7OaJX5xe47fzQFu1aT/PvLeK+NhI/nDjKOJdTsr7yVnC7CU7eevLjZw5vHOV\nxy1Zn87B3AIuGNeNmKj6+y/903P6sHD1Hl6fuYGR/ZNszY0GyDq9TZ34zNd3MWVMt/LHPB4PF0/o\nye9vGEV4eBh/e30Zr83YQGk1q76t2rSfXzwxl3VpmYwZ1I4n755Q4wS0iPAwBvRI5Krz+vLkLybw\n6v3nMmlYJ7btzeWNL+q3uN7OfXn8+eUleDzw2+tG0j4xzvWx8bFR/OSs3hw+WsRbX1b9OmYuOvnO\n7rrQqW08E4d2Ynt6Ht+u2n3C5/lufToPPZ9CeubhOozO1AVLGOak5Rwq4NuVe+jQOo5BPY8fVjms\nb1v+dtd4klrF8vZXG3n0lSUcLSg+5jmlpV7e+lL5w38XknekkJt+MID7rh5O0yaRtY6nWVw0t14y\niKRWsfzvm02s35p5wq/tZGRkHeHB5xdz+GgRd142hP7dW9X6HM4Evlg+X7CVPQcOHbc/PdO5Nde3\na0u6JCXURdgnZerZQniYhze+SD2h0WzzV+zmkRe/47v16Tz6yhIKi0oCEKU5UQFtv4qIB3gGGAzk\nAzeqaprf/uHA477NdOBK388vAt2BHOAOVd0SyDjNyfnqux0Ul5QyZUzXKjs7Oycl8PjPJ/Doy0tY\ntGYv6Znz+d31I2nTIpacQwU88cZylmsGic2b8H9XD6PPSc4abhIdwd1Tk5n29Lc8+eZynvrlGQHv\nDC8sKmH91kxWqHNrbNveXAAuP6s3k4Z1OqFzRkaEc835/fjLK0t5+bP1TLtmxDH7yzu7R1deA+pU\nS2rVlLNGdmHmom18s2wnk0e4j2v2kh089fYKYqIj6Nu1JctSM5j+0Vpu/9HgwAVsaiXQLYyLgWhV\nHQNMA56osP9Z4FpVPR2YCXQBbgLyVHU0cBfwdIBjNCehpNTLjEXbiIoMZ9LwztU+N6FpFA/eMppz\nR3dl655cfvn3ecxctI2fPzGH5ZrBsL5t+cc9E086WZTp160Vl5zRi/TMIzz/8do6Oac/r9fLzn15\nfDxvC/c/t4ipv5/B7/+7iP/N2czu/Yc4rXdrbr90EFec0+ekrjN2UHukSwsWrt57TGvJ6ezeQVyT\nSMa6GHp7qlw+uTeREWG8OUspKnbXypi5aBt/f2sFsTGRPHzrGO67Zjhd2yUwY9G28vpWwcrr9fLu\n7I28+Mm641rODU2ge8jG4SQCVDVFRIaV7RCR3kAmcI+IDAA+VdVNIvILYIbvmI0i0jfAMZqTsEIz\n2HfwCGeP7EKci9tHEeFh3H7pILokxfPcR2t5+r1VhHng6il9ufSMXnXeUfrTc4SlG/bxxeLtjBrQ\njmF9257U+fILilmWmsFyzWDFxgz2Zx0t39c5KZ4hvZ2aS/17tDrp+SdlPB4PN1w4gF//az4vfLyO\nx+4aj8fjIWVtOtl5BVw0vnudXasuJDZvwnljuvLxvDRmpWzn/LHdqn3+x/O38NyHa2kW56wIWDaP\n5L5rhnP3k3N5+t2V9OjQjE5t408qrs27snn89WWM7J/E1VP61cm/tdJSL//532pmLNoGwKI1e7l7\najJ9u538l55DR4t49fP1rNlygN9dX7v+r0AJdAsjAee2UpliESm7ZiIwGngKmAxMFpGJwArgAgAR\nGQW0993aMkGobB2F88Z0dX2Mx+PhgnHduf/GUQzr25aHbx3Lj8/sHZBRNZER4dzz02QiwsN46u0V\n5BwqOOFzpWce5q4n5vDoK0uYlbKd/IJixg1uz12XncaLvz+bp++dxI0/GEBynzZ1/gHet1tLxg5u\nj+7I4tuVewD3Zczrw48m9SI6Kpx3vlIKqumHeP/rTTz34VpaJkTzp9vGHjPpsEPrOO66/DTyC0v4\n88tLyD+Jb++p2w/yu38vYFfGId7/ZjOPv7GMouKT6x8pKfXy1DsrmLFoG93bN+PiCT1IP3iY+56e\nzyufr3fduqrI6/Uyf8Vubv/LbD5fuI2d+w4x/aO6byGfiEC3MHIB/68FYapa9lvMBDar6kYAEZkJ\nDMO5bdVPROYBC4Blqmr1BoJQeubh8tnFPTs2r/XxQ3yT7QKtW/tmXHluH176bD3/fn81/3f1sFpP\nLNu8K5sHnltM9qECpozpypnDO9OjY3PCT+HQ0Wum9CNl7V5e+nw9XdrFs3LTfvp3b3XS37wDoUV8\nDBeO6857X29ixsLj55F4vV7e+nIjb3yRSmKzGB65bSztWx//DXrc4A6sG5fJp99u5en3V3HP1ORa\nv3drtxzgwecXU1BUyu2XDuKbZbuYt2I3OYcK+M21I4iNqf3AipKSUp54cznzVuymVyencGN8bBSj\nBrTjyTeX8+7sTSzbkME9P02mSzv3gxHSMw/z7/dXs1wziIoI46rz+rJy436WrN/HstR9DO1zci3k\nkxXoFsYCYAqUtxbW+O1LA+JEpLtvezywDhgBzPb1a7zne54JQjMXbcPrPXYobbC6eGJP+nZtyYLV\ne5i7onZDPldoBr955ltyDhdw6yWDuO3SwfTu3OKUJgtw5p5cMK47GQeP8MD0xQCcOyo4Orsrc8kZ\nPYmNieDd2Zs4kv/9gkter5dXZ2zgjS9Sadsylj/fMa7SZFHm+gsH0Ltzc+Ys28WsWq7wt3JjBn98\nbjFFxaX8+qphnDemGw/dOoaR/ZNYtekA055eQFZufq3OWVRcyl9eXcq8Fbvp27UlD/nWEwHo370V\nT/1yImeP7ELanhx+8eRcPpizudqh5GXnfOerjdzx169ZrhkkSxv+de8kLpvcm5suHkCYx1loq7ie\n66gFOmF8ABSIyAKc0VB3i8hUEblRVYuAG4A3RSQF2KGqM4BNwC9EZCHwIHBPgGM0J6CwqIQvv9tB\nfGwU4wbXz+zi2ggP83D31GRiosL5z/9WcyD7aM0HAXOW7eSB6YspLvFy39XDa7wfH2iXTe5NXJNI\nMrKOEh8bxZhBwfu7j4+N4uIJPck9XMgn3zrf+7xeL9M/Xsu7szfRPrEpf759XI21wCIjwvi/q4YT\n1ySS/36whi27sl1df+mGfTz4fAqlpV6mXTuCsb7fVXRkONOuGc45o5wP9Xv/OZ/d+48fslyZwqIS\n/vTSdyxas5dBPRN54ObRxw39jo2J5M7LTuP3148krkkkL3yyjt/+ZwH7Dh6p9Jzr0jL5+RNzeHXG\nBmKbRHLvlUO5/6ZRtEt0fi/d2jfjnNFd2ZVxiM9rsZRuIHhCvbqkiHQFts6ePZuOHWueRWzqxjfL\ndvLEG8u5ZGJPrruwf32H49oXi7fxr3dXcVqv1jxw8+hq+00+mLOZFz5ZR9OYCH53/UgGBEnp7o/m\nbWH6R2u5eEIPbrhoQH2HU60j+UXc+MiXlJZ6ee63Z/Hq5xuYsWgbndrG8/CtY2pVGXfJ+nQefD6F\ndq2a8uTdE6qdo7NozV7++uoSwsLC+O11I0iu5Nan1+vlrVnKG7OUhKZR/PHGUdWWr8kvLOaRF79j\n5cb9JEsbfnPdiBr7qnIOFfD0e6tYtGYvTaIjuPnigZw5vBMej4fcw4W89Ok6vvxuBx6P0xd19ZR+\nlQ4eyTlUwC2Pzgavl/9Om1wnJW927drFmWeeCdBNVbe5OSb8/vvvP+kL16d//etfzYFfXHPNNSQk\n1P/EpcbimfdWkZmbz91Tk12XuggGPTo0Y9PObJZrBs3ioir9gCgt9fLCJ+t4c5bSqlkMD982tlZ1\nsAKtV6cWdGufwDkjuxBRQ02q+lZWlmXJhn3MX7WHVZv20619Ao/cNrbWa6Z0aB1HcUkpKevS2b3/\nEOMGt6+0P2P+it389bWlREaE8cebRnFar9aVns/j8TCwZyItE2JYuHoPc5bvonuHZpXeHjuSX8SD\nz6ewevMBRvRL4jfXDSfKxcCGmKgIxg1uT9uWsSxLzeDbVXvYuieHI/nF/Oml79iw7SBd2yXwu+tG\ncN7oblWeMyYqgqjIMBavTedIQTEj+iXVeO2a5Obm8sorrwD8484773TVbAvuf20mKKXtziF1exbJ\n0qa82RwqPB4Pd112GvGxUbz46Xp2ZeQds7+ouJTH31jGh3O30KltHH+9czxda9FpeSqEh3kYM6j9\nCS2SVB/OH9eN5vHRZBw8Qs9OzXnktrEn/A35inP6MKBHKxat2ctH847v3vx66Q7+9vpSYqLCefDm\nMa4WdDp3dFemXTsCb6mXh15IYfaSHcfsP3y0iD8+u4i1WzIZO6g9910zvFb1yTweD2cO78y/fnUG\nA3sksnhtOk+/t4qCohKuu6A/T949wdXytlPGdKNT2zi+WLyNtN05NT4/ECxhmForW/NiSj3fzz9R\nLRJiuONHgyksKuHJN5eXl7A4kl/Eg9MXl3dm/uVn42nTIraeow19MVER3DM1mSljuvKwXwfxiQgP\nD+PeK4fRPD6alz5dx4atB8v3VZz8V5u5EKMGtOOhW8cQGx3B399awbuzN+L1esk7Usjv/ruQ1O1Z\nTEzuyL1XDq2x0nBV2rSM5eFbx3DTxQM4a0Rnnrl3Epec0ZOIcHfniwgP48aLBuL1wnMframXxaos\nYZhaOXy0iDnLd9GmRZN6H+J3MsYObs/E5I5s3JHNu19vIis3n2nPLGDlpv2M7J/EQ7ee3AebOdYQ\nacNtlw4+odpgFbVMiOHXVw7D6/Xy11eXkHOogE/mp/H0e6uIj43iT7ePpVen2t9C7NetFX/52TgS\nmzfhlc838O/3V/ObZxaweWc2Z43ozC+mJhPu8sO9KmFhHi4a34O7Lh9Cm5a1/zKS3KcNI/olsXZL\nJgtX7z2pWE6EJQxTK18v3UlBYQnnju56yoeV1rVbLhlEq2YxvDVL+eVT80jbncM5o7ow7ZrhQTVz\n2hxvYM9Erji3Lwdy8rn3qfk8++EaWsRH8+fbx57UioOdkxJ47M7xdEmKZ8aibWzbm8uUMV352Y9P\nC5p/7zf8oD8R4R5e+GRttZMiA8EShnHN6/Xy+cKtRISHcVYtisoFq7gmkfz88iGUlHrZn3WUn54t\n3PGjwSf9LdKcGj+a1IthfduyN/Mwic1iePSOcXSug4q9ic2b8OjPxnP6kA5ccW4fbr1kUFCt7dE+\nMY4fnN6DjKyjfDBn8ym9dmj0mpmgsGbLAXZlHGJickeaxwfHSnYna4i04VdXDCUqMozRA4N3ToM5\nXliYh1/+NJnPF25jYnLHE7rFU5W4JpHce+Wwmp9YTy6b3JvZS3fy7uxNnDmsM61bnNgSyLVlX6WM\na58v2AbUrm5UKJiQ3NGSRYiKi43issm96zRZhILYmEiumdKXwqISXv5sfa2O9Xq9LFi1h7++trTW\n17UWhnElM+coi9bupWu7BPp2rZvy48aYEzdpWGc+W7CVuSt2MWVsV/p1q3mBrg1bD/LCJ2tJ3Z5F\nSb67GfP+rIVhXJmVsoPSUi9TxnardfE3Y0zdCwvzcPPFgwB47sM11dar2nPgEH9++Tt+/a/5pG7P\nYvTAdjx8y5haX7PGFoaI3Au8qqrptT67aRCKS0qZuWgbTaIjmJhs5VeMCRZ9u7VkYnJH5izfxewl\nOzhr5LGDUXIPF/L2l8rnC7dSXOJFurTg+gv7069bK3btqv3CVG5uSTUB5orIZuAl4ENf4UDTSKSs\nS+dgbj4XjO0W8GVOjTG1c835/Vi0di+vfL6BsYPbExsTSWFRCZ9+m8Y7X23kcH4xSa1iueb8fowd\nVHk5Fbdq/N+vqg8CD4rIOOCnwAMi8jUwXVVXnvCVTVA7kl9Eyrp05q3YzQrNABpeZ7cxDUFi8yb8\neFIvXpuZypuzlB4dm/Pq5+t9FY0jufEHA5gypmutyplUxdXXRRGJBboB3YFSIAt4SkQWqOq0k47C\nBIWCohKWbdjHvBW7WbI+nULfimHdOzTjB6d3r5Mx7saYunfxxJ7MStnOh3O3AE4ZkR9O7MllZ/Yi\nrg4rFrjpw3gdOBP4DHhYVb/1PR4N7AUsYYSw4pJSVm7cz/yVu1m0Zm/5IvYdWscxYUgHxg/pQMc2\nwbeimzHme9GR4dzyw0H8+eUljBnUjqun9KNtAIYau2lhzAZuUtVjVv9Q1QIR6VfnEZlTYnt6Lp9+\nu5UFq/aQd6QQgDYtmjBlTFcmJHeka7sEGw1lTAgZ0T+J9x+9IKCz0t0kjK3Al8BYERFgBnClqi60\nkVOh6dDRIqY9/S15R4poER/NheO7c/ppHZAuLSxJGBPCAl3CxE3CeBy4GkBVVUSmAK8CwwMZmAmc\nD+duJu9IEZdN7s1Pz+kTNEXVjDHBzc3EvRhVXVu2oaqpwMnXKDb1IudQAR/P20Lz+Gh+PKmXJQtj\njGtuWhipIvIXnFYFwE+AjYELyQTS/77ZzNGCEq48r2/IrNhmjAkObloYNwBxwJvAK76fbwpkUCYw\nDubm8+mCrSQ2i+HcUV3rOxxjTIhxM3EvC7ijbFtEPDhzMupnUVlzwt79aiOFRSVcftYAVwvYG2OM\nPzfzMO4EHgGa+j28DegRoJhMAGQcPMLMxdtIahXL5BGd6zscY0wIcnNL6h5gMPA2TpK4AVgcyKBM\n3XvrS6W4xMvUs/u4XnTeGGP8ufnkyFDVrcBqYKCqvgRIQKMydWrP/kPMXrqTTm3jmGDVZo0xJ8hN\nwjgsImfgJIwLRSQJaBHYsExdenOWUlrq5Ypz+towWmPMCXOTMO4ELgRmAq2AVOCfgQzK1J3t6bnM\nXbGL7u2bMXpgu/oOxxgTwtwMxJ+qqvf4fr40kMGYuvf6zFS8XrjivD4BLxtgjGnY3LQwLvQNpTUh\nZvPObBat2Yt0acHwvm3rOxxjTIhz08LIxJntvRw4Wvagql4fsKhMnXj9i1QArjq3rxUVNMacNDcJ\n4+UTPbmvZfIMzrDcfOBGVU3z2z8cp7ghQDpwJc4CTS8DXYFinNLqVoqkljZsPcjSDfsY2CORQb0S\n6zscY0wD4OaW1DdV/HHjYiBaVcfgLLT0RIX9zwLXqurpOJ3qXYApQLiqjgUeAv7k8lrGz2szNwBw\n5Xl9rHVhjKkTbhLGXGCO7++FQBrwvsvzj8NJBKhqCjCsbIeI9Ma53XWPiMwBWqrqJpzChhG+1kkz\noNDltYzPqk37Wb35AEP7tKFft1b1HY4xpoFwU0uqm/+2iIzAr7ZUDRI4tuZUsYiEqWopkAiMBm7H\nSUKfishSYDNOrapUnGG8F7i8lgG8Xi+vzvC1Ls7tW8/RGGMaklrXiFDV74ChLp+eC/gvCF2WLMBp\nXWxW1Y2qWozTEhkO3A3MVFXB6ft4RUTqbhXzBm7phn3o9ixGD2xHz07N6zscY0wD4qb44B/8Nj1A\nP2Cfy/MvwGkhvCcio4A1fvvSgDgR6e7rCB8PTAeigCLfc7J9MVppVRdKS728NjMVjweuOKdPfYdj\njGlg3IyS8u8x9eL0Zbzl8vwfAGeJyALf9nUiMhVoqqrTReQG4E1nqXAWquoMEZkHvOD7OxKYpqpH\nKz27OcaiNXtJ253DhCEd6dIuob7DMcY0MG4SxiPAFFX9WEQSgYuALDcnV1UvcFuFhzf67Z8DjKxw\nzGHgcjfnN5CZc5RNO7PZtDObr5fsICzMw0/PsdqQxpi65yZhPItzS+hj3/YZOB/ytwQqKFO5vCOF\nvuSQxaYdTpI4mJt/zHMum9yb9q3j6ilCY0xD5iZhDFfVgQCqegC4SkRWBzYsA86Ip5mLt7N28wE2\n7cxmb+bhY/a3TIhhZP8kenVuTq9OLejVqTnxsTY+wBgTGG4SRpiItFPVvQAi0gZnNrYJsA3bDvLM\ne6sAiGsSyZDerenV2UkMvTo1p1WzJvUcoTGmMXHbh7FCRL7F6QAfAfw8oFEZADbuyAbg9h8N5txR\nXWzGtjGmXtU4D0NV3wCSgTdxajyNUNX/BTowA1t2OwljYI9WliyMMfWuxoThW23vXVV9H1BggYiM\nCXhkhi27smkSHUH7ROvENsbUPzczvR/HNyJKVRWnOOA/AhmUgaMFxezKOET3Ds1s4SNjTFBwkzBi\nVHVt2YaqpuJMqDMBlLY7B68Xena08h7GmODgptM7VUT+Arzq2/4JfpPvTGCU9V/06NisniMxxhiH\nmxbGDUAcTqf3K76fbwpkUAa27HKK/FoLwxgTLNyUN8/Cr5y5b52KbhxbttzUsc27somJCrdZ28aY\noOGmWu3i8rvXAAAbvklEQVSdOHMxmvo9vA3oEaCYGr38gmJ27cujT9eWhFuHtzEmSLi5JXUPzroU\nb+MkiRuAxYEMqrHbtjeXUi/0sNtRxpgg4iZhZKjqVmA1MFBVXwKsHGoAbd7ldHj3tA5vY0wQcZMw\nDvsm760GLhSRJKBFYMNq3MoShrUwjDHBxE3CuBO4EGcJ1VY4a23/M5BBNXZbduUQFRlOxzbxNT/Z\nGGNOETejpNbh9GMAXBrYcExBUQk79uXRu1Nz6/A2xgQVNy0Mcwpt25NDaanX5l8YY4KOJYw6kHOo\ngDnLduL1ek/6XJt9E/as/8IYE2zclAYxNfh4fhrvfLWRpk0iGd4v6aTOtaVshFQnSxjGmOBSZcIQ\nka1AlV+ZVbV7QCIKQfuzjgCwdMO+OkgYOURFhNGpjc3wNsYEl+paGBNxVtj7A5AGvAQUA1fglAYx\nPtl5BQAsS83A6/We8GJHhUUlbE/PpWfH5oSH291CY0xwqTJhqOp2ABEZpKrX++16XESWBTyyEJLl\nSxj7Dh5hz4HDdDjB+k/b9uZSUuq1CrXGmKDk5musxzdxDwAROQ+npWF8sg8VlP+8LHXfCZ+nvP/C\nOryNMUHITaf3jcDLItLet70duCpwIYWWklIvuYcKaNsyln0Hj7AsNYOLxp9YXcYtu22ElDEmeLmZ\nuLcCGCQirQCvqh4MfFihI/dwAaW+lfFiosJZu/kABUUlREeG1/pcm3dlExkRRuckm+FtjAk+Nd6S\nEpEuIvIlToXaKBH5WkS6BjyyEFHW4d08PprkPm0pLC5l7ZYDtT5PUXEJ2/fm0rVdAhHW4W2MCUJu\nPpn+CzwGHAL28f3Ke4bvO7xbxEcztE8bwBktVVvb9+ZRXGIzvI0xwctNwkhU1VkAqupV1eeAhMCG\nFTqy8/IBp4XRr1srYqLCWX4CHd+2hrcxJti56fQ+KiId8U3iE5FxQEH1hzh8y7k+g7MAUz5wo6qm\n+e0fDjzu20wHrgSmAtf6rtfEd2ySqua6ueapll3ewoghMiKMwb1ak7IunfTMwyS1alrD0d+zkiDG\nmGDndsW9T4FeIrISeAO4y+X5LwaiVXUMMA14osL+Z4FrVfV0nPLpXVT1ZVU9Q1UnAcuAO4M1WcD3\nt6Sax0cDfH9bakPtWhmbd2UTER5GlyRrvBljgpObhLEZGA6MAq4GeuK0BtwYh5MIUNUUYFjZDhHp\nDWQC94jIHKClqm7y2z8M6Keqz7u8Vr3IrpAwkvu0BWCZuu/HKCouZdueXLq2iycywjq8jTHBqcpP\nJxHpJCKdgflAEpAHZAMdgS9cnj8ByPHbLhaRsmsmAqOBp4DJwGQRmej33GnAAy6vU2/KE0ackzDa\ntoylY5s4Vm8+QGFRiatz7NyXR3FJqd2OMsYEteq+zj4AzAV6AfN8P8/FSRYzXJ4/F/CfVBCmqqW+\nnzOBzaq6UVWLcVoiwwBEpBnQW1Xnun0h9SUrL5+mTSKJ8pt3MbRPWwoKS1iXlunqHLYkqzEmFFRX\nS+p6ABH5P1X9ywmefwFwAfCeiIwC1vjtSwPiRKS7ryN8PDDdt+90YPYJXvOUyj5UUN66KDO0Txs+\nmreF5ZrBEGlT4zk2l5cEsRFSxpjg5WaU1EsicjcQh1O9NhzopqpXuzj2A+AsEVng275ORKYCTVV1\nuojcALwpIgALVbWs5SI4CSWolZSUknu48Li1t/t3b0V0VDjLUvdxw0UDajzPll3ZhId56NrOOryN\nMcHLTcJ4H9iC0+n9IXA2sMrNyVXVC9xW4eGNfvvnACMrOe5vbs5f33IOF+L1OpP2/EVFhjOwRyJL\nN+wj4+AR2rSMrfIcxSWlbN2TS5ekBCIjal9OxBhjThW3E/euAT4B/oezTkb/QAYVKrJyv5+0V9Gw\nsuG1NYyW2rkvj6LiUpuwZ4wJem4SRpbvbwUGq2oOEBm4kEJHWVnzFvExx+0rH15bw3wMW5LVGBMq\n3NyS+lpE3gV+BcwSkWScWduNXsU5GP7aJTalfWJTVm/eT1FxaZXzK8pmeFsNKWNMsKuxhaGqvwXu\n863ANxWnpXFJoAMLBf6FBysztG9bjhaUsGFb1cNrt+zKJizMQxfr8DbGBLkqWxgicnWF7bG+HzNx\nJto1+oq11bUwAJKlDZ/MT2N5agaDerY+bn9JSSlpe3Lp3Db+hNbPMMaYU6m6W1Jly7L2wCkH8jnO\n0qznAuuwhEGWr1JtZX0YAAN7JhIVEcay1AyuveD4cQK7Mg5RWFRit6OMMSGhuol71wGIyDfAIFU9\n4NtugTO8ttEra2E0i6u8hREdGc6AnoksT83gQPZREps3OWa/TdgzxoQSN6Ok2gP+y7IeBtoFJpzQ\nkpVXQHxsZLUFA4f6Znovr2R4ra3hbYwJJW4SxmfAlyJyh4jcCXwFvB3YsEJDdl5Blf0XZYb29Q2v\nrWRRpc07swnzQNf21uFtjAl+bkZJ3YOzCFIfnEKEf1PV3wc6sGBXXFJK3pFCmsdV3n9Rpn1iU5Ja\nxbJy436KS0rLHy8p9ZK2J4dObeOJiXIzutkYY+pXdeXNk31/nw7sB94F3gOyfY81ajmHqh9SW8bj\n8ZAsbTiSX4xuzyp/fHdGHgWFJXY7yhgTMqr7ansbcBOVr0nhBSYFJKIQkZVb/ZBaf0P7tuXzhdtY\nlrqP/t1bAf79F9bhbYwJDdWNkrrJ9/cZVT2nMSsrC+ImYQzqkUhEuDO89uop/QD/EVLWwjDGhIbq\nJu59g9OSqJRvze1GK7t8DkbNCSMmOoIB3VuxctN+snLzaZEQw5ZdOYR5oHt7a2EYY0JDdbek7j9V\nQYSirPJZ3tV3epcZ2rcNKzftZ1lqBpOGdSJtdzYd2sQTE20d3saY0FBlp7eqzi37g7PUailOiyMM\nZ/Z3o1ZTWZCKhvqq1y7XDPYcOMTRghLrvzDGhJQav96KyMvAGKAlsAE4DWfp1RcCG1pwq6nwYEUd\n28TRukUTVmgGw3xzM6z/whgTStxM3Dsd6IczrPZmnBXyogIZVCioqSxIRR6Ph6F92nLoaBEzFm4F\nLGEYY0KLm4SxR1WLcFoXg1R1HRBfwzENXlZePvGxUUSEu/kVOob6VuFL3Z6FxwPdbIa3MSaEuOlx\n3S0i03BKgvxVRADiAhpVCMjOK6BlM3cd3mUG9UwkItxDcYmX9olxxMbYwoXGmNDh5uvxDcBWVV2C\ns6b3VJxJfY1WUXEJh44W0dzl7agysTGR9OvmTNyz21HGmFDjpoXxEPAagKr+E/hnQCMKAdl5hUDV\n62BUZ2ifNqzefMDW8DbGhBw3CWMT8HcRaQm8AbymqtsCGlWQK1s4ye2QWn/njelGUXEpZ4/sXNdh\nGWNMQLmpVvu0qo7DWWkvH/hQRL4NeGRBLNtl4cHKNImO4PKzxPovjDEhx9UQHxFphrOO99k4rZIv\nAhlUsKvtpD1jjGkI3Ezc+wQYgtPh/XtVTQl4VEGuprW8jTGmIXLTh/EsMENViwMdTKiwFoYxpjFy\n04fxSVmyEJHlgQ8p+GVZwjDGNELupyk7PAGJIsRk5xXg8UCzpo2+QooxphEJaG1tEfHgrAc+GGeE\n1Y2qmua3fzjwuG8zHbhSVQtF5D7gIiASeEZVXwxknLWVnZdPQtMowmtRFsQYY0JdbT/xJopI/1o8\n/2IgWlXHANOAJyrsfxa4VlVPB2YCXURkAjDad8xEoFMtYwy47LwC6/A2xjQ6NSYMEblRRF4QkdbA\nOuA9EXnY5fnH4SQCfKOrhvmdtzeQCdwjInOAlqq6CTgHWCsiHwIfA5/W4vUEXGFRCYfzi2tdFsQY\nY0KdmxbGbcCvcGpIfQQMxJnE50YCkOO3XSwiZddMBEYDT+HM8ZgsImf4Hh8K/Mh37TdcXuuUKB8h\nlWAJwxjTuLi6JaWqB4EpwGe+EVNNXJ4/l2NLoYepaqnv50xgs6pu9J1zJk4L5ADwhaoWq+pGIF9E\nEl1eL+DKy4JYC8MY08i4SRjrRORToDvwlYi8Ayx1ef4FOIkGERkFrPHblwbEiUh33/Z4YK3vmHN9\nx7QHYnGSS1DILl9pz/owjDGNi5tRUtfjLNG61jeC6RV8/RIufACcJSILfNvXichUoKmqTheRG4A3\nfWtsLFTVGQAiMl5EvsMZxnu7qnpr8ZoCqqyOlM3BMMY0Nm4SRheckUrzReRZnDIh2UCNBQh9H/QV\n187Y6Ld/Ds6SrxWPu89FXPXCJu0ZYxorN7ekXgQKgR8AvYF7gL8FMqhg9v0tKUsYxpjGxU3CiFHV\nd4ELgNdVdT7OhLpG6WTWwjDGmFDmJmGUiMilOAnjUxG5GCgJbFjBKzuvgDAPJDS1hGGMaVzcJIyb\ngfNxOp/3Aj8BbgxoVEEsK6+AhLhowsOsrJYxpnFxU612DfAk0F5EfgE8qqqrAx5ZkHLKgljrwhjT\n+LgpDXIV8CHQDWfE1P9E5PpABxaM8guLOVpgZUGMMY2Tm2G1vwRGqGomgIg8AswBXghgXEGpfIRU\ngk3aM8Y0Pm76MMLLkgWAqh4ASqt5foNVPmnPWhjGmEbITQtjlYj8HXjet30DsCpwIQWvrNyyFoYl\nDGNM4+OmhXETUIBzC+olnEl8twcwpqBlLQxjTGPmpoXxjKpeF/BIQkB2rk3aM8Y0Xm5aGANEJC7g\nkYSArENWqdYY03i5aWGUAjtERIGjZQ+q6qSARRWksq3woDGmEXOTMH4d8ChCRHZeAWFhHuJjo+o7\nFGOMOeWqTRgi0gJY5xtKi4hMANar6v5TEVywycrLp3lcFGFWFsQY0whV2YchIkOA9TjLppY5G1gp\nIoMCHVgwys4roLn1XxhjGqnqOr3/BkxV1fLV9VT1tzgr8D0R6MCCzdGCYvILS6z/whjTaFWXMFr4\nVsQ7hqp+ASQGLKIgZQsnGWMau+oSRqSIHLff91ij6/UtHyFlk/aMMY1UdQljLvDHSh7/HbA0MOEE\nr+9X2rM+DGNM41TdKKlpwOcicgWwBPAAyUAGcNEpiC2oZB+yW1LGmMatyoShqnkicjpwBjAEZwLf\n0741vRudssKD1ultjGmsqp2Hoape4Gvfn0bNWhjGmMbOTS0pA2TlWh+GMaZxs4ThUvahAiLCPcQ1\niazvUIwxpl5YwnApK6+AZnHRVhbEGNNoWcJwwev1kp1XYP0XxphGzRKGC0cLiiksKrH+C2NMo2YJ\nwwWb5W2MMe7WwzhhIuIBngEGA/nAjaqa5rd/OPC4bzMduFJVC0VkGZDje3yrqt4QyDhrklVWRyrB\nEoYxpvEKaMIALgaiVXWMiIzEqXJ7sd/+Z4FLVTVNRK4HuojIDgjMin4vfbqOvCNF3HnZabU6zloY\nxhgT+FtS44CZAKqagt/aGiLSG8gE7hGROUBLVd2E0xppKiJfiMhXvkRTJ7buzWVWynYOZB+t+cl+\nsn11pGwtb2NMYxbohJHA97eWAIr9KuAmAqOBp4DJwGQRmQgcAR5T1XOA24DXK6uaeyJG9G0LQMq6\n9Fodl2VreRtjTMATRi4Q7389VS31/ZwJbFbVjapajNMSGQYo8DqAr8WRCbSri2BG9HdOk7J2b62O\nKysLYgnDGNOYBTphLACmAIjIKGCN3740IE5Euvu2xwPrgBvwdYSLSHuchFO7T/gqtG7RhO4dmrFm\nywEOHy1yfVxZ4UGbh2GMacwCnTA+AApEZAFOErhbRKaKyI2qWoSTHN4UkRRgh6rOAJ4HmonIfOBN\n4Hq/VslJG9U/ieISL8tTM1wfk30on4jwMJpaWRBjTCMW0FFSvmq3t1V4eKPf/jnAyArHFAFXBiqm\nkQPa8cYsZfG6vYwf0sHVMVl5BTSPj8bjsbIgxpjGq9FN3OvWPoE2LZqwbMM+iktqbriUlQWx/gtj\nTGPX6BKGx+NhRP8kDucXs25LZo3PP5xfTFFxqfVfGGMavUaXMABG+UZLLV5Xc1962RwMm7RnjGns\nGmXC6N+jFU1jIkhZl47X6632udnlZUFs0p4xpnFrlAkjIjyMoX3bsj/rKFv35Fb73CwrC2KMMUAj\nTRjw/W2pmmZ9Z1vhQWOMARpxwhjatw0R4R5SaujHyLI+DGOMARpxwoiNiWRgj0S27Mphf1bVxQit\nD8MYYxyNNmGAM4kP4LtqWhnWh2GMMY5GnTBG9EsCYHE1/RjZhwqIiggjNibQS4cYY0xwa9QJo3WL\nJvTo2Iy11RQjzM7Nt7IgxhhDI08YACP7t6uyGKHX6yX7UKGVBTHGGCxhMGpA2W2p4/sxDh8torik\n1FbaM8YYLGHQtV3VxQhtpT1jjPleo08Y/sUI1245cMy+bEsYxhhTrtEnDPCb9b322NFSZZP2WtiQ\nWmOMsYQBvmKETSJJWX9sMcLyFoZN2jPGGEsY4BQjHNbn+GKENmnPGGO+ZwnDZ6RvtFTK2u9HS1nh\nQWOM+Z4lDJ+hfZxihP6zvq3woDHGfM8Shk9ZMcK03TlkZB0BfGVBIsNpEm1lQYwxxhKGn7JihEt8\nrYys3AJaWFkQY4wBLGEcY2T/74sRlpZ6yTlUYHMwjDHGxxKGn8TmTejpK0aYkXWEklIvLSxhGGMM\nYAnjOCMHOMUIv1qyA4DmVkfKGGMASxjHKbst9WWKkzCshWGMMQ5LGBWUFSM8mOsbUmsJwxhjAEsY\nx/F4POWjpcBaGMYYU8YSRiXKbksBNI+zPgxjjAEI6Iw0EfEAzwCDgXzgRlVN89s/HHjct5kOXKmq\nhb59bYClwGRV3RjIOCvq390pRnj4aJHdkjLGGJ9AtzAuBqJVdQwwDXiiwv5ngWtV9XRgJtAFQEQi\ngP8ARwIcX6UiwsOYPLwzic1iSGxuLQxjjIHAJ4xxOIkAVU0BhpXtEJHeQCZwj4jMAVqq6ibf7r8B\n/wb2BDi+Kl1/YX+e/93ZREaE11cIxhgTVAKdMBKAHL/tYhEpu2YiMBp4CpgMTBaRiSJyDZChql8C\n9VaTIyzMQ1iYlQQxxpgyga6qlwvE+22HqWrZwtmZwOay/gkRmQkMB84HvCJyFnAa8IqIXKSqGVVc\nIxwgPT29it3GGGMq8vvMdH0bJdAJYwFwAfCeiIwC1vjtSwPiRKS7ryN8PDBdVR8re4KIfAPcUk2y\nAGgHcMUVV9R58MYY0wi0A7a4eWKgE8YHwFkissC3fZ2ITAWaqup0EbkBeFNEABaq6owKx3up2RKc\nZLMXKKmjuI0xpqELx0kWS9we4PFfw9oYY4ypik3cM8YY44olDGOMMa5YwjDGGOOKJQxjjDGuBHqU\nVMDUVKeqIRCRZXw/8XGrqt5Qn/HUFREZCTyqqmeISA/gJaAUWKuqd9RrcHWgwus7DfgUKKuH9m9V\nfbf+ojtxvpI9LwBdgSjgEWA9DeT9q+L17aQBvH++CdPPAYLzXt0KFFDL9y6UWxg11akKaSISDaCq\nk3x/GkqyuBfnH25ZVccngN+o6gQgTER+UG/B1YFKXt9Q4HG/9zHkPmz8XAkc8NV+Oxf4Fw3r/fN/\nfefhvL5kGsb7dyHgVdVxwO+BP3EC710oJ4wq61Q1EIOBpiLyhYh85fvW2hBsBn7otz1UVef7fp6B\nUyYmlB33+oDzRWSuiEwXkab1FFddeAfnwwacMfzFQHIDev/8X18YUITz/l0Q6u+fqn4E3Ozb7AJk\ncQLvXSgnjOrqVDUER4DHVPUc4Dbg9Ybw+lT1A5wPmjL+BbvygGanNqK6VcnrSwHu9X2LSwPur4+4\n6oKqHlHVwyISD7wL/JYG9P5V8vp+B3wH/KqBvH+lIvISTv2+NziB9y6UP4Cqq1PVEGwEXgfwVfHN\nxFcGpYHxf8/igez6CiRAPlTVFb6fP8CpjxayRKQT8DXwsqq+RQN7/yp5fQ3q/VPVa4HewHSgid8u\nV+9dKCeMBcAUgErqVDUE1+NbXEpE2uO8oXvrNaLAWC4ip/t+Pg+YX92TQ9AXIlJ2u/RMYFl9BnMy\nRKQt8AXwa1V92ffwioby/lXx+hrE+yciV4rIfb7NfJwySktFZILvMVfvXciOkqKSOlX1GUwAPA+8\nKCLzcb7FXd/AWlBlfgU8JyKRwAbgvXqOp67dBvxTRApxVpW8uYbnB7NpQHPg9yLyB5xabz/HeX0N\n4f2r7PXdDfy9Abx//8P5PJmL87l/F5AKTK/Ne2e1pIwxxrgSyrekjDHGnEKWMIwxxrhiCcMYY4wr\nljCMMca4YgnDGGOMK5YwjDHGuBLK8zBMIyIi84CnVfVtv8digR1Ab1U9WMVx3wB/VNV5AYrrPODf\nwHxVvaqq6/rWsv8zcJZv5n7Z8+JxZhaHA5ep6uZaXv+POEXlHvRt98eZfHYnsBzY6rvmbL9jtgIT\ncEpDVLlfVXfUJhbT8FkLw4SKF4ErKjx2CfB1VcniFPkR8LB/sqhIRH4MPAxM8k8WPkOAAlVNrm2y\nqOQ6fYHPgVt9Na3AKaD3XIWief6Tr2rab0w5a2GYUPEO8JiINFfVspo3V+Era+/7UL4HiMGpkXOj\nqn5bdrCvBML9qnqGb/tF4BtVfUVErgJ+gfONexlwh6oW+l9cRC4AHvI9Jw1nPYELccrsnykipar6\nQsWgReQSnHUVJqnq9gr7WuPM6G8rIh/iVLn9BzAJZ3b/a6r6V1/sf8X5grdWVY+raiAivYDPgFtU\ndabfrj3Al77f0y2+xzy12G9MOWthmJCgqoeBj4AfA4hIO5xbUV/4FtO6GThfVYcAfwHureQ0x31z\nFpF+wE3AaFVNBvZXPNb3wf4f4CJVPQ1YCPxLVZ8HPgb+UFmywEkmbwKvV0wWvte0H7gRWKqqF+OU\nEemgqgOAkcClvlteAL2AMypLFr59XwPbKiSLstf8S+AcETmzkmNr2m9MOUsYJpT435a6AngVQFW9\nOLenzhWRB4BrgTiX5zwD6AksFpEVwEU4q5L5GwGkqOpO3/azOK2AmlwInA3cJSLJLmN5CUBVj+JU\nKy77EFdVPVTFcT/ESZjNReTOijt9x92Ec+vpuN9LTfuNKWMJw4QM3y2mtiLSEWd1tBcBfPffl+As\nrTkXp95/xdsq3gqPRfr+Dgfe8fUhDMFJDj+rcGxYhWPDcHc79zZVnQv8H/Cmr5O+OhX/P3r8rnO0\nmuP+oaozcG7RPSgiAys+QVW/xLn19DiVtLRq2m8MWMIwoedlnIVtMlV1q++x3kCJqv4J+AanVHN4\nheMOAN1FJEpEWgLjfY/PAX4oIq19t7b+g9Of4S8FGCkinX3bN/uuU5NCAFWdjlMN9Jkanv81cI2I\nhPmSyxUur1Pgu846nH6Wt0QkxrfPP9H9CjgHaO/3WE37jSlnCcOEmldxStk/7/fYKmCliChOp3Ue\nzjKU4Pu2rKrrcUYQrQPeBub5Hl8NPIDzYb0G5wP0Uf8LqmoGTpL4UETWAKfjdHqXn78SFR+/CeeW\n2U+qeW3/BXb7Xs8ynMV7Pqrm+cdR1SdwynD/o2IcqprniyPS75Ca9htTzsqbG2OMccVaGMYYY1yx\nhGGMMcYVSxjGGGNcsYRhjDHGFUsYxhhjXLGEYYwxxhVLGMYYY1yxhGGMMcaV/wcantCZgn2tfQAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1258ffc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]\n",
    "plt.plot(k_range, grid_mean_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-validated accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.696724709784\n",
      "{'n_neighbors': 18}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=18, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "#Examine the best model\n",
    "print grid.best_score_\n",
    "print grid.best_params_\n",
    "print grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Score: 0.695273631841\n",
      "0.695273631841\n"
     ]
    }
   ],
   "source": [
    "# train model using all data and best known parameters\n",
    "knn = KNeighborsClassifier(n_neighbors =18)\n",
    "knn.fit(Xb,yb)\n",
    "\n",
    "\n",
    "predictions = knn.predict(Xb)\n",
    "\n",
    "scores = cross_val_score(knn, Xb, yb, cv=10, scoring='accuracy')\n",
    "scores\n",
    "\n",
    "#fit a model on the training data and test on the testing data\n",
    "model = logreg.fit(Xb, yb)\n",
    "print model\n",
    "predictions = logreg.predict(Xb)\n",
    "\n",
    "print \"Score:\", model.score(Xb, yb)     \n",
    "print accuracy_score(yb, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Choose a new target from alchemy_category to predict with logistic regression\n",
    "\n",
    "**Ideally your category choice will have a small fraction of the total rows, but not TOO small!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Choose your target category, create the Y vector, and check the fraction of instances\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5853\n",
       "1.0     294\n",
       "Name: news_front_page, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New target category will be \"news_front_page\"\n",
    "su_sub['news_front_page'].value_counts() #Value counts with low values can drop this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "6       0.0\n",
      "10      0.0\n",
      "11      0.0\n",
      "12      0.0\n",
      "14      0.0\n",
      "15      0.0\n",
      "16      0.0\n",
      "17      0.0\n",
      "18      0.0\n",
      "19      0.0\n",
      "20      0.0\n",
      "21      0.0\n",
      "22      0.0\n",
      "25      0.0\n",
      "26      1.0\n",
      "27      0.0\n",
      "30      0.0\n",
      "31      0.0\n",
      "33      0.0\n",
      "34      0.0\n",
      "37      0.0\n",
      "40      0.0\n",
      "41      1.0\n",
      "43      0.0\n",
      "45      0.0\n",
      "       ... \n",
      "7349    0.0\n",
      "7351    0.0\n",
      "7352    0.0\n",
      "7353    0.0\n",
      "7354    0.0\n",
      "7355    0.0\n",
      "7358    0.0\n",
      "7359    0.0\n",
      "7360    0.0\n",
      "7362    0.0\n",
      "7364    0.0\n",
      "7370    0.0\n",
      "7372    0.0\n",
      "7373    1.0\n",
      "7374    0.0\n",
      "7375    1.0\n",
      "7376    0.0\n",
      "7377    0.0\n",
      "7378    0.0\n",
      "7379    0.0\n",
      "7381    0.0\n",
      "7382    0.0\n",
      "7383    0.0\n",
      "7386    0.0\n",
      "7387    0.0\n",
      "7388    0.0\n",
      "7390    0.0\n",
      "7391    0.0\n",
      "7392    0.0\n",
      "7393    1.0\n",
      "Name: news_front_page, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "yz = su_subc['news_front_page']\n",
    "Xz = su_subc.drop(['news_front_page'], axis=1)\n",
    "\n",
    "#print xz.head(1)\n",
    "print yz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Use patsy to create an X matrix of the numeric predictors and all two-way interactions between them\n",
    "\n",
    "Ex:\n",
    "\n",
    "```python\n",
    "import patsy\n",
    "\n",
    "formula_interactions = '~ (var1 + var2 + var3)**2 -1'\n",
    "X_interactions = patsy.dmatrix(formula_interactions, data=data\n",
    "```\n",
    "\n",
    "Get the column names from the `design_info` property of the patsy X matrix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_front_page ~ (C(alchemy_category) + alchemy_category_score + avglinksize + commonlinkratio_1 + commonlinkratio_2 + commonlinkratio_3 + commonlinkratio_4 + compression_ratio + embed_ratio + frameTagRatio + hasDomainLink + html_ratio + image_ratio + lengthyLinkDomain + linkwordscore + news_front_page + non_markup_alphanum_characters + numberOfLinks + numwords_in_url + parametrizedLinkRatio + spelling_errors_ratio)**2 - 1\n"
     ]
    }
   ],
   "source": [
    "import patsy\n",
    "from patsy import dmatrices\n",
    "\n",
    "non_target_cols_z = [c for c in Xz.columns if c not in [\"news_front_page\", \"alchemy_category\"]]\n",
    "\n",
    "# Use some string adding and joining to make the simple model formula:\n",
    "formula_interactions = 'news_front_page' + ' ~ (C(alchemy_category) + ' + ' + '.join(non_target_cols_c) + ')**2 - 1'\n",
    "formula_interactions = str(formula_interactions)\n",
    "print formula_interactions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Normalize the predictor matrix columns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C(alchemy_category)[arts_entertainment]</th>\n",
       "      <th>C(alchemy_category)[business]</th>\n",
       "      <th>C(alchemy_category)[computer_internet]</th>\n",
       "      <th>C(alchemy_category)[culture_politics]</th>\n",
       "      <th>C(alchemy_category)[gaming]</th>\n",
       "      <th>C(alchemy_category)[health]</th>\n",
       "      <th>C(alchemy_category)[law_crime]</th>\n",
       "      <th>C(alchemy_category)[recreation]</th>\n",
       "      <th>C(alchemy_category)[religion]</th>\n",
       "      <th>C(alchemy_category)[science_technology]</th>\n",
       "      <th>...</th>\n",
       "      <th>non_markup_alphanum_characters:numberOfLinks</th>\n",
       "      <th>non_markup_alphanum_characters:numwords_in_url</th>\n",
       "      <th>non_markup_alphanum_characters:parametrizedLinkRatio</th>\n",
       "      <th>non_markup_alphanum_characters:spelling_errors_ratio</th>\n",
       "      <th>numberOfLinks:numwords_in_url</th>\n",
       "      <th>numberOfLinks:parametrizedLinkRatio</th>\n",
       "      <th>numberOfLinks:spelling_errors_ratio</th>\n",
       "      <th>numwords_in_url:parametrizedLinkRatio</th>\n",
       "      <th>numwords_in_url:spelling_errors_ratio</th>\n",
       "      <th>parametrizedLinkRatio:spelling_errors_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.477882</td>\n",
       "      <td>2.169769</td>\n",
       "      <td>-0.250552</td>\n",
       "      <td>-0.268744</td>\n",
       "      <td>-0.123944</td>\n",
       "      <td>-0.330451</td>\n",
       "      <td>-0.075016</td>\n",
       "      <td>-0.568993</td>\n",
       "      <td>-0.120449</td>\n",
       "      <td>-0.244897</td>\n",
       "      <td>...</td>\n",
       "      <td>922080.0</td>\n",
       "      <td>43392.0</td>\n",
       "      <td>829.552939</td>\n",
       "      <td>429.198815</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.452028</td>\n",
       "      <td>1.223529</td>\n",
       "      <td>0.633037</td>\n",
       "      <td>0.012102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.477882</td>\n",
       "      <td>-0.460783</td>\n",
       "      <td>-0.250552</td>\n",
       "      <td>-0.268744</td>\n",
       "      <td>-0.123944</td>\n",
       "      <td>-0.330451</td>\n",
       "      <td>-0.075016</td>\n",
       "      <td>1.757127</td>\n",
       "      <td>-0.120449</td>\n",
       "      <td>-0.244897</td>\n",
       "      <td>...</td>\n",
       "      <td>929951.0</td>\n",
       "      <td>44757.0</td>\n",
       "      <td>904.181819</td>\n",
       "      <td>623.853048</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.458781</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>1.129032</td>\n",
       "      <td>0.022809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.477882</td>\n",
       "      <td>-0.460783</td>\n",
       "      <td>-0.250552</td>\n",
       "      <td>-0.268744</td>\n",
       "      <td>-0.123944</td>\n",
       "      <td>3.025540</td>\n",
       "      <td>-0.075016</td>\n",
       "      <td>-0.568993</td>\n",
       "      <td>-0.120449</td>\n",
       "      <td>-0.244897</td>\n",
       "      <td>...</td>\n",
       "      <td>577920.0</td>\n",
       "      <td>24640.0</td>\n",
       "      <td>373.333334</td>\n",
       "      <td>129.053499</td>\n",
       "      <td>2838.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>14.864198</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.633745</td>\n",
       "      <td>0.009602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.477882</td>\n",
       "      <td>-0.460783</td>\n",
       "      <td>-0.250552</td>\n",
       "      <td>-0.268744</td>\n",
       "      <td>-0.123944</td>\n",
       "      <td>3.025540</td>\n",
       "      <td>-0.075016</td>\n",
       "      <td>-0.568993</td>\n",
       "      <td>-0.120449</td>\n",
       "      <td>-0.244897</td>\n",
       "      <td>...</td>\n",
       "      <td>328440.0</td>\n",
       "      <td>13685.0</td>\n",
       "      <td>114.041668</td>\n",
       "      <td>276.049356</td>\n",
       "      <td>600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.103004</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.504292</td>\n",
       "      <td>0.004202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.477882</td>\n",
       "      <td>-0.460783</td>\n",
       "      <td>-0.250552</td>\n",
       "      <td>-0.268744</td>\n",
       "      <td>-0.123944</td>\n",
       "      <td>-0.330451</td>\n",
       "      <td>-0.075016</td>\n",
       "      <td>-0.568993</td>\n",
       "      <td>-0.120449</td>\n",
       "      <td>-0.244897</td>\n",
       "      <td>...</td>\n",
       "      <td>1949184.0</td>\n",
       "      <td>120320.0</td>\n",
       "      <td>1188.345678</td>\n",
       "      <td>993.467886</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.376147</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.008155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.092133</td>\n",
       "      <td>-0.460783</td>\n",
       "      <td>-0.250552</td>\n",
       "      <td>-0.268744</td>\n",
       "      <td>-0.123944</td>\n",
       "      <td>-0.330451</td>\n",
       "      <td>-0.075016</td>\n",
       "      <td>-0.568993</td>\n",
       "      <td>-0.120449</td>\n",
       "      <td>-0.244897</td>\n",
       "      <td>...</td>\n",
       "      <td>119691.0</td>\n",
       "      <td>3861.0</td>\n",
       "      <td>705.774194</td>\n",
       "      <td>82.789473</td>\n",
       "      <td>279.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.982456</td>\n",
       "      <td>1.645161</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.035276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.477882</td>\n",
       "      <td>2.169769</td>\n",
       "      <td>-0.250552</td>\n",
       "      <td>-0.268744</td>\n",
       "      <td>-0.123944</td>\n",
       "      <td>-0.330451</td>\n",
       "      <td>-0.075016</td>\n",
       "      <td>-0.568993</td>\n",
       "      <td>-0.120449</td>\n",
       "      <td>-0.244897</td>\n",
       "      <td>...</td>\n",
       "      <td>1725192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>707.303573</td>\n",
       "      <td>324.284213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>28.884211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.477882</td>\n",
       "      <td>-0.460783</td>\n",
       "      <td>-0.250552</td>\n",
       "      <td>-0.268744</td>\n",
       "      <td>-0.123944</td>\n",
       "      <td>-0.330451</td>\n",
       "      <td>-0.075016</td>\n",
       "      <td>-0.568993</td>\n",
       "      <td>-0.120449</td>\n",
       "      <td>-0.244897</td>\n",
       "      <td>...</td>\n",
       "      <td>202575.0</td>\n",
       "      <td>21608.0</td>\n",
       "      <td>504.186668</td>\n",
       "      <td>311.653845</td>\n",
       "      <td>600.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.653846</td>\n",
       "      <td>1.493333</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.021538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.477882</td>\n",
       "      <td>-0.460783</td>\n",
       "      <td>-0.250552</td>\n",
       "      <td>-0.268744</td>\n",
       "      <td>-0.123944</td>\n",
       "      <td>3.025540</td>\n",
       "      <td>-0.075016</td>\n",
       "      <td>-0.568993</td>\n",
       "      <td>-0.120449</td>\n",
       "      <td>-0.244897</td>\n",
       "      <td>...</td>\n",
       "      <td>144432.0</td>\n",
       "      <td>9558.0</td>\n",
       "      <td>179.602941</td>\n",
       "      <td>191.508197</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.524590</td>\n",
       "      <td>1.522059</td>\n",
       "      <td>1.622951</td>\n",
       "      <td>0.030497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.477882</td>\n",
       "      <td>-0.460783</td>\n",
       "      <td>-0.250552</td>\n",
       "      <td>-0.268744</td>\n",
       "      <td>-0.123944</td>\n",
       "      <td>-0.330451</td>\n",
       "      <td>-0.075016</td>\n",
       "      <td>1.757127</td>\n",
       "      <td>-0.120449</td>\n",
       "      <td>-0.244897</td>\n",
       "      <td>...</td>\n",
       "      <td>837520.0</td>\n",
       "      <td>39710.0</td>\n",
       "      <td>778.017240</td>\n",
       "      <td>289.539249</td>\n",
       "      <td>2552.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18.607508</td>\n",
       "      <td>2.370690</td>\n",
       "      <td>0.882253</td>\n",
       "      <td>0.017286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    C(alchemy_category)[arts_entertainment]  C(alchemy_category)[business]  \\\n",
       "0                                 -0.477882                       2.169769   \n",
       "1                                 -0.477882                      -0.460783   \n",
       "2                                 -0.477882                      -0.460783   \n",
       "3                                 -0.477882                      -0.460783   \n",
       "4                                 -0.477882                      -0.460783   \n",
       "6                                  2.092133                      -0.460783   \n",
       "10                                -0.477882                       2.169769   \n",
       "11                                -0.477882                      -0.460783   \n",
       "12                                -0.477882                      -0.460783   \n",
       "14                                -0.477882                      -0.460783   \n",
       "\n",
       "    C(alchemy_category)[computer_internet]  \\\n",
       "0                                -0.250552   \n",
       "1                                -0.250552   \n",
       "2                                -0.250552   \n",
       "3                                -0.250552   \n",
       "4                                -0.250552   \n",
       "6                                -0.250552   \n",
       "10                               -0.250552   \n",
       "11                               -0.250552   \n",
       "12                               -0.250552   \n",
       "14                               -0.250552   \n",
       "\n",
       "    C(alchemy_category)[culture_politics]  C(alchemy_category)[gaming]  \\\n",
       "0                               -0.268744                    -0.123944   \n",
       "1                               -0.268744                    -0.123944   \n",
       "2                               -0.268744                    -0.123944   \n",
       "3                               -0.268744                    -0.123944   \n",
       "4                               -0.268744                    -0.123944   \n",
       "6                               -0.268744                    -0.123944   \n",
       "10                              -0.268744                    -0.123944   \n",
       "11                              -0.268744                    -0.123944   \n",
       "12                              -0.268744                    -0.123944   \n",
       "14                              -0.268744                    -0.123944   \n",
       "\n",
       "    C(alchemy_category)[health]  C(alchemy_category)[law_crime]  \\\n",
       "0                     -0.330451                       -0.075016   \n",
       "1                     -0.330451                       -0.075016   \n",
       "2                      3.025540                       -0.075016   \n",
       "3                      3.025540                       -0.075016   \n",
       "4                     -0.330451                       -0.075016   \n",
       "6                     -0.330451                       -0.075016   \n",
       "10                    -0.330451                       -0.075016   \n",
       "11                    -0.330451                       -0.075016   \n",
       "12                     3.025540                       -0.075016   \n",
       "14                    -0.330451                       -0.075016   \n",
       "\n",
       "    C(alchemy_category)[recreation]  C(alchemy_category)[religion]  \\\n",
       "0                         -0.568993                      -0.120449   \n",
       "1                          1.757127                      -0.120449   \n",
       "2                         -0.568993                      -0.120449   \n",
       "3                         -0.568993                      -0.120449   \n",
       "4                         -0.568993                      -0.120449   \n",
       "6                         -0.568993                      -0.120449   \n",
       "10                        -0.568993                      -0.120449   \n",
       "11                        -0.568993                      -0.120449   \n",
       "12                        -0.568993                      -0.120449   \n",
       "14                         1.757127                      -0.120449   \n",
       "\n",
       "    C(alchemy_category)[science_technology]  \\\n",
       "0                                 -0.244897   \n",
       "1                                 -0.244897   \n",
       "2                                 -0.244897   \n",
       "3                                 -0.244897   \n",
       "4                                 -0.244897   \n",
       "6                                 -0.244897   \n",
       "10                                -0.244897   \n",
       "11                                -0.244897   \n",
       "12                                -0.244897   \n",
       "14                                -0.244897   \n",
       "\n",
       "                       ...                       \\\n",
       "0                      ...                        \n",
       "1                      ...                        \n",
       "2                      ...                        \n",
       "3                      ...                        \n",
       "4                      ...                        \n",
       "6                      ...                        \n",
       "10                     ...                        \n",
       "11                     ...                        \n",
       "12                     ...                        \n",
       "14                     ...                        \n",
       "\n",
       "    non_markup_alphanum_characters:numberOfLinks  \\\n",
       "0                                       922080.0   \n",
       "1                                       929951.0   \n",
       "2                                       577920.0   \n",
       "3                                       328440.0   \n",
       "4                                      1949184.0   \n",
       "6                                       119691.0   \n",
       "10                                     1725192.0   \n",
       "11                                      202575.0   \n",
       "12                                      144432.0   \n",
       "14                                      837520.0   \n",
       "\n",
       "    non_markup_alphanum_characters:numwords_in_url  \\\n",
       "0                                          43392.0   \n",
       "1                                          44757.0   \n",
       "2                                          24640.0   \n",
       "3                                          13685.0   \n",
       "4                                         120320.0   \n",
       "6                                           3861.0   \n",
       "10                                             0.0   \n",
       "11                                         21608.0   \n",
       "12                                          9558.0   \n",
       "14                                         39710.0   \n",
       "\n",
       "    non_markup_alphanum_characters:parametrizedLinkRatio  \\\n",
       "0                                          829.552939      \n",
       "1                                          904.181819      \n",
       "2                                          373.333334      \n",
       "3                                          114.041668      \n",
       "4                                         1188.345678      \n",
       "6                                          705.774194      \n",
       "10                                         707.303573      \n",
       "11                                         504.186668      \n",
       "12                                         179.602941      \n",
       "14                                         778.017240      \n",
       "\n",
       "    non_markup_alphanum_characters:spelling_errors_ratio  \\\n",
       "0                                          429.198815      \n",
       "1                                          623.853048      \n",
       "2                                          129.053499      \n",
       "3                                          276.049356      \n",
       "4                                          993.467886      \n",
       "6                                           82.789473      \n",
       "10                                         324.284213      \n",
       "11                                         311.653845      \n",
       "12                                         191.508197      \n",
       "14                                         289.539249      \n",
       "\n",
       "    numberOfLinks:numwords_in_url  numberOfLinks:parametrizedLinkRatio  \\\n",
       "0                          1360.0                                 26.0   \n",
       "1                          1683.0                                 34.0   \n",
       "2                          2838.0                                 43.0   \n",
       "3                           600.0                                  5.0   \n",
       "4                          1620.0                                 16.0   \n",
       "6                           279.0                                 51.0   \n",
       "10                            0.0                                 63.0   \n",
       "11                          600.0                                 14.0   \n",
       "12                         1224.0                                 23.0   \n",
       "14                         2552.0                                 50.0   \n",
       "\n",
       "    numberOfLinks:spelling_errors_ratio  \\\n",
       "0                             13.452028   \n",
       "1                             23.458781   \n",
       "2                             14.864198   \n",
       "3                             12.103004   \n",
       "4                             13.376147   \n",
       "6                              5.982456   \n",
       "10                            28.884211   \n",
       "11                             8.653846   \n",
       "12                            24.524590   \n",
       "14                            18.607508   \n",
       "\n",
       "    numwords_in_url:parametrizedLinkRatio  \\\n",
       "0                                1.223529   \n",
       "1                                1.636364   \n",
       "2                                1.833333   \n",
       "3                                0.208333   \n",
       "4                                0.987654   \n",
       "6                                1.645161   \n",
       "10                               0.000000   \n",
       "11                               1.493333   \n",
       "12                               1.522059   \n",
       "14                               2.370690   \n",
       "\n",
       "    numwords_in_url:spelling_errors_ratio  \\\n",
       "0                                0.633037   \n",
       "1                                1.129032   \n",
       "2                                0.633745   \n",
       "3                                0.504292   \n",
       "4                                0.825688   \n",
       "6                                0.192982   \n",
       "10                               0.000000   \n",
       "11                               0.923077   \n",
       "12                               1.622951   \n",
       "14                               0.882253   \n",
       "\n",
       "    parametrizedLinkRatio:spelling_errors_ratio  \n",
       "0                                      0.012102  \n",
       "1                                      0.022809  \n",
       "2                                      0.009602  \n",
       "3                                      0.004202  \n",
       "4                                      0.008155  \n",
       "6                                      0.035276  \n",
       "10                                     0.011842  \n",
       "11                                     0.021538  \n",
       "12                                     0.030497  \n",
       "14                                     0.017286  \n",
       "\n",
       "[10 rows x 463 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import patsy\n",
    "from patsy import dmatrices\n",
    "\n",
    "yz, Xz = dmatrices(formula_interactions, data = su_subc, return_type='dataframe')\n",
    "yz = su_subc['news_front_page']\n",
    "\n",
    "#NORMALIZE\n",
    "Xz.ix[:, nc] = (Xz.ix[:, nc] - Xz.ix[:, nc].mean()) / Xz.ix[:, nc].std()\n",
    "Xz[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Gridsearch a logistic regression to predict accuracy on your new target from the interaction predictors\n",
    "\n",
    "Include Ridge and Lasso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([  1.00000e+03,   1.00000e+02,   1.00000e+01,   1.00000e+00,\n",
      "         1.00000e-01,   1.00000e-02,   1.00000e-03,   1.00000e-04,\n",
      "         0.00000e+00])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "0.999999999995\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "#Ridge fit, new model\n",
    "estim_ridge.fit(Xz, yz)\n",
    "print(estim_ridge)\n",
    "\n",
    "#Summarize the Results of the Grid Search\n",
    "print(estim_ridge.best_score_)\n",
    "print(estim_ridge.best_estimator_.alpha)\n",
    "\n",
    "#Best Alpha 0.001, strong fit model, should cross-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Build a logistic regression with the optimal parameters, and look at the coefficients\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Score: 0.998963515755\n",
      "0.998963515755\n"
     ]
    }
   ],
   "source": [
    "#Lasso doesn't seem to work, will do regular logistic regression - should cross validate\n",
    "\n",
    "#fit a model on the training data and test on the testing data\n",
    "model = logreg.fit(Xz, yz)\n",
    "print model\n",
    "predictions = logreg.predict(Xz)\n",
    "\n",
    "print \"Score:\", model.score(Xz, yz)     \n",
    "print accuracy_score(yz, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Better to do false pos, false neg, ROC  to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Gridsearch parameters for a logistic regression with the same target and predictors, but score based on precision rather than accuracy\n",
    "\n",
    "Look at the documentation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                predicted_front_page  predicted_not_front_page\n",
      "is_front_page                     92                         3\n",
      "not_front_page                     3                      1832\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split( Xz, yz, test_size=0.4, random_state=42)\n",
    "\n",
    "#Fit Log Reg to training data\n",
    "logreg = LogisticRegression(random_state=77)\n",
    "logreg.fit(X_train, y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "conmat = np.array(confusion_matrix(y_test, Y_pred, labels=[1,0]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['is_front_page', 'not_front_page'],\n",
    "                         columns=['predicted_front_page','predicted_not_front_page'])\n",
    "\n",
    "print(confusion)\n",
    "\n",
    "# print \"Score:\", model.score(X_test, y_test)     \n",
    "# print accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99689119171\n",
      "0.968421052632\n",
      "0.968421052632\n"
     ]
    }
   ],
   "source": [
    "# Accuracy tells us the percent of houses selling for over and under 200k correctly predicted\n",
    "print(accuracy_score(y_test, Y_pred))\n",
    "\n",
    "# Precision tells us how well the classifier avoided misclassifying the over 200k houses\n",
    "print(precision_score(y_test, Y_pred))\n",
    "\n",
    "# Recall tells us how well the classifier correctly identified houses as selling for over 200k\n",
    "print(recall_score(y_test, Y_pred))\n",
    "\n",
    "#GOOD ACCURACY AND PRECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqcAAAI+CAYAAACBjKOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUDgVEREREb+hcCoiIiIifuP/Ad49ybijkrf9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1192bfe90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generic curve plotting function\n",
    "def auc_plotting_function(rate1, rate2, rate1_name, rate2_name, curve_name):\n",
    "    AUC = auc(rate1, rate2)\n",
    "    # Plot of a ROC curve for class 1 (has_cancer)\n",
    "    plt.figure(figsize=[11,9])\n",
    "    plt.plot(rate1, rate2, label=curve_name + ' (area = %0.2f)' % AUC, linewidth=4)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(rate1_name, fontsize=18)\n",
    "    plt.ylabel(rate2_name, fontsize=18)\n",
    "    plt.title(curve_name + ' for is_front_page', fontsize=18)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# plot receiving operator characteristic curve\n",
    "def plot_roc(y_true, y_score):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc_plotting_function(fpr, tpr, 'False Positive Rate', 'True Positive Rate', 'ROC')\n",
    "\n",
    "    \n",
    "Y_score = logreg.decision_function(X_test)\n",
    "plot_roc(y_test, Y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [BONUS] 8. Build models predicting from words\n",
    "\n",
    "This is a bit of the NLP we covered in the pipeline lecture!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Choose 'body' or 'title' from the boilerplate to be the basis of your word predictors\n",
    "\n",
    "You will need to parse the json from the boilerplate field.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Use CountVectorizer to create your predictor matrix from the string column\n",
    "\n",
    "It is up to you what range of ngrams and features, and whether or not you want the columns binary or counts.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Gridsearch a logistic regression predicting accuracy of your chosen target category from word predictor matrix\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Do the same as above, but score the gridsearch based on precision rather than accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Build a logistic regression with optimal precision categories\n",
    "\n",
    "Print out the top 20 or 25 word features as ranked by their coefficients.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
